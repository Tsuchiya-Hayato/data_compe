model: efficientnet-b1, lr: 1e-05, weights: tensor([19.6000,  9.7000,  8.9000,  1.6000,  8.3000]). batchsize: 16, kfold: 3, epoch: 25, RandomHorizontalFlip:(True,),CenterCrop: True 

kfold: 1, epoch: 1. train_loss: 1.50238685116105, train_acc: 45.68143578238923. val_loss: 1.366353976085047, val_acc: 61.08229356511986
kfold: 1, epoch: 2. train_loss: 1.2579760234719435, train_acc: 62.885586090858105. val_loss: 1.1131514554066508, val_acc: 66.73209028459274
kfold: 1, epoch: 3. train_loss: 1.0772180646791587, train_acc: 66.94475602916432. val_loss: 0.9682659904384827, val_acc: 69.90046263844106
kfold: 1, epoch: 4. train_loss: 0.9827010998410495, train_acc: 69.37044307347168. val_loss: 0.9040996699589785, val_acc: 71.98934529650919
kfold: 1, epoch: 5. train_loss: 0.9070239069750491, train_acc: 72.13264161525518. val_loss: 0.8534548020683597, val_acc: 73.54549278003645
kfold: 1, epoch: 6. train_loss: 0.8556769053397425, train_acc: 73.4296130117779. val_loss: 0.8352722031118623, val_acc: 74.37263423524463
kfold: 1, epoch: 7. train_loss: 0.8267507325406833, train_acc: 74.62142456533931. val_loss: 0.8115363593125557, val_acc: 75.17173699705593
kfold: 1, epoch: 8. train_loss: 0.7911091930328997, train_acc: 75.56085249579361. val_loss: 0.7952938729337513, val_acc: 75.52222066451704
kfold: 1, epoch: 9. train_loss: 0.761032476854164, train_acc: 76.77369601794727. val_loss: 0.7880591343369986, val_acc: 76.19514930604234
kfold: 1, epoch: 10. train_loss: 0.7321665734386765, train_acc: 77.40465507571508. val_loss: 0.7690563317171126, val_acc: 77.31669704191785
kfold: 1, epoch: 11. train_loss: 0.7077063562624123, train_acc: 78.48429613011778. val_loss: 0.7635053074981333, val_acc: 77.69521940277583
kfold: 1, epoch: 12. train_loss: 0.6706201126924277, train_acc: 79.42372406057207. val_loss: 0.7568282234762281, val_acc: 77.75129678956961
kfold: 1, epoch: 13. train_loss: 0.6560402153218541, train_acc: 79.59197980931015. val_loss: 0.7582757944583626, val_acc: 78.46628347119024
kfold: 1, epoch: 14. train_loss: 0.6394559211460998, train_acc: 79.93550196298374. val_loss: 0.7553100297436318, val_acc: 78.74667040515912
kfold: 1, epoch: 15. train_loss: 0.615465103911712, train_acc: 81.17638810992709. val_loss: 0.7812820643253391, val_acc: 78.41020608439646
kfold: 1, epoch: 16. train_loss: 0.5862788084159384, train_acc: 81.83538979248458. val_loss: 0.775950714244169, val_acc: 78.1017804570307
kfold: 1, epoch: 17. train_loss: 0.5720189650012639, train_acc: 82.35417835109367. val_loss: 0.7788354259802889, val_acc: 79.22332819290621
kfold: 1, epoch: 18. train_loss: 0.5449015285920001, train_acc: 83.02019068984858. val_loss: 0.7941506166228265, val_acc: 78.73265105846068
kfold: 1, epoch: 19. train_loss: 0.5331823645335009, train_acc: 83.25154234436343. val_loss: 0.7791081927382625, val_acc: 78.52236085798401
kfold: 1, epoch: 20. train_loss: 0.49822957201071516, train_acc: 84.05776780706674. val_loss: 0.8037769538872445, val_acc: 78.83078648534978
kfold: 1, epoch: 21. train_loss: 0.47723112869673645, train_acc: 84.82893998878295. val_loss: 0.8022471252210739, val_acc: 79.09715407262021
kfold: 1, epoch: 22. train_loss: 0.47038110485091605, train_acc: 85.0532809871004. val_loss: 0.823956253165755, val_acc: 78.84480583204822
kfold: 1, epoch: 23. train_loss: 0.4486428272822713, train_acc: 85.22153673583847. val_loss: 0.8212662670727936, val_acc: 79.58783120706575
kfold: 1, epoch: 24. train_loss: 0.41872751103889516, train_acc: 86.3853056646102. val_loss: 0.8637989996828038, val_acc: 78.62049628487313
kfold: 1, epoch: 25. train_loss: 0.41200271403341815, train_acc: 86.70078519349411. val_loss: 0.8704848728923653, val_acc: 79.12519276601711
kfold: 2, epoch: 1. train_loss: 1.5065601975928506, train_acc: 40.73606729758149. val_loss: 1.3488733920815814, val_acc: 59.15591699383062
kfold: 2, epoch: 2. train_loss: 1.2493314897399312, train_acc: 61.682439537329124. val_loss: 1.1091911304959268, val_acc: 65.26920919798093
kfold: 2, epoch: 3. train_loss: 1.0761206061850748, train_acc: 66.82089029092184. val_loss: 0.9747183972410023, val_acc: 68.80257992148066
kfold: 2, epoch: 4. train_loss: 0.9739702423124036, train_acc: 69.85629162285313. val_loss: 0.9029672866177666, val_acc: 71.53673583847448
kfold: 2, epoch: 5. train_loss: 0.905652228158151, train_acc: 72.1416053277252. val_loss: 0.8639299056655623, val_acc: 72.86876051598429
kfold: 2, epoch: 6. train_loss: 0.8540664138147115, train_acc: 73.55765860497722. val_loss: 0.8366512351506494, val_acc: 73.79416713404375
kfold: 2, epoch: 7. train_loss: 0.8287396443999402, train_acc: 74.92464072905713. val_loss: 0.8087392448042541, val_acc: 75.25238362310712
kfold: 2, epoch: 8. train_loss: 0.7866799436476198, train_acc: 75.80091132141605. val_loss: 0.8000622234336464, val_acc: 75.09814918676388
kfold: 2, epoch: 9. train_loss: 0.7616945147647985, train_acc: 76.69120224325272. val_loss: 0.7764176359826139, val_acc: 76.00953449242849
kfold: 2, epoch: 10. train_loss: 0.7299329567817562, train_acc: 77.97406239046617. val_loss: 0.775941130107962, val_acc: 76.58440830061694
kfold: 2, epoch: 11. train_loss: 0.6989778250522678, train_acc: 78.57693655800911. val_loss: 0.7661531381476085, val_acc: 77.15928210880539
kfold: 2, epoch: 12. train_loss: 0.6742763007435564, train_acc: 78.94146512443042. val_loss: 0.7683495138792714, val_acc: 76.96298373527762
kfold: 2, epoch: 13. train_loss: 0.6497081444502679, train_acc: 79.78268489309498. val_loss: 0.7718042515452133, val_acc: 77.81828379136287
kfold: 2, epoch: 14. train_loss: 0.631834505735625, train_acc: 80.4135997195934. val_loss: 0.7580543593607943, val_acc: 77.91643297812675
kfold: 2, epoch: 15. train_loss: 0.611096828749963, train_acc: 81.198738170347. val_loss: 0.7583919504966437, val_acc: 78.51934941110488
kfold: 2, epoch: 16. train_loss: 0.5870690216047213, train_acc: 81.85769365580092. val_loss: 0.7617201694191305, val_acc: 78.42120022434099
kfold: 2, epoch: 17. train_loss: 0.5601592132562746, train_acc: 82.26428321065545. val_loss: 0.7724817596342531, val_acc: 79.2204150308469
kfold: 2, epoch: 18. train_loss: 0.5474152110450203, train_acc: 82.6919032597266. val_loss: 0.7750110485728814, val_acc: 78.42120022434099
kfold: 2, epoch: 19. train_loss: 0.5271049154579907, train_acc: 83.12653347353663. val_loss: 0.792835173351615, val_acc: 78.11273135165452
kfold: 2, epoch: 20. train_loss: 0.5083526208278443, train_acc: 83.61724500525763. val_loss: 0.8124830231337804, val_acc: 78.9119461581604
kfold: 2, epoch: 21. train_loss: 0.4799380544406015, train_acc: 84.577637574483. val_loss: 0.8096062412711003, val_acc: 78.9820527201346
kfold: 2, epoch: 22. train_loss: 0.4507964851476686, train_acc: 85.3838065194532. val_loss: 0.821503864008215, val_acc: 78.50532809871004
kfold: 2, epoch: 23. train_loss: 0.44853225350379944, train_acc: 85.13144058885383. val_loss: 0.8237339873451556, val_acc: 77.80426247896803
kfold: 2, epoch: 24. train_loss: 0.4307527664313803, train_acc: 85.83946722747984. val_loss: 0.8336152254599627, val_acc: 78.32305103757712
kfold: 2, epoch: 25. train_loss: 0.410968754290198, train_acc: 86.29512793550649. val_loss: 0.8624763819368163, val_acc: 79.65507571508694
kfold: 3, epoch: 1. train_loss: 1.5125653428347121, train_acc: 45.33473536628111. val_loss: 1.385658064230675, val_acc: 60.19349411104879
kfold: 3, epoch: 2. train_loss: 1.2661805714860626, train_acc: 62.66386260077112. val_loss: 1.1389964510908042, val_acc: 65.54963544587774
kfold: 3, epoch: 3. train_loss: 1.0814856406418198, train_acc: 65.95864002804066. val_loss: 1.0045235161690433, val_acc: 67.8771733034212
kfold: 3, epoch: 4. train_loss: 0.9867208895728727, train_acc: 69.4987732211707. val_loss: 0.9233732444689413, val_acc: 71.39652271452609
kfold: 3, epoch: 5. train_loss: 0.9177266885881467, train_acc: 72.25376796354715. val_loss: 0.8775757215750057, val_acc: 72.61637689287717
kfold: 3, epoch: 6. train_loss: 0.8666920742780104, train_acc: 73.17209954433929. val_loss: 0.8547031722728982, val_acc: 73.80818844643859
kfold: 3, epoch: 7. train_loss: 0.8150750896789033, train_acc: 75.16298633017875. val_loss: 0.8218141475466869, val_acc: 75.78519349411106
kfold: 3, epoch: 8. train_loss: 0.7848779781817588, train_acc: 75.57658604977217. val_loss: 0.8060997277164138, val_acc: 75.25238362310712
kfold: 3, epoch: 9. train_loss: 0.7544342061930708, train_acc: 76.67718191377497. val_loss: 0.8080353815058422, val_acc: 76.31800336511498
kfold: 3, epoch: 10. train_loss: 0.7342218433761544, train_acc: 77.43427970557308. val_loss: 0.7995041960958943, val_acc: 76.48625911385305
kfold: 3, epoch: 11. train_loss: 0.6957399638144157, train_acc: 78.57693655800911. val_loss: 0.7904717876103962, val_acc: 76.62647223780145
kfold: 3, epoch: 12. train_loss: 0.6673136840119223, train_acc: 79.41815632667368. val_loss: 0.7902227292680954, val_acc: 77.74817722938867
kfold: 3, epoch: 13. train_loss: 0.6432980941065625, train_acc: 80.02103049421662. val_loss: 0.7994485281641708, val_acc: 77.4116657319125
kfold: 3, epoch: 14. train_loss: 0.6247399503974904, train_acc: 80.67998597967052. val_loss: 0.7909896703512145, val_acc: 77.56590016825575
kfold: 3, epoch: 15. train_loss: 0.5974542706904122, train_acc: 81.59831756046268. val_loss: 0.8094601278013712, val_acc: 76.79472798653954
kfold: 3, epoch: 16. train_loss: 0.5732374094643802, train_acc: 82.06799859796705. val_loss: 0.8024579107327044, val_acc: 77.43970835670218
kfold: 3, epoch: 17. train_loss: 0.5469923942212032, train_acc: 82.43953732912723. val_loss: 0.8153203831392554, val_acc: 78.04262478968032
kfold: 3, epoch: 18. train_loss: 0.5232139102646856, train_acc: 83.30879775674728. val_loss: 0.8336730403616824, val_acc: 77.6920919798093
kfold: 3, epoch: 19. train_loss: 0.5135223488386036, train_acc: 83.65229582895198. val_loss: 0.8228453758753201, val_acc: 78.50532809871004
kfold: 3, epoch: 20. train_loss: 0.48610669941612156, train_acc: 83.93270241850684. val_loss: 0.8603404483887379, val_acc: 77.90241166573192
kfold: 3, epoch: 21. train_loss: 0.4689816549261656, train_acc: 84.86505432877672. val_loss: 0.8550619408321221, val_acc: 78.08468872686484
kfold: 3, epoch: 22. train_loss: 0.44426990148398376, train_acc: 84.99824745881529. val_loss: 0.8668723832398252, val_acc: 77.81828379136287
kfold: 3, epoch: 23. train_loss: 0.4231352896216605, train_acc: 86.12688398177357. val_loss: 0.8855986810986771, val_acc: 77.94447560291643
kfold: 3, epoch: 24. train_loss: 0.4084934934873485, train_acc: 86.37924991237294. val_loss: 0.9004808804396156, val_acc: 77.88839035333707
kfold: 3, epoch: 25. train_loss: 0.3929099891618763, train_acc: 86.63161584297231. val_loss: 0.9244760785903364, val_acc: 77.97251822770612