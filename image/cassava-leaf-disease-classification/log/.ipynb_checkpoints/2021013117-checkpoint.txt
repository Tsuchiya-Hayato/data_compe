filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b3, lr: 1e-05, weights: tensor([1.5000, 1.0000, 1.0000, 1.0000, 1.0000]). batchsize: 8, kfold: 3, epoch: 25, weght_decay: 1e-05, smoothing: 0.12

kfold: 1, epoch: 1. train_loss: 1.261599089881375, train_acc: 64.44896242288279. val_loss: 1.1164212856324798, val_acc: 74.13430534137109
kfold: 1, epoch: 2. train_loss: 1.0870182262132895, train_acc: 73.72406057206955. val_loss: 1.0058553585022554, val_acc: 79.51773447357353
kfold: 1, epoch: 3. train_loss: 1.0247146444112079, train_acc: 77.27145260796411. val_loss: 0.956374861467045, val_acc: 81.63465582503855
kfold: 1, epoch: 4. train_loss: 0.9961496603936876, train_acc: 78.58945597307908. val_loss: 0.9305454269385659, val_acc: 83.05060984158138
kfold: 1, epoch: 5. train_loss: 0.974415341756749, train_acc: 79.70415030846887. val_loss: 0.9126224237840806, val_acc: 83.94784803028179
kfold: 1, epoch: 6. train_loss: 0.96376926870207, train_acc: 80.22994952327538. val_loss: 0.9005711893864277, val_acc: 84.08804149726623
kfold: 1, epoch: 7. train_loss: 0.9487561867334705, train_acc: 80.95905776780707. val_loss: 0.8904332550651824, val_acc: 84.53666059161642
kfold: 1, epoch: 8. train_loss: 0.9388249046803858, train_acc: 81.7372406057207. val_loss: 0.8794048223393915, val_acc: 85.33576335342774
kfold: 1, epoch: 9. train_loss: 0.928407190157601, train_acc: 82.16489063376332. val_loss: 0.8767351790126664, val_acc: 85.33576335342774
kfold: 1, epoch: 10. train_loss: 0.9217967012258841, train_acc: 82.65563656758273. val_loss: 0.8828661798628991, val_acc: 85.01331837936353
kfold: 1, epoch: 11. train_loss: 0.9097523490365007, train_acc: 83.01318003365115. val_loss: 0.8741347448975516, val_acc: 85.26566661993552
kfold: 1, epoch: 12. train_loss: 0.9031430768017279, train_acc: 83.68620302860347. val_loss: 0.868676703540199, val_acc: 85.34978270012617
kfold: 1, epoch: 13. train_loss: 0.8946157796156922, train_acc: 83.73527762198542. val_loss: 0.8665803314057167, val_acc: 85.61615028739661
kfold: 1, epoch: 14. train_loss: 0.8906248124609887, train_acc: 84.12086371284352. val_loss: 0.8695826620665367, val_acc: 85.27968596663395
kfold: 1, epoch: 15. train_loss: 0.8820188427934202, train_acc: 84.76584408300617. val_loss: 0.8648255266282591, val_acc: 85.65820832749193
kfold: 1, epoch: 16. train_loss: 0.8807689610051761, train_acc: 84.61862030286035. val_loss: 0.864773999415171, val_acc: 85.47595682041216
kfold: 1, epoch: 17. train_loss: 0.8772342613889338, train_acc: 85.13039820527202. val_loss: 0.8699837900330668, val_acc: 85.08341511285575
kfold: 1, epoch: 18. train_loss: 0.8665402893998686, train_acc: 85.55103757711721. val_loss: 0.8671422883400468, val_acc: 85.27968596663395
kfold: 1, epoch: 19. train_loss: 0.8657278309561066, train_acc: 85.55103757711721. val_loss: 0.8575522929697293, val_acc: 85.81242114117482
kfold: 1, epoch: 20. train_loss: 0.8712897908132663, train_acc: 85.1233875490746. val_loss: 0.8567753778979382, val_acc: 85.7423244076826
kfold: 1, epoch: 21. train_loss: 0.8591013476210769, train_acc: 85.98569826135726. val_loss: 0.8542640315443946, val_acc: 86.02271134165147
kfold: 1, epoch: 22. train_loss: 0.8571809752229487, train_acc: 86.04178351093663. val_loss: 0.8553616021647047, val_acc: 85.91055656806392
kfold: 1, epoch: 23. train_loss: 0.856522890636243, train_acc: 85.81043185642176. val_loss: 0.8543537728187749, val_acc: 86.13486611523903
kfold: 1, epoch: 24. train_loss: 0.8499331720678979, train_acc: 86.60964666292764. val_loss: 0.8527195995564952, val_acc: 86.0928080751437
kfold: 1, epoch: 25. train_loss: 0.8478779883045062, train_acc: 86.64469994391474. val_loss: 0.8534962862997312, val_acc: 86.07878872844526
kfold: 2, epoch: 1. train_loss: 1.2604095223840042, train_acc: 64.58464773922188. val_loss: 1.1282724637220793, val_acc: 74.04655075715087
kfold: 2, epoch: 2. train_loss: 1.0909775036466496, train_acc: 73.79600420609884. val_loss: 1.0085129350958384, val_acc: 79.47279865395402
kfold: 2, epoch: 3. train_loss: 1.0331829601873732, train_acc: 76.87346652646337. val_loss: 0.960278381213479, val_acc: 81.50588895120583
kfold: 2, epoch: 4. train_loss: 0.9982401047386396, train_acc: 78.64002804065896. val_loss: 0.9263706838737155, val_acc: 82.76780706674144
kfold: 2, epoch: 5. train_loss: 0.9880345931168094, train_acc: 79.00455660708026. val_loss: 0.9115104057195476, val_acc: 83.95961862030286
kfold: 2, epoch: 6. train_loss: 0.9689966042279663, train_acc: 80.23133543638275. val_loss: 0.9045220626175671, val_acc: 83.95961862030286
kfold: 2, epoch: 7. train_loss: 0.9514847946741656, train_acc: 81.33894146512444. val_loss: 0.8908217974976039, val_acc: 84.50644980370163
kfold: 2, epoch: 8. train_loss: 0.9416909309045616, train_acc: 81.41605327725202. val_loss: 0.8815913044016458, val_acc: 85.03925967470555
kfold: 2, epoch: 9. train_loss: 0.931803957630166, train_acc: 82.00490711531721. val_loss: 0.8764176292537039, val_acc: 85.08132361189007
kfold: 2, epoch: 10. train_loss: 0.9274211289035366, train_acc: 82.39747634069401. val_loss: 0.8723059577257644, val_acc: 85.09534492428492
kfold: 2, epoch: 11. train_loss: 0.9195517598580352, train_acc: 82.97932001402033. val_loss: 0.8731671406682832, val_acc: 85.33370723499719
kfold: 2, epoch: 12. train_loss: 0.9120294769783192, train_acc: 83.0844724851034. val_loss: 0.8665074889168076, val_acc: 85.58609085810431
kfold: 2, epoch: 13. train_loss: 0.8981349921279959, train_acc: 84.05187521906765. val_loss: 0.8627281088732818, val_acc: 85.7543466068424
kfold: 2, epoch: 14. train_loss: 0.8951791818901028, train_acc: 84.00280406589555. val_loss: 0.858531193481967, val_acc: 85.88053841839596
kfold: 2, epoch: 15. train_loss: 0.8921188961029587, train_acc: 84.12197686645636. val_loss: 0.862266064358399, val_acc: 85.88053841839596
kfold: 2, epoch: 16. train_loss: 0.8833600674910396, train_acc: 84.34630213810024. val_loss: 0.8556015461415988, val_acc: 86.04879416713405
kfold: 2, epoch: 17. train_loss: 0.8802859741409264, train_acc: 84.78093235191027. val_loss: 0.8550660639600369, val_acc: 86.1048794167134
kfold: 2, epoch: 18. train_loss: 0.8754596786047311, train_acc: 84.9211356466877. val_loss: 0.8551006356563269, val_acc: 86.0347728547392
kfold: 2, epoch: 19. train_loss: 0.8714968877522935, train_acc: 85.32772520154224. val_loss: 0.8468010118857627, val_acc: 86.87605159842961
kfold: 2, epoch: 20. train_loss: 0.8696274559594056, train_acc: 85.30669470732562. val_loss: 0.8458603171489698, val_acc: 86.49747616376892
kfold: 2, epoch: 21. train_loss: 0.8704744196192031, train_acc: 85.51699964949177. val_loss: 0.8482379285209382, val_acc: 86.70779584969154
kfold: 2, epoch: 22. train_loss: 0.8657413393659976, train_acc: 85.57308096740273. val_loss: 0.8507962871025496, val_acc: 86.60964666292764
kfold: 2, epoch: 23. train_loss: 0.8626657817930384, train_acc: 85.7273045916579. val_loss: 0.8479873171168057, val_acc: 86.51149747616377
kfold: 2, epoch: 24. train_loss: 0.8571586871494626, train_acc: 85.99369085173501. val_loss: 0.8510598686644849, val_acc: 86.32922041503085
kfold: 2, epoch: 25. train_loss: 0.8523249858697968, train_acc: 86.33017875920085. val_loss: 0.8516423726295677, val_acc: 86.28715647784632
kfold: 3, epoch: 1. train_loss: 1.2559004513872578, train_acc: 64.60567823343848. val_loss: 1.1088152883966942, val_acc: 74.5793606281548
kfold: 3, epoch: 2. train_loss: 1.0827572667812553, train_acc: 73.73992288818788. val_loss: 0.9963641614390061, val_acc: 80.00560852495794
kfold: 3, epoch: 3. train_loss: 1.0212760916806658, train_acc: 77.15387311601823. val_loss: 0.9422750779064247, val_acc: 82.13684800897364
kfold: 3, epoch: 4. train_loss: 0.9946178861730837, train_acc: 78.68208902909218. val_loss: 0.9223871586568687, val_acc: 83.21648906337633
kfold: 3, epoch: 5. train_loss: 0.9747102756738129, train_acc: 79.57237995092885. val_loss: 0.9033946898753333, val_acc: 84.2540661805945
kfold: 3, epoch: 6. train_loss: 0.9604683877574489, train_acc: 80.7570977917981. val_loss: 0.892231586669058, val_acc: 84.78687605159843
kfold: 3, epoch: 7. train_loss: 0.9476074625825668, train_acc: 80.86926042762005. val_loss: 0.8847001933998057, val_acc: 84.95513180033652
kfold: 3, epoch: 8. train_loss: 0.9408035125633526, train_acc: 81.52821591307396. val_loss: 0.8721095223330596, val_acc: 85.0532809871004
kfold: 3, epoch: 9. train_loss: 0.9292277035558171, train_acc: 82.38345601121627. val_loss: 0.8739975926721043, val_acc: 85.13740886146944
kfold: 3, epoch: 10. train_loss: 0.9240237890404436, train_acc: 82.46757798808272. val_loss: 0.873318230290584, val_acc: 85.41783510936624
kfold: 3, epoch: 11. train_loss: 0.9196715826678169, train_acc: 82.61479144759902. val_loss: 0.8666006773042038, val_acc: 85.40381379697139
kfold: 3, epoch: 12. train_loss: 0.9108933801073664, train_acc: 83.1335436382755. val_loss: 0.8610495151158406, val_acc: 85.65619742007851
kfold: 3, epoch: 13. train_loss: 0.895352126270399, train_acc: 83.79249912372941. val_loss: 0.8657362692960174, val_acc: 85.16545148625912
kfold: 3, epoch: 14. train_loss: 0.8961700584254992, train_acc: 83.82053978268489. val_loss: 0.8563585989678387, val_acc: 85.79641054402693
kfold: 3, epoch: 15. train_loss: 0.8899276213795615, train_acc: 84.10795653697862. val_loss: 0.8556570573772551, val_acc: 86.09085810431857
kfold: 3, epoch: 16. train_loss: 0.8817344601913418, train_acc: 84.73887136347705. val_loss: 0.8528035182856658, val_acc: 86.30117779024117
kfold: 3, epoch: 17. train_loss: 0.8747467616815203, train_acc: 85.0192779530319. val_loss: 0.8575405133011095, val_acc: 85.93662366797533
kfold: 3, epoch: 18. train_loss: 0.8727555073831114, train_acc: 85.36978618997547. val_loss: 0.8558561956935934, val_acc: 86.27313516545149
kfold: 3, epoch: 19. train_loss: 0.8687497057321361, train_acc: 85.34174553101998. val_loss: 0.8628508465306106, val_acc: 85.93662366797533
kfold: 3, epoch: 20. train_loss: 0.8662322422514582, train_acc: 85.6081317910971. val_loss: 0.8538337164128308, val_acc: 86.51149747616377
kfold: 3, epoch: 21. train_loss: 0.8590547118686774, train_acc: 85.81843673326323. val_loss: 0.8485083868017111, val_acc: 86.74985978687606
kfold: 3, epoch: 22. train_loss: 0.8608426636109973, train_acc: 85.91657903960743. val_loss: 0.8520170085365997, val_acc: 86.58160403813797
kfold: 3, epoch: 23. train_loss: 0.8535487306692675, train_acc: 86.1689449702068. val_loss: 0.8511991115963512, val_acc: 86.39932697700505
kfold: 3, epoch: 24. train_loss: 0.850807458964164, train_acc: 86.08482299334034. val_loss: 0.853880289691446, val_acc: 86.1048794167134
kfold: 3, epoch: 25. train_loss: 0.8492367101891694, train_acc: 86.47038205397827. val_loss: 0.851579360029088, val_acc: 86.73583847448121