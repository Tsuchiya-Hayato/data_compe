filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b4, lr: 1e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 4, kfold: 3, epoch: 25, weght_decay: 1e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.139359964541485, train_acc: 65.11497476163768. val_loss: 0.9375215254623793, val_acc: 76.29328473293144
kfold: 1, epoch: 2. train_loss: 0.969728528400251, train_acc: 74.36904094223219. val_loss: 0.8553091546378595, val_acc: 80.54114678255993
kfold: 1, epoch: 3. train_loss: 0.9139982284251987, train_acc: 77.04711160964666. val_loss: 0.7989561186410119, val_acc: 83.16276461516894
kfold: 1, epoch: 4. train_loss: 0.8799550727101704, train_acc: 78.90493550196298. val_loss: 0.7804317578105381, val_acc: 84.42450581802888
kfold: 1, epoch: 5. train_loss: 0.8577544813034444, train_acc: 80.3771733034212. val_loss: 0.7680618913150956, val_acc: 85.27968596663395
kfold: 1, epoch: 6. train_loss: 0.8291357236669362, train_acc: 81.60403813796971. val_loss: 0.7643199720891869, val_acc: 85.54605355390439
kfold: 1, epoch: 7. train_loss: 0.8162056590340074, train_acc: 82.41026360067302. val_loss: 0.7410749676950577, val_acc: 86.20496284873126
kfold: 1, epoch: 8. train_loss: 0.8025269392445324, train_acc: 83.18844643858665. val_loss: 0.7410825122932949, val_acc: 86.58348520958923
kfold: 1, epoch: 9. train_loss: 0.7910846177273364, train_acc: 83.58104318564217. val_loss: 0.7391223462774614, val_acc: 86.28907892892191
kfold: 1, epoch: 10. train_loss: 0.7857394860707436, train_acc: 83.98766124509254. val_loss: 0.7363117793783746, val_acc: 86.12084676854059
kfold: 1, epoch: 11. train_loss: 0.7795993805733946, train_acc: 84.28210880538418. val_loss: 0.7321365312109346, val_acc: 86.10682742184214
kfold: 1, epoch: 12. train_loss: 0.7690218412852728, train_acc: 84.57655636567583. val_loss: 0.7276124920144744, val_acc: 87.01808495724099
kfold: 1, epoch: 13. train_loss: 0.7613077103857638, train_acc: 84.96915311273135. val_loss: 0.7363316836545553, val_acc: 86.5414271694939
kfold: 1, epoch: 14. train_loss: 0.7510079875947783, train_acc: 85.65619742007851. val_loss: 0.7309208693559127, val_acc: 86.79377541006589
kfold: 1, epoch: 15. train_loss: 0.7471027809936414, train_acc: 86.16096466629277. val_loss: 0.7331528244999492, val_acc: 86.62554324968457
kfold: 1, epoch: 16. train_loss: 0.7411596283809696, train_acc: 86.11890072910825. val_loss: 0.7432427915322674, val_acc: 86.63956259638302
kfold: 1, epoch: 17. train_loss: 0.7402338843063497, train_acc: 86.46242288278182. val_loss: 0.7468621729468017, val_acc: 86.75171736997056
kfold: 1, epoch: 18. train_loss: 0.7304368847819172, train_acc: 86.49747616376892. val_loss: 0.7322839849164935, val_acc: 87.13023973082855
kfold: 1, epoch: 19. train_loss: 0.731714205374493, train_acc: 86.67274256870444. val_loss: 0.7400098326093948, val_acc: 86.84985279685966
kfold: 1, epoch: 20. train_loss: 0.7231142007679466, train_acc: 86.96017947279866. val_loss: 0.7316810007420088, val_acc: 87.08818169073321
kfold: 1, epoch: 21. train_loss: 0.722401934397468, train_acc: 86.92512619181156. val_loss: 0.736578428407822, val_acc: 87.2143558110192
kfold: 1, epoch: 22. train_loss: 0.7211230535789347, train_acc: 87.04430734716769. val_loss: 0.7527649791351616, val_acc: 87.08818169073321
kfold: 1, epoch: 23. train_loss: 0.7170009867769243, train_acc: 87.2546270330903. val_loss: 0.7318823585963302, val_acc: 87.42464601149587
kfold: 1, epoch: 24. train_loss: 0.7148454834989665, train_acc: 87.41587212563095. val_loss: 0.7346092879839008, val_acc: 87.42464601149587
kfold: 1, epoch: 25. train_loss: 0.7098004134080415, train_acc: 87.5701065619742. val_loss: 0.7312323996137343, val_acc: 87.49474274498809
kfold: 2, epoch: 1. train_loss: 1.1353174210229708, train_acc: 66.12688398177357. val_loss: 0.9558265500702486, val_acc: 76.23387549074593
kfold: 2, epoch: 2. train_loss: 0.9667970521262222, train_acc: 74.39887837364178. val_loss: 0.832976900187357, val_acc: 81.92652832305103
kfold: 2, epoch: 3. train_loss: 0.9231306790286231, train_acc: 76.90150718541885. val_loss: 0.7841896427125657, val_acc: 83.81940549635446
kfold: 2, epoch: 4. train_loss: 0.8888814606885801, train_acc: 78.86435331230284. val_loss: 0.7709185786950609, val_acc: 84.8429613011778
kfold: 2, epoch: 5. train_loss: 0.8633622324764144, train_acc: 80.16824395373291. val_loss: 0.760916898508655, val_acc: 85.57206954570948
kfold: 2, epoch: 6. train_loss: 0.8414613888699499, train_acc: 81.27584998247458. val_loss: 0.7453535811257911, val_acc: 86.35726303982052
kfold: 2, epoch: 7. train_loss: 0.8226782840976603, train_acc: 82.4465474938661. val_loss: 0.7387544617884224, val_acc: 86.41334828939989
kfold: 2, epoch: 8. train_loss: 0.8114736533930297, train_acc: 82.74097441289871. val_loss: 0.7361816308234959, val_acc: 86.89007291082446
kfold: 2, epoch: 9. train_loss: 0.7991231688605592, train_acc: 83.15457413249212. val_loss: 0.7278452894858811, val_acc: 87.70330902972518
kfold: 2, epoch: 10. train_loss: 0.786769782106583, train_acc: 83.91167192429022. val_loss: 0.7233033632703932, val_acc: 87.73135165451487
kfold: 2, epoch: 11. train_loss: 0.7792703199526961, train_acc: 84.44444444444444. val_loss: 0.7098511541685361, val_acc: 88.09590577678071
kfold: 2, epoch: 12. train_loss: 0.7733311476428736, train_acc: 84.56361724500526. val_loss: 0.7129787447843001, val_acc: 87.78743690409422
kfold: 2, epoch: 13. train_loss: 0.7669659538164773, train_acc: 84.90010515247108. val_loss: 0.7140841617453185, val_acc: 87.85754346606842
kfold: 2, epoch: 14. train_loss: 0.7667168325357889, train_acc: 84.8229933403435. val_loss: 0.7159971002775568, val_acc: 87.92765002804262
kfold: 2, epoch: 15. train_loss: 0.7581767419372448, train_acc: 85.18752190676481. val_loss: 0.7098156498244688, val_acc: 87.85754346606842
kfold: 2, epoch: 16. train_loss: 0.7537815686965944, train_acc: 85.55205047318611. val_loss: 0.7134614722720706, val_acc: 88.33426808749299
kfold: 2, epoch: 17. train_loss: 0.7442715922038964, train_acc: 86.2180161233789. val_loss: 0.7137121615855131, val_acc: 88.12394840157039
kfold: 2, epoch: 18. train_loss: 0.7401052296395592, train_acc: 86.06379249912374. val_loss: 0.7065080733561342, val_acc: 88.34828939988783
kfold: 2, epoch: 19. train_loss: 0.7388955452694824, train_acc: 86.13389414651245. val_loss: 0.7124294074345223, val_acc: 88.06786315199102
kfold: 2, epoch: 20. train_loss: 0.7339578130798645, train_acc: 86.35821941815632. val_loss: 0.7151567284571476, val_acc: 88.13796971396523
kfold: 2, epoch: 21. train_loss: 0.7304092456989005, train_acc: 86.51945320715036. val_loss: 0.7193908804397668, val_acc: 88.20807627593943
kfold: 2, epoch: 22. train_loss: 0.7288694896716713, train_acc: 86.4633718892394. val_loss: 0.7107710293585574, val_acc: 88.44643858665171
kfold: 2, epoch: 23. train_loss: 0.724862707982987, train_acc: 86.70171749036102. val_loss: 0.721481525540285, val_acc: 88.05384183959619
kfold: 2, epoch: 24. train_loss: 0.7172571588103965, train_acc: 87.20644935155975. val_loss: 0.7166395766208229, val_acc: 88.37633202467751
kfold: 2, epoch: 25. train_loss: 0.7235076199451481, train_acc: 86.7788293024886. val_loss: 0.7146692390329572, val_acc: 88.29220415030846
kfold: 3, epoch: 1. train_loss: 1.1439109996048917, train_acc: 65.14546091833158. val_loss: 0.965897896737111, val_acc: 74.83174425126192
kfold: 3, epoch: 2. train_loss: 0.9735378341444875, train_acc: 74.20259376095338. val_loss: 0.8292325203397337, val_acc: 81.57599551318003
kfold: 3, epoch: 3. train_loss: 0.9195127509741146, train_acc: 77.04171048019629. val_loss: 0.7865759704932695, val_acc: 83.67919237240606
kfold: 3, epoch: 4. train_loss: 0.890088426254696, train_acc: 78.61198738170347. val_loss: 0.7676219270260095, val_acc: 85.27762198541784
kfold: 3, epoch: 5. train_loss: 0.8555910243585659, train_acc: 80.61689449702068. val_loss: 0.7603321341036146, val_acc: 85.83847448121143
kfold: 3, epoch: 6. train_loss: 0.8363918214409767, train_acc: 81.21976866456362. val_loss: 0.76145656673479, val_acc: 85.47392035894559
kfold: 3, epoch: 7. train_loss: 0.8112284735133409, train_acc: 82.97230984928146. val_loss: 0.7458367625515714, val_acc: 86.45541222658441
kfold: 3, epoch: 8. train_loss: 0.8062705140856424, train_acc: 82.55169996494918. val_loss: 0.7585003951327292, val_acc: 85.58609085810431
kfold: 3, epoch: 9. train_loss: 0.7939162039108426, train_acc: 83.70837714686296. val_loss: 0.7390330920744932, val_acc: 86.76388109927089
kfold: 3, epoch: 10. train_loss: 0.7875929243062637, train_acc: 83.65930599369085. val_loss: 0.7325489871032573, val_acc: 86.66573191250701
kfold: 3, epoch: 11. train_loss: 0.7803835616764783, train_acc: 84.34630213810024. val_loss: 0.738365716099806, val_acc: 86.46943353897925
kfold: 3, epoch: 12. train_loss: 0.7714614423176204, train_acc: 84.80897301086576. val_loss: 0.7370136949832828, val_acc: 86.62366797532249
kfold: 3, epoch: 13. train_loss: 0.7602699416122217, train_acc: 85.32071503680336. val_loss: 0.7230756355849666, val_acc: 87.3247335950645
kfold: 3, epoch: 14. train_loss: 0.7565246452077417, train_acc: 85.25762355415353. val_loss: 0.7324560405796188, val_acc: 87.3948401570387
kfold: 3, epoch: 15. train_loss: 0.7490749653561429, train_acc: 86.10585348755696. val_loss: 0.7283860985743351, val_acc: 87.35277621985418
kfold: 3, epoch: 16. train_loss: 0.7453870967736523, train_acc: 86.26007711181212. val_loss: 0.735852813610386, val_acc: 87.22658440830061
kfold: 3, epoch: 17. train_loss: 0.7372364267886504, train_acc: 86.2180161233789. val_loss: 0.7523364198221227, val_acc: 86.56758272574314
kfold: 3, epoch: 18. train_loss: 0.7404307924484652, train_acc: 86.29512793550649. val_loss: 0.7363518313684961, val_acc: 87.26864834548513
kfold: 3, epoch: 19. train_loss: 0.7348871097398934, train_acc: 86.39327024185069. val_loss: 0.7354601169494986, val_acc: 87.70330902972518
kfold: 3, epoch: 20. train_loss: 0.7294158872967846, train_acc: 86.66666666666667. val_loss: 0.7387190584011848, val_acc: 87.24060572069546
kfold: 3, epoch: 21. train_loss: 0.7246510278436694, train_acc: 87.08727655099895. val_loss: 0.7497007060405316, val_acc: 87.35277621985418
kfold: 3, epoch: 22. train_loss: 0.7222425457740785, train_acc: 87.50788643533123. val_loss: 0.7351182502471391, val_acc: 87.8855860908581
kfold: 3, epoch: 23. train_loss: 0.7188933331290647, train_acc: 87.37469330529268. val_loss: 0.7425311080070941, val_acc: 87.4649467190129
kfold: 3, epoch: 24. train_loss: 0.7138710927405142, train_acc: 87.45180511742026. val_loss: 0.7402356544105243, val_acc: 87.47896803140775
kfold: 3, epoch: 25. train_loss: 0.7069795133855652, train_acc: 87.98457763757449. val_loss: 0.7317386030883383, val_acc: 87.77341559169939