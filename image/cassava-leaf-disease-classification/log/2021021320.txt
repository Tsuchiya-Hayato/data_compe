filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b5, lr: 5e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 2, kfold: 3, epoch: 25, weght_decay: 5e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.071476386869415, train_acc: 69.23022994952328. val_loss: 0.9293724752237792, val_acc: 76.5035749334081
kfold: 1, epoch: 2. train_loss: 0.8765044788497255, train_acc: 79.03813796971397. val_loss: 1.0183365407998, val_acc: 78.1298191504276
kfold: 1, epoch: 3. train_loss: 0.8239809299954456, train_acc: 82.11581604038138. val_loss: 0.8789644599094557, val_acc: 81.35426889106968
kfold: 1, epoch: 4. train_loss: 0.7972047256407147, train_acc: 83.14638250140213. val_loss: 0.8556012552694209, val_acc: 83.03659049488294
kfold: 1, epoch: 5. train_loss: 0.7734373425892479, train_acc: 84.31716208637128. val_loss: 0.822550742999492, val_acc: 84.52264124491799
kfold: 1, epoch: 6. train_loss: 0.7701459672726143, train_acc: 84.45737521031968. val_loss: 0.7872364141374935, val_acc: 86.21898219542969
kfold: 1, epoch: 7. train_loss: 0.7532280705915163, train_acc: 85.39680314077398. val_loss: 0.7786407576978859, val_acc: 86.47133043600168
kfold: 1, epoch: 8. train_loss: 0.7461365909763287, train_acc: 85.76836791923724. val_loss: 0.7751481251236033, val_acc: 86.68162063647834
kfold: 1, epoch: 9. train_loss: 0.7369097671186864, train_acc: 86.2100392596747. val_loss: 0.8001573160228056, val_acc: 85.08341511285575
kfold: 1, epoch: 10. train_loss: 0.7328574891905737, train_acc: 86.60263600673024. val_loss: 0.7573654223614659, val_acc: 86.3171176223188
kfold: 1, epoch: 11. train_loss: 0.7339385179400578, train_acc: 86.39231632080762. val_loss: 0.854547730548595, val_acc: 85.61615028739661
kfold: 1, epoch: 12. train_loss: 0.7278436344415702, train_acc: 86.70779584969154. val_loss: 0.7907088130236274, val_acc: 85.6441889807935
kfold: 1, epoch: 13. train_loss: 0.7194837638988163, train_acc: 87.05832865956253. val_loss: 0.7501962559711776, val_acc: 87.36856862470209
kfold: 1, epoch: 14. train_loss: 0.7130431372649336, train_acc: 87.29669097027482. val_loss: 0.7578566294692964, val_acc: 86.51338847609702
kfold: 1, epoch: 15. train_loss: 0.7086163675031232, train_acc: 87.92765002804262. val_loss: 0.7914184552048447, val_acc: 86.77975606336744
kfold: 1, epoch: 16. train_loss: 0.707333780954677, train_acc: 87.76640493550197. val_loss: 0.7807566790661626, val_acc: 87.03210430393943
kfold: 1, epoch: 17. train_loss: 0.7097582275228627, train_acc: 87.59113853056647. val_loss: 0.789280240939116, val_acc: 86.63956259638302
kfold: 1, epoch: 18. train_loss: 0.6982890460065624, train_acc: 87.93466068424004. val_loss: 0.9179776002955029, val_acc: 85.46193747371372
kfold: 1, epoch: 19. train_loss: 0.6953589980163002, train_acc: 88.27117218171621. val_loss: 0.805189440597631, val_acc: 87.48072339828964
kfold: 1, epoch: 20. train_loss: 0.6948012842207028, train_acc: 88.33426808749299. val_loss: 0.7989376604406647, val_acc: 86.4152530492079
kfold: 1, epoch: 21. train_loss: 0.6935839964786207, train_acc: 88.44643858665171. val_loss: 0.7639696434963174, val_acc: 87.64895555867096
kfold: 1, epoch: 22. train_loss: 0.6877594618643861, train_acc: 88.66376892877173. val_loss: 0.9054746798333381, val_acc: 86.14888546193747
kfold: 1, epoch: 23. train_loss: 0.6852136109603033, train_acc: 88.97924845765564. val_loss: 0.7982503020833579, val_acc: 87.56483947848031
kfold: 1, epoch: 24. train_loss: 0.6854276128042233, train_acc: 89.23864273696017. val_loss: 0.8942320800759995, val_acc: 85.02733772606197
kfold: 1, epoch: 25. train_loss: 0.6836277569779438, train_acc: 88.73387549074593. val_loss: 0.8377121658695489, val_acc: 86.40123370250946
kfold: 2, epoch: 1. train_loss: 1.07903124892359, train_acc: 68.93094987732212. val_loss: 0.9508849585317054, val_acc: 76.4301738642737
kfold: 2, epoch: 2. train_loss: 0.8837428360396141, train_acc: 78.64002804065896. val_loss: 0.8782899539355675, val_acc: 82.44531688166012
kfold: 2, epoch: 3. train_loss: 0.8256391269636241, train_acc: 81.66140904311251. val_loss: 0.7924355797415293, val_acc: 85.13740886146944
kfold: 2, epoch: 4. train_loss: 0.7988136195040143, train_acc: 83.1335436382755. val_loss: 0.8103713669839764, val_acc: 85.09534492428492
kfold: 2, epoch: 5. train_loss: 0.7825756667331477, train_acc: 83.82053978268489. val_loss: 0.8517677871968996, val_acc: 83.21648906337633
kfold: 2, epoch: 6. train_loss: 0.771755320894155, train_acc: 84.09393620750087. val_loss: 0.7505858680604217, val_acc: 86.45541222658441
kfold: 2, epoch: 7. train_loss: 0.7615226885262335, train_acc: 84.75289169295479. val_loss: 0.7539378417738355, val_acc: 86.1048794167134
kfold: 2, epoch: 8. train_loss: 0.7517690570829427, train_acc: 85.2646337188924. val_loss: 0.7268962519210975, val_acc: 86.98822209758833
kfold: 2, epoch: 9. train_loss: 0.7396466866643235, train_acc: 86.35120925341745. val_loss: 0.7237487357450347, val_acc: 87.7453729669097
kfold: 2, epoch: 10. train_loss: 0.7385750361299775, train_acc: 86.09183315807921. val_loss: 0.7528260577965238, val_acc: 86.72181716208637
kfold: 2, epoch: 11. train_loss: 0.7340993791563756, train_acc: 86.60357518401682. val_loss: 0.7645769651458962, val_acc: 85.8244531688166
kfold: 2, epoch: 12. train_loss: 0.7286784659716519, train_acc: 86.6596565019278. val_loss: 0.7344042889134508, val_acc: 88.05384183959619
kfold: 2, epoch: 13. train_loss: 0.7227689903890135, train_acc: 87.01016473887137. val_loss: 0.7432412490942341, val_acc: 87.49298934380258
kfold: 2, epoch: 14. train_loss: 0.7185196822210698, train_acc: 87.2204696810375. val_loss: 0.7305936710559044, val_acc: 87.73135165451487
kfold: 2, epoch: 15. train_loss: 0.716342617903721, train_acc: 87.25552050473186. val_loss: 0.7458528620987479, val_acc: 87.68928771733034
kfold: 2, epoch: 16. train_loss: 0.7124500409025607, train_acc: 87.35366281107606. val_loss: 0.7094432516122761, val_acc: 88.54458777341559
kfold: 2, epoch: 17. train_loss: 0.7080703729811414, train_acc: 87.65509989484752. val_loss: 0.7526557898912547, val_acc: 86.76388109927089
kfold: 2, epoch: 18. train_loss: 0.7051981678646443, train_acc: 88.00560813179109. val_loss: 0.7303003219243054, val_acc: 87.95569265283231
kfold: 2, epoch: 19. train_loss: 0.7016318805811366, train_acc: 88.01962846126884. val_loss: 0.7432301753251257, val_acc: 87.64722378014582
kfold: 2, epoch: 20. train_loss: 0.7021572128111662, train_acc: 87.90045566070803. val_loss: 0.7383451262803407, val_acc: 87.10039259674706
kfold: 2, epoch: 21. train_loss: 0.6982857378096028, train_acc: 88.08973010865755. val_loss: 0.7179623715541902, val_acc: 88.01177790241167
kfold: 2, epoch: 22. train_loss: 0.6936002166336722, train_acc: 88.41920785138451. val_loss: 0.7196604302273129, val_acc: 88.16601233875491
kfold: 2, epoch: 23. train_loss: 0.6917970596147958, train_acc: 88.5173501577287. val_loss: 0.7569186701259115, val_acc: 86.39932697700505
kfold: 2, epoch: 24. train_loss: 0.6839973949147661, train_acc: 88.98002103049421. val_loss: 0.7467387405945488, val_acc: 87.45092540661805
kfold: 2, epoch: 25. train_loss: 0.6859238024941504, train_acc: 88.94497020679987. val_loss: 0.7865594096536123, val_acc: 86.96017947279866
kfold: 3, epoch: 1. train_loss: 1.0723015674656644, train_acc: 69.42166140904311. val_loss: 0.861905997413233, val_acc: 81.29556926528323
kfold: 3, epoch: 2. train_loss: 0.8707415880393835, train_acc: 79.50928846827901. val_loss: 0.9033295617251335, val_acc: 81.02916432978127
kfold: 3, epoch: 3. train_loss: 0.8167276252465882, train_acc: 82.29933403434981. val_loss: 0.8284653159870703, val_acc: 84.66068424004487
kfold: 3, epoch: 4. train_loss: 0.7993885983796403, train_acc: 83.12653347353663. val_loss: 0.8433640587550498, val_acc: 84.00168255748738
kfold: 3, epoch: 5. train_loss: 0.778235792399255, train_acc: 84.10795653697862. val_loss: 0.8055919441141176, val_acc: 85.09534492428492
kfold: 3, epoch: 6. train_loss: 0.7617216317546363, train_acc: 84.94917630564318. val_loss: 0.7817427239355182, val_acc: 86.62366797532249
kfold: 3, epoch: 7. train_loss: 0.7533651684187211, train_acc: 85.48895899053628. val_loss: 0.8017957558206675, val_acc: 85.38979248457656
kfold: 3, epoch: 8. train_loss: 0.7456511042779214, train_acc: 85.73431475639677. val_loss: 0.7445246846286085, val_acc: 86.89007291082446
kfold: 3, epoch: 9. train_loss: 0.7438790303626636, train_acc: 85.93760953382404. val_loss: 0.7551774366795849, val_acc: 86.97420078519349
kfold: 3, epoch: 10. train_loss: 0.7388522298618803, train_acc: 86.22502628811777. val_loss: 0.7531773371938502, val_acc: 86.44139091418957
kfold: 3, epoch: 11. train_loss: 0.7311495165620665, train_acc: 86.68769716088327. val_loss: 0.7651992578287172, val_acc: 86.97420078519349
kfold: 3, epoch: 12. train_loss: 0.7205076477988211, train_acc: 87.12933753943217. val_loss: 0.7531367775618997, val_acc: 86.90409422321929
kfold: 3, epoch: 13. train_loss: 0.7192856417194616, train_acc: 87.24851033999299. val_loss: 0.7632332944295009, val_acc: 87.24060572069546
kfold: 3, epoch: 14. train_loss: 0.7140188772932737, train_acc: 87.35366281107606. val_loss: 0.8276244504309342, val_acc: 84.66068424004487
kfold: 3, epoch: 15. train_loss: 0.7116830770537877, train_acc: 87.44479495268139. val_loss: 0.7793065859271245, val_acc: 87.08637128435221