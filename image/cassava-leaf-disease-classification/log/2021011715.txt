model: efficientnet-b3, lr: 1e-05, weights: tensor([19.6000,  9.7000,  8.9000,  1.6000,  8.3000]). batchsize: 8, kfold: 3, epoch: 25, RandomHorizontalFlip:(True,),CenterCrop: True 

kfold: 1, epoch: 1. train_loss: 1.3845688563615368, train_acc: 56.14834548513741. val_loss: 1.112237126169718, val_acc: 66.94238048506939
kfold: 1, epoch: 2. train_loss: 1.046357222223175, train_acc: 68.42400448681997. val_loss: 0.8666641907474117, val_acc: 71.82111313612786
kfold: 1, epoch: 3. train_loss: 0.8984518997283445, train_acc: 73.10011217049916. val_loss: 0.788136900732536, val_acc: 74.97546614327773
kfold: 1, epoch: 4. train_loss: 0.8162111184709673, train_acc: 76.07263039820528. val_loss: 0.7352164634774886, val_acc: 77.16248422823496
kfold: 1, epoch: 5. train_loss: 0.7674846483527177, train_acc: 77.52383623107123. val_loss: 0.7368939416858915, val_acc: 77.10640684144118
kfold: 1, epoch: 6. train_loss: 0.7204163704470711, train_acc: 78.96803140773976. val_loss: 0.7098840225504652, val_acc: 78.62049628487313
kfold: 1, epoch: 7. train_loss: 0.6802313127756052, train_acc: 80.45429052159282. val_loss: 0.6898932096134921, val_acc: 79.29342492639843
kfold: 1, epoch: 8. train_loss: 0.6254827843219527, train_acc: 81.76528323051038. val_loss: 0.7094803876682046, val_acc: 78.81676713865134
kfold: 1, epoch: 9. train_loss: 0.598131394106738, train_acc: 82.45933819405496. val_loss: 0.7064533831944246, val_acc: 78.56441889807935
kfold: 1, epoch: 10. train_loss: 0.5755737560497731, train_acc: 83.05524397083568. val_loss: 0.6966157994262306, val_acc: 79.15323145941399
kfold: 1, epoch: 11. train_loss: 0.5259546026591665, train_acc: 83.99467190128996. val_loss: 0.7393852701439886, val_acc: 79.27940557969998
kfold: 1, epoch: 12. train_loss: 0.49329458858840797, train_acc: 85.30566461020751. val_loss: 0.7392481203637851, val_acc: 80.51310808916304
kfold: 1, epoch: 13. train_loss: 0.46397248160802307, train_acc: 85.90157038698823. val_loss: 0.7631352946732294, val_acc: 79.55979251366887
kfold: 1, epoch: 14. train_loss: 0.43015031730082354, train_acc: 86.72882781828379. val_loss: 0.7719743225949027, val_acc: 79.93831487452685
kfold: 1, epoch: 15. train_loss: 0.40266128590166467, train_acc: 87.50701065619742. val_loss: 0.7976734062475089, val_acc: 80.51310808916304
kfold: 1, epoch: 16. train_loss: 0.3674691058993047, train_acc: 88.50252383623108. val_loss: 0.8082831227116186, val_acc: 79.54577316697042
kfold: 1, epoch: 17. train_loss: 0.3364890870746315, train_acc: 89.05636567582725. val_loss: 0.8448661791918708, val_acc: 79.82616010093929
kfold: 1, epoch: 18. train_loss: 0.3190146044932987, train_acc: 89.69433538979249. val_loss: 0.8832709420270876, val_acc: 79.5037151268751
kfold: 1, epoch: 19. train_loss: 0.2983595019392356, train_acc: 90.40241166573192. val_loss: 0.9006048634193102, val_acc: 80.37291462217861
kfold: 1, epoch: 20. train_loss: 0.27190819732657834, train_acc: 91.00532809871004. val_loss: 0.9213282117633683, val_acc: 80.44301135567082
kfold: 1, epoch: 21. train_loss: 0.24568762522675536, train_acc: 91.53112731351655. val_loss: 0.9585529065653348, val_acc: 80.35889527548017
kfold: 1, epoch: 22. train_loss: 0.24083652202091146, train_acc: 91.8956814357824. val_loss: 0.9944857107417976, val_acc: 80.34487592878172
kfold: 1, epoch: 23. train_loss: 0.22512147170389663, train_acc: 92.31632080762759. val_loss: 0.9724656130226889, val_acc: 79.82616010093929
kfold: 1, epoch: 24. train_loss: 0.2033426357414657, train_acc: 93.27678070667415. val_loss: 1.032037471489581, val_acc: 79.85419879433618
kfold: 1, epoch: 25. train_loss: 0.18390691552945296, train_acc: 93.28379136287157. val_loss: 1.0634249059889036, val_acc: 79.5738118603673