filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b5, lr: 5e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 2, kfold: 3, epoch: 25, weght_decay: 5e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.0696505102518563, train_acc: 69.49663488502524. val_loss: 0.8649251579336001, val_acc: 81.11593999719614
kfold: 1, epoch: 2. train_loss: 0.9171446029700661, train_acc: 77.33454851374088. val_loss: 0.8742332044171124, val_acc: 81.25613346418056
kfold: 1, epoch: 3. train_loss: 0.904485190417816, train_acc: 77.63600673022995. val_loss: 0.8688477189693927, val_acc: 81.27015281087901
kfold: 1, epoch: 4. train_loss: 0.9099398991589257, train_acc: 77.77621985417835. val_loss: 0.8884750283546464, val_acc: 80.45703070236927
kfold: 1, epoch: 5. train_loss: 0.9087197942950721, train_acc: 77.7271452607964. val_loss: 0.8727958319081557, val_acc: 80.93368849011637
kfold: 1, epoch: 6. train_loss: 0.9143481584191656, train_acc: 77.36259113853056. val_loss: 0.8920743106826534, val_acc: 80.52712743586149
kfold: 1, epoch: 7. train_loss: 0.9111496411426911, train_acc: 77.04010095344924. val_loss: 0.8768325462908112, val_acc: 81.01780457030702
kfold: 1, epoch: 8. train_loss: 0.9127298597616221, train_acc: 77.70611329220415. val_loss: 0.8868889189966259, val_acc: 80.6252628627506
kfold: 1, epoch: 9. train_loss: 0.9114721234066728, train_acc: 77.46074032529445. val_loss: 0.8990151607625987, val_acc: 79.96635356792373
kfold: 1, epoch: 10. train_loss: 0.9165071156325129, train_acc: 77.4116657319125. val_loss: 0.8939505515226904, val_acc: 80.13458572830505
kfold: 1, epoch: 11. train_loss: 0.9129072704795901, train_acc: 77.3766124509254. val_loss: 0.8767572471765968, val_acc: 81.0738819571008
kfold: 1, epoch: 12. train_loss: 0.9134866423023195, train_acc: 76.83679192372406. val_loss: 0.8815050187701099, val_acc: 81.03182391700547
kfold: 1, epoch: 13. train_loss: 0.9085698834026522, train_acc: 77.65002804262478. val_loss: 0.8942386642587195, val_acc: 79.85419879433618
kfold: 1, epoch: 14. train_loss: 0.9132601614337388, train_acc: 77.56590016825575. val_loss: 0.8749545605068351, val_acc: 81.17201738398991
kfold: 1, epoch: 15. train_loss: 0.9130225577425636, train_acc: 77.42568704430735. val_loss: 0.8880819552897872, val_acc: 80.68134024954438
kfold: 1, epoch: 16. train_loss: 0.9123914726767992, train_acc: 77.45372966909703. val_loss: 0.881578661169296, val_acc: 80.79349502313192
kfold: 1, epoch: 17. train_loss: 0.9125841961347247, train_acc: 77.61497476163768. val_loss: 0.9098496497395929, val_acc: 79.36352165989065
kfold: 1, epoch: 18. train_loss: 0.9088776246281534, train_acc: 77.56590016825575. val_loss: 0.8730906648130553, val_acc: 81.24211411748213
kfold: 1, epoch: 19. train_loss: 0.9122669974146635, train_acc: 77.39764441951766. val_loss: 0.8910690855004054, val_acc: 80.45703070236927
kfold: 1, epoch: 20. train_loss: 0.9054146920588333, train_acc: 77.93746494671902. val_loss: 0.8763831700468585, val_acc: 80.86359175662415
kfold: 1, epoch: 21. train_loss: 0.9095824080667199, train_acc: 77.31351654514863. val_loss: 0.8796897561970565, val_acc: 80.8495724099257
kfold: 1, epoch: 22. train_loss: 0.9077511932021838, train_acc: 77.81828379136287. val_loss: 0.8841751089509141, val_acc: 80.7233982896397
kfold: 1, epoch: 23. train_loss: 0.9080924492912285, train_acc: 77.46074032529445. val_loss: 0.8838444530529437, val_acc: 80.77947567643348
kfold: 1, epoch: 24. train_loss: 0.9125601026661531, train_acc: 77.34155916993831. val_loss: 0.8803362308311836, val_acc: 80.98976587691014
kfold: 1, epoch: 25. train_loss: 0.9117136728091649, train_acc: 77.47476163768928. val_loss: 0.8760468372701763, val_acc: 81.15799803729146
kfold: 2, epoch: 1. train_loss: 1.0698991343890836, train_acc: 69.67402733964248. val_loss: 0.9159769290662253, val_acc: 79.41671340437465
kfold: 2, epoch: 2. train_loss: 0.9167305421489963, train_acc: 76.67718191377497. val_loss: 0.8876892305613902, val_acc: 80.42624789680315
kfold: 2, epoch: 3. train_loss: 0.9064876431212525, train_acc: 77.14686295127936. val_loss: 0.919007472940462, val_acc: 79.01009534492428
kfold: 2, epoch: 4. train_loss: 0.9038203010489892, train_acc: 77.56046267087277. val_loss: 0.9285254775976373, val_acc: 78.7016264722378
kfold: 2, epoch: 5. train_loss: 0.9079648822516758, train_acc: 77.15387311601823. val_loss: 0.9265679522253994, val_acc: 78.74369040942233
kfold: 2, epoch: 6. train_loss: 0.9046055110552427, train_acc: 77.84086926042762. val_loss: 0.9056791602077607, val_acc: 79.64105440269209
kfold: 2, epoch: 7. train_loss: 0.9082582597225826, train_acc: 77.49036102348406. val_loss: 0.944220329109899, val_acc: 78.02860347728547
kfold: 2, epoch: 8. train_loss: 0.9041148604433182, train_acc: 77.58149316508938. val_loss: 0.8920214002512173, val_acc: 80.17386427369601
kfold: 2, epoch: 9. train_loss: 0.9102132258735431, train_acc: 77.25902558710129. val_loss: 0.909289451275257, val_acc: 79.59899046550757
kfold: 2, epoch: 10. train_loss: 0.9093593095690242, train_acc: 77.18892393971258. val_loss: 0.9304435791607593, val_acc: 78.53337072349971
kfold: 2, epoch: 11. train_loss: 0.9021130830036981, train_acc: 78.00210304942166. val_loss: 0.9508177709342119, val_acc: 77.70611329220415
kfold: 2, epoch: 12. train_loss: 0.9015632383154566, train_acc: 77.59551349456713. val_loss: 0.8918004918319083, val_acc: 80.24397083567023