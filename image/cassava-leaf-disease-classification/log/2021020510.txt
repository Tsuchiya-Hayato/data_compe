filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b4, lr: 1e-05, weights: tensor([1.5000, 1.0000, 1.0000, 1.0000, 1.0000]). batchsize: 4, kfold: 3, epoch: 25, weght_decay: 5e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.2136028200571816, train_acc: 65.33931575995513. val_loss: 1.010959812076637, val_acc: 77.16248422823496
kfold: 1, epoch: 2. train_loss: 1.041542467245946, train_acc: 74.53729669097028. val_loss: 0.9192765005634504, val_acc: 80.59722416935371
kfold: 1, epoch: 3. train_loss: 0.9813904722654211, train_acc: 77.20835670218733. val_loss: 0.859789700318345, val_acc: 83.2468806953596
kfold: 1, epoch: 4. train_loss: 0.9446023972396829, train_acc: 78.99607403252945. val_loss: 0.8415398220176654, val_acc: 84.07402215056779
kfold: 1, epoch: 5. train_loss: 0.9214264648186645, train_acc: 80.38418395961862. val_loss: 0.8289603193044128, val_acc: 84.92920229917286
kfold: 1, epoch: 6. train_loss: 0.8926270372133475, train_acc: 81.64610207515423. val_loss: 0.8241305660306071, val_acc: 85.47595682041216
kfold: 1, epoch: 7. train_loss: 0.879142633764114, train_acc: 82.4383062254627. val_loss: 0.8004904217650538, val_acc: 86.03673068834992
kfold: 1, epoch: 8. train_loss: 0.8651998801907995, train_acc: 82.97812675266405. val_loss: 0.8009210324140408, val_acc: 86.58348520958923
kfold: 1, epoch: 9. train_loss: 0.8535120556244874, train_acc: 83.60207515423444. val_loss: 0.7981628529359942, val_acc: 86.37319500911258
kfold: 1, epoch: 10. train_loss: 0.8476418476390892, train_acc: 83.9385866517106. val_loss: 0.7959274840395012, val_acc: 85.99467264825459
kfold: 1, epoch: 11. train_loss: 0.8410563938783516, train_acc: 84.26808749298934. val_loss: 0.7906156694808884, val_acc: 85.99467264825459
kfold: 1, epoch: 12. train_loss: 0.8303306574943156, train_acc: 84.66068424004487. val_loss: 0.787694870156023, val_acc: 86.96200757044721
kfold: 1, epoch: 13. train_loss: 0.8220016443522138, train_acc: 85.0182277061133. val_loss: 0.7949505356796119, val_acc: 86.4152530492079
kfold: 1, epoch: 14. train_loss: 0.8113864435617401, train_acc: 85.67722938867078. val_loss: 0.788329882605728, val_acc: 86.84985279685966
kfold: 1, epoch: 15. train_loss: 0.8076317612200858, train_acc: 85.94363432417275. val_loss: 0.7900731213424238, val_acc: 86.63956259638302
kfold: 1, epoch: 16. train_loss: 0.8007695566417793, train_acc: 86.15395401009535. val_loss: 0.801134462079927, val_acc: 86.5414271694939
kfold: 1, epoch: 17. train_loss: 0.7996406339890356, train_acc: 86.27313516545149. val_loss: 0.8050036403630346, val_acc: 86.42927239590635
kfold: 1, epoch: 18. train_loss: 0.7894987824654486, train_acc: 86.3502523836231. val_loss: 0.7898302919527875, val_acc: 86.9900462638441
kfold: 1, epoch: 19. train_loss: 0.7911249308424322, train_acc: 86.83398766124509. val_loss: 0.7970958718604036, val_acc: 86.68162063647834
kfold: 1, epoch: 20. train_loss: 0.7813237332689315, train_acc: 86.85501962983736. val_loss: 0.7894281953105478, val_acc: 86.94798822374878
kfold: 1, epoch: 21. train_loss: 0.7808529505620027, train_acc: 86.81295569265284. val_loss: 0.7917277478182797, val_acc: 87.08818169073321
kfold: 1, epoch: 22. train_loss: 0.7793532929859065, train_acc: 87.01626472237801. val_loss: 0.8090409283012553, val_acc: 87.06014299733633
kfold: 1, epoch: 23. train_loss: 0.7748227659832274, train_acc: 87.2195737521032. val_loss: 0.7899879335421618, val_acc: 87.28445254451142
kfold: 1, epoch: 24. train_loss: 0.7728269461561172, train_acc: 87.28266965787998. val_loss: 0.7911352814246186, val_acc: 87.28445254451142
kfold: 1, epoch: 25. train_loss: 0.7675176892832832, train_acc: 87.55608524957935. val_loss: 0.7878250512774749, val_acc: 87.31249123790832
kfold: 2, epoch: 1. train_loss: 1.208071600999824, train_acc: 66.17595513494567. val_loss: 1.0279514446595512, val_acc: 76.73864273696017
kfold: 2, epoch: 2. train_loss: 1.037858476467015, train_acc: 74.72835611636873. val_loss: 0.897546903544173, val_acc: 81.7722938867078
kfold: 2, epoch: 3. train_loss: 0.990650294924571, train_acc: 77.16789344549596. val_loss: 0.8451678279204377, val_acc: 83.65114974761637
kfold: 2, epoch: 4. train_loss: 0.9550186280345997, train_acc: 78.93445495969155. val_loss: 0.830568413151427, val_acc: 84.82893998878295
kfold: 2, epoch: 5. train_loss: 0.9292109993983291, train_acc: 80.26638626007711. val_loss: 0.8218836520939012, val_acc: 85.10936623667975
kfold: 2, epoch: 6. train_loss: 0.9064045274561783, train_acc: 81.08657553452507. val_loss: 0.8062240514806062, val_acc: 86.00673022994953
kfold: 2, epoch: 7. train_loss: 0.8862592818558567, train_acc: 82.30634419908868. val_loss: 0.8000050190119549, val_acc: 86.11890072910825
kfold: 2, epoch: 8. train_loss: 0.8744261780305173, train_acc: 82.74097441289871. val_loss: 0.7973697975453405, val_acc: 86.3853056646102
kfold: 2, epoch: 9. train_loss: 0.8626186308454391, train_acc: 82.90220820189275. val_loss: 0.7866616448323779, val_acc: 87.26864834548513
kfold: 2, epoch: 10. train_loss: 0.8487513452843521, train_acc: 83.84858044164038. val_loss: 0.7817367783638446, val_acc: 87.24060572069546
kfold: 2, epoch: 11. train_loss: 0.8412792543787431, train_acc: 84.33929197336137. val_loss: 0.7688270425836624, val_acc: 87.85754346606842
kfold: 2, epoch: 12. train_loss: 0.8348843172413981, train_acc: 84.55660708026639. val_loss: 0.7716835972237173, val_acc: 87.59113853056647
kfold: 2, epoch: 13. train_loss: 0.8284301353597093, train_acc: 84.85804416403785. val_loss: 0.7725388310093326, val_acc: 87.45092540661805
kfold: 2, epoch: 14. train_loss: 0.8284460030452256, train_acc: 84.78794251664914. val_loss: 0.7752507538589546, val_acc: 87.73135165451487
kfold: 2, epoch: 15. train_loss: 0.8187038829622731, train_acc: 85.09638976515949. val_loss: 0.7698822860562661, val_acc: 87.50701065619742
kfold: 2, epoch: 16. train_loss: 0.8141418943927841, train_acc: 85.34875569575885. val_loss: 0.7714230266101428, val_acc: 87.78743690409422
kfold: 2, epoch: 17. train_loss: 0.8044846920630228, train_acc: 86.02874167542937. val_loss: 0.7732072565171803, val_acc: 88.05384183959619
kfold: 2, epoch: 18. train_loss: 0.7995640531386987, train_acc: 86.09884332281808. val_loss: 0.7662853344531121, val_acc: 88.36231071228266
kfold: 2, epoch: 19. train_loss: 0.7990953972568892, train_acc: 86.06379249912374. val_loss: 0.771414380426562, val_acc: 88.22209758833426
kfold: 2, epoch: 20. train_loss: 0.7934373682675523, train_acc: 86.3371889239397. val_loss: 0.7750810871482631, val_acc: 88.01177790241167
kfold: 2, epoch: 21. train_loss: 0.7891963472846245, train_acc: 86.54048370136698. val_loss: 0.7808458347769848, val_acc: 87.8855860908581
kfold: 2, epoch: 22. train_loss: 0.7878312380299837, train_acc: 86.61058534875569. val_loss: 0.7715558630659282, val_acc: 88.30622546270331
kfold: 2, epoch: 23. train_loss: 0.7839402917021625, train_acc: 86.65264633718893. val_loss: 0.7832595874135975, val_acc: 87.89960740325294
kfold: 2, epoch: 24. train_loss: 0.7758979513961326, train_acc: 87.25552050473186. val_loss: 0.776929397129705, val_acc: 87.91362871564779
kfold: 2, epoch: 25. train_loss: 0.7822394494018469, train_acc: 86.77181913774973. val_loss: 0.7757439017964426, val_acc: 88.23611890072911
kfold: 3, epoch: 1. train_loss: 1.2182703504784287, train_acc: 65.1664914125482. val_loss: 1.0378856728468728, val_acc: 75.75715086932136
kfold: 3, epoch: 2. train_loss: 1.0445305074100104, train_acc: 74.46196985629162. val_loss: 0.8947188843185823, val_acc: 81.51991026360068
kfold: 3, epoch: 3. train_loss: 0.9880976899184197, train_acc: 77.15387311601823. val_loss: 0.8475719400489858, val_acc: 83.77734155916994
kfold: 3, epoch: 4. train_loss: 0.9556394256996046, train_acc: 78.78724150017526. val_loss: 0.8296960278033408, val_acc: 85.30566461020751
kfold: 3, epoch: 5. train_loss: 0.9195522582093173, train_acc: 80.54679284963197. val_loss: 0.8236218801189258, val_acc: 85.6842400448682
kfold: 3, epoch: 6. train_loss: 0.900079004514575, train_acc: 81.32492113564669. val_loss: 0.8242056114046479, val_acc: 85.13740886146944
kfold: 3, epoch: 7. train_loss: 0.8731529781856489, train_acc: 82.9372590255871. val_loss: 0.8078604863055021, val_acc: 86.315199102636
kfold: 3, epoch: 8. train_loss: 0.8689348880469983, train_acc: 82.46757798808272. val_loss: 0.8197876432606562, val_acc: 85.38979248457656
kfold: 3, epoch: 9. train_loss: 0.8559351202851422, train_acc: 83.7434279705573. val_loss: 0.8042623719270485, val_acc: 86.55356141334829
kfold: 3, epoch: 10. train_loss: 0.8498865173649714, train_acc: 83.55415352260778. val_loss: 0.79396595693477, val_acc: 86.65171060011217
kfold: 3, epoch: 11. train_loss: 0.842259788031935, train_acc: 84.22011917280057. val_loss: 0.7995329302345443, val_acc: 86.3853056646102
kfold: 3, epoch: 12. train_loss: 0.8320456660859953, train_acc: 84.71083070452156. val_loss: 0.7979286572134903, val_acc: 86.42736960179472
kfold: 3, epoch: 13. train_loss: 0.8205266190002972, train_acc: 85.06133894146512. val_loss: 0.784523000459088, val_acc: 87.42288278182838
kfold: 3, epoch: 14. train_loss: 0.8174215721957049, train_acc: 85.18051174202594. val_loss: 0.7926332778764854, val_acc: 87.1845204711161
kfold: 3, epoch: 15. train_loss: 0.8090071035494215, train_acc: 86.06379249912374. val_loss: 0.7892977473311924, val_acc: 87.15647784632641
kfold: 3, epoch: 16. train_loss: 0.8053025734468037, train_acc: 86.11286365229583. val_loss: 0.7986151758566774, val_acc: 87.05832865956253
kfold: 3, epoch: 17. train_loss: 0.7966358898599709, train_acc: 86.29512793550649. val_loss: 0.8117911998836498, val_acc: 86.44139091418957
kfold: 3, epoch: 18. train_loss: 0.7998547204275375, train_acc: 86.18296529968454. val_loss: 0.7963176627407833, val_acc: 87.1144139091419
kfold: 3, epoch: 19. train_loss: 0.7935167499406685, train_acc: 86.14090431125132. val_loss: 0.7980750693876424, val_acc: 87.59113853056647
kfold: 3, epoch: 20. train_loss: 0.7884948375113444, train_acc: 86.66666666666667. val_loss: 0.8016810612068775, val_acc: 87.29669097027482
kfold: 3, epoch: 21. train_loss: 0.7831883426136351, train_acc: 87.1223273746933. val_loss: 0.8109867458790123, val_acc: 87.2546270330903
kfold: 3, epoch: 22. train_loss: 0.7802790282051336, train_acc: 87.37469330529268. val_loss: 0.7979834941218424, val_acc: 87.75939427930454
kfold: 3, epoch: 23. train_loss: 0.7763984602875225, train_acc: 87.33964248159832. val_loss: 0.8064851003353741, val_acc: 87.26864834548513
kfold: 3, epoch: 24. train_loss: 0.7719894586940891, train_acc: 87.29057132842622. val_loss: 0.8015913395686425, val_acc: 87.36679753224902
kfold: 3, epoch: 25. train_loss: 0.7646863084064, train_acc: 87.80231335436383. val_loss: 0.7949852362082904, val_acc: 87.73135165451487