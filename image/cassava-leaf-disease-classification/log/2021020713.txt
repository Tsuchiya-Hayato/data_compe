filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b4, lr: 1e-05, weights: tensor([1.5000, 1.0000, 1.0000, 1.0000, 1.0000]). batchsize: 4, kfold: 3, epoch: 25, weght_decay: 5e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.2136028266762056, train_acc: 65.33931575995513. val_loss: 1.0143137443894228, val_acc: 76.8540586008692
kfold: 1, epoch: 2. train_loss: 1.038760139175967, train_acc: 74.34800897363993. val_loss: 0.9143294037190254, val_acc: 80.93368849011637
kfold: 1, epoch: 3. train_loss: 0.9788484545617845, train_acc: 77.25743129556926. val_loss: 0.8545353651514502, val_acc: 83.31697742885181
kfold: 1, epoch: 4. train_loss: 0.940822937049962, train_acc: 79.2975322490185. val_loss: 0.8464567846714648, val_acc: 83.7936352165989
kfold: 1, epoch: 5. train_loss: 0.9287221028740594, train_acc: 80.15984296130118. val_loss: 0.8281002309958496, val_acc: 84.92920229917286
kfold: 1, epoch: 6. train_loss: 0.8957862942759, train_acc: 81.67414469994391. val_loss: 0.8304932818752233, val_acc: 85.20958923314174
kfold: 1, epoch: 7. train_loss: 0.8800923117445348, train_acc: 82.12983735277622. val_loss: 0.8078248686921436, val_acc: 85.91055656806392
kfold: 1, epoch: 8. train_loss: 0.8674143161321716, train_acc: 82.87997756590016. val_loss: 0.8048708778993966, val_acc: 85.99467264825459
kfold: 1, epoch: 9. train_loss: 0.8566449183930992, train_acc: 83.51093662366797. val_loss: 0.7934429841993101, val_acc: 86.45731108930323
kfold: 1, epoch: 10. train_loss: 0.8430441238708999, train_acc: 84.17694896242288. val_loss: 0.7956606366842851, val_acc: 86.06476938174681
kfold: 1, epoch: 11. train_loss: 0.8333736050683865, train_acc: 84.48541783510936. val_loss: 0.7966998217819518, val_acc: 86.33113696901724
kfold: 1, epoch: 12. train_loss: 0.8280066276492527, train_acc: 84.96214245653393. val_loss: 0.7953444727667244, val_acc: 86.42927239590635
kfold: 1, epoch: 13. train_loss: 0.826033721963676, train_acc: 84.54851374088615. val_loss: 0.7952937774126305, val_acc: 86.49936912939857
kfold: 1, epoch: 14. train_loss: 0.8140437076316412, train_acc: 85.55103757711721. val_loss: 0.798680740655003, val_acc: 86.35917566241413
kfold: 1, epoch: 15. train_loss: 0.8051150860207441, train_acc: 85.9296130117779. val_loss: 0.7975642509725062, val_acc: 86.51338847609702
kfold: 1, epoch: 16. train_loss: 0.8046605488555991, train_acc: 85.8595064498037. val_loss: 0.7976113224042906, val_acc: 86.68162063647834
kfold: 1, epoch: 17. train_loss: 0.7964893637984506, train_acc: 85.99270891755468. val_loss: 0.8009589160771647, val_acc: 86.87789149025656
kfold: 1, epoch: 18. train_loss: 0.7943652269717221, train_acc: 86.47644419517667. val_loss: 0.7985106240540342, val_acc: 86.9900462638441
kfold: 1, epoch: 19. train_loss: 0.7917322697628768, train_acc: 86.48345485137409. val_loss: 0.7948746050419829, val_acc: 87.17229777092388
kfold: 1, epoch: 20. train_loss: 0.7878517035814864, train_acc: 86.73583847448121. val_loss: 0.7956129384014105, val_acc: 87.13023973082855
kfold: 1, epoch: 21. train_loss: 0.7801112172413728, train_acc: 87.12843522153673. val_loss: 0.7956904763932185, val_acc: 86.75171736997056
kfold: 1, epoch: 22. train_loss: 0.7737393523960787, train_acc: 87.30370162647223. val_loss: 0.8024893329215691, val_acc: 87.06014299733633
kfold: 1, epoch: 23. train_loss: 0.7726515185712631, train_acc: 87.38782950084128. val_loss: 0.7916878202236821, val_acc: 87.2423945044161
kfold: 1, epoch: 24. train_loss: 0.7695412443751241, train_acc: 87.56309590577678. val_loss: 0.7909285260756989, val_acc: 87.45268470489275
kfold: 1, epoch: 25. train_loss: 0.7723494529289539, train_acc: 87.2896803140774. val_loss: 0.793885347654734, val_acc: 87.15827842422543
kfold: 2, epoch: 1. train_loss: 1.205588044691126, train_acc: 66.42131090080616. val_loss: 1.0253752782915793, val_acc: 77.10319685922602
kfold: 2, epoch: 2. train_loss: 1.034251086729262, train_acc: 74.81247809323519. val_loss: 0.9087291212812008, val_acc: 81.44980370162648
kfold: 2, epoch: 3. train_loss: 0.9909970093949823, train_acc: 76.89449702067999. val_loss: 0.855568142801072, val_acc: 83.244531688166
kfold: 2, epoch: 4. train_loss: 0.9557903549869688, train_acc: 78.73817034700315. val_loss: 0.8413295651912956, val_acc: 84.3241727425687
kfold: 2, epoch: 5. train_loss: 0.9292501772288886, train_acc: 79.90886785839467. val_loss: 0.8347914346268654, val_acc: 84.29613011777903
kfold: 2, epoch: 6. train_loss: 0.9042551519157574, train_acc: 81.36698212407991. val_loss: 0.8058419895185491, val_acc: 85.8244531688166
kfold: 2, epoch: 7. train_loss: 0.8884325592765829, train_acc: 81.87171398527866. val_loss: 0.8033610857810054, val_acc: 85.69826135726304
kfold: 2, epoch: 8. train_loss: 0.8782346967491811, train_acc: 82.43252716438836. val_loss: 0.7994125276152096, val_acc: 85.95064498037016
kfold: 2, epoch: 9. train_loss: 0.8610433116492552, train_acc: 83.24570627409744. val_loss: 0.7862306474235308, val_acc: 86.60964666292764
kfold: 2, epoch: 10. train_loss: 0.8497525697366711, train_acc: 83.79249912372941. val_loss: 0.7868050969656571, val_acc: 86.37128435221537
kfold: 2, epoch: 11. train_loss: 0.8427952511791158, train_acc: 84.12898703119524. val_loss: 0.7763945475362756, val_acc: 87.29669097027482
kfold: 2, epoch: 12. train_loss: 0.8338311088663342, train_acc: 84.48650543287768. val_loss: 0.7721855101194932, val_acc: 87.6051598429613
kfold: 2, epoch: 13. train_loss: 0.8287470525374492, train_acc: 84.59165790396074. val_loss: 0.7752074694874176, val_acc: 87.45092540661805
kfold: 2, epoch: 14. train_loss: 0.8265569421768456, train_acc: 84.99123729407641. val_loss: 0.7707698322452324, val_acc: 87.73135165451487
kfold: 2, epoch: 15. train_loss: 0.8173318023370166, train_acc: 85.25061338941465. val_loss: 0.7720575897598695, val_acc: 87.68928771733034
kfold: 2, epoch: 16. train_loss: 0.8112977673300916, train_acc: 85.71328426218017. val_loss: 0.7659682916979809, val_acc: 88.06786315199102
kfold: 2, epoch: 17. train_loss: 0.8001386116859055, train_acc: 86.14090431125132. val_loss: 0.7718330781511958, val_acc: 88.12394840157039
kfold: 2, epoch: 18. train_loss: 0.7971521317708181, train_acc: 86.29512793550649. val_loss: 0.7745705615986083, val_acc: 87.40886146943353
kfold: 2, epoch: 19. train_loss: 0.8008397542063449, train_acc: 85.97967052225728. val_loss: 0.7702388236914467, val_acc: 88.01177790241167
kfold: 2, epoch: 20. train_loss: 0.7911459892645649, train_acc: 86.50543287767263. val_loss: 0.7788701894172309, val_acc: 87.49298934380258
kfold: 2, epoch: 21. train_loss: 0.789258266100203, train_acc: 86.37924991237294. val_loss: 0.7825452599776841, val_acc: 87.15647784632641
kfold: 2, epoch: 22. train_loss: 0.7872495540457678, train_acc: 86.54048370136698. val_loss: 0.775440609094071, val_acc: 87.8154795288839
kfold: 2, epoch: 23. train_loss: 0.7858255601644449, train_acc: 86.75078864353313. val_loss: 0.7769031791424925, val_acc: 87.95569265283231
kfold: 2, epoch: 24. train_loss: 0.7800378034453717, train_acc: 87.05222572730459. val_loss: 0.7826671598336032, val_acc: 88.05384183959619
kfold: 2, epoch: 25. train_loss: 0.7754992690613065, train_acc: 87.46582544689801. val_loss: 0.7827365646118939, val_acc: 88.19405496354459
kfold: 3, epoch: 1. train_loss: 1.2180233410101897, train_acc: 65.34174553101998. val_loss: 1.0458500795129038, val_acc: 75.74312955692653
kfold: 3, epoch: 2. train_loss: 1.0388936043153265, train_acc: 74.51104100946372. val_loss: 0.9029510798443587, val_acc: 81.28154795288839
kfold: 3, epoch: 3. train_loss: 0.9844566904967126, train_acc: 77.16789344549596. val_loss: 0.845934440664408, val_acc: 83.93157599551319
kfold: 3, epoch: 4. train_loss: 0.9491816016349065, train_acc: 79.1167192429022. val_loss: 0.8320379704821999, val_acc: 85.27762198541784
kfold: 3, epoch: 5. train_loss: 0.9182555329776259, train_acc: 80.7570977917981. val_loss: 0.8311667574033668, val_acc: 85.53000560852496
kfold: 3, epoch: 6. train_loss: 0.9003859131249988, train_acc: 81.61233788994042. val_loss: 0.8238151164383816, val_acc: 85.614133482894
kfold: 3, epoch: 7. train_loss: 0.876800152060362, train_acc: 82.57974062390466. val_loss: 0.8008662154349596, val_acc: 86.67975322490184
kfold: 3, epoch: 8. train_loss: 0.8665997956458814, train_acc: 82.85313704872064. val_loss: 0.8055653531967223, val_acc: 86.04879416713405
kfold: 3, epoch: 9. train_loss: 0.8560880827475971, train_acc: 83.56116368734665. val_loss: 0.8034838901031438, val_acc: 86.32922041503085
kfold: 3, epoch: 10. train_loss: 0.8465343120220431, train_acc: 83.89765159481247. val_loss: 0.7918055369087771, val_acc: 86.81996634885026
kfold: 3, epoch: 11. train_loss: 0.8386846019802623, train_acc: 84.34630213810024. val_loss: 0.8002480298899161, val_acc: 86.80594503645541
kfold: 3, epoch: 12. train_loss: 0.8363311825795838, train_acc: 84.59165790396074. val_loss: 0.8028619515046737, val_acc: 85.86651710600113
kfold: 3, epoch: 13. train_loss: 0.8221691224733454, train_acc: 85.32071503680336. val_loss: 0.783130607608992, val_acc: 87.19854178351093
kfold: 3, epoch: 14. train_loss: 0.8166483796575272, train_acc: 85.57308096740273. val_loss: 0.7880465701197348, val_acc: 87.2546270330903
kfold: 3, epoch: 15. train_loss: 0.8143066962894219, train_acc: 85.18752190676481. val_loss: 0.7772845550661199, val_acc: 87.68928771733034
kfold: 3, epoch: 16. train_loss: 0.8067941319083579, train_acc: 85.79039607430775. val_loss: 0.7955553934136871, val_acc: 87.19854178351093
kfold: 3, epoch: 17. train_loss: 0.7975204428070428, train_acc: 86.2180161233789. val_loss: 0.8032554954340534, val_acc: 86.94615816040381
kfold: 3, epoch: 18. train_loss: 0.7952436696657588, train_acc: 86.30213810024536. val_loss: 0.7958531864760501, val_acc: 87.24060572069546
kfold: 3, epoch: 19. train_loss: 0.7891232340750923, train_acc: 86.83491062039958. val_loss: 0.7879072176026148, val_acc: 87.8154795288839
kfold: 3, epoch: 20. train_loss: 0.7865874868231993, train_acc: 86.77181913774973. val_loss: 0.799294653630163, val_acc: 87.43690409422322
kfold: 3, epoch: 21. train_loss: 0.7836890090972327, train_acc: 86.98913424465475. val_loss: 0.8059274066183183, val_acc: 87.3247335950645
kfold: 3, epoch: 22. train_loss: 0.7822023792396515, train_acc: 87.02418506834911. val_loss: 0.7900635578695202, val_acc: 87.6752664049355
kfold: 3, epoch: 23. train_loss: 0.7745323708687706, train_acc: 87.38871363477041. val_loss: 0.7960247534483387, val_acc: 87.21256309590578
kfold: 3, epoch: 24. train_loss: 0.7715657950617333, train_acc: 87.45180511742026. val_loss: 0.7932758246388117, val_acc: 87.56309590577678
kfold: 3, epoch: 25. train_loss: 0.7643805709846353, train_acc: 87.83035401331931. val_loss: 0.7965669366862757, val_acc: 87.31071228266966