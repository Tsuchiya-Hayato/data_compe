model: efficientnet-b3, lr: 1e-05, weights: tensor([1.5000, 1.0000, 1.0000, 1.0000, 1.0000]). batchsize: 8, kfold: 3, epoch: 25, weght_decay: 1e-05,

kfold: 1, epoch: 1. train_loss: 1.038430037303915, train_acc: 64.78547392035894. val_loss: 0.8135069529672108, val_acc: 73.25108649936912
kfold: 1, epoch: 2. train_loss: 0.7624586810907887, train_acc: 73.57683679192372. val_loss: 0.6465018091163695, val_acc: 79.01303799242956
kfold: 1, epoch: 3. train_loss: 0.6618698846738925, train_acc: 77.22237801458216. val_loss: 0.5727783860680501, val_acc: 81.28417215757746
kfold: 1, epoch: 4. train_loss: 0.6164873893290708, train_acc: 78.54038137969714. val_loss: 0.5330967530441124, val_acc: 82.16739099957942
kfold: 1, epoch: 5. train_loss: 0.5867790847481869, train_acc: 79.93550196298374. val_loss: 0.5054528915360904, val_acc: 83.20482265526427
kfold: 1, epoch: 6. train_loss: 0.5647388542686295, train_acc: 80.33510936623668. val_loss: 0.49052365499573675, val_acc: 83.6674610963129
kfold: 1, epoch: 7. train_loss: 0.5433771241167942, train_acc: 81.08524957936064. val_loss: 0.4750146335826126, val_acc: 83.87775129678957
kfold: 1, epoch: 8. train_loss: 0.5322834510905684, train_acc: 82.10179472798654. val_loss: 0.461910676726896, val_acc: 84.81704752558531
kfold: 1, epoch: 9. train_loss: 0.5136673853921209, train_acc: 82.48037016264722. val_loss: 0.4598687689692918, val_acc: 84.92920229917286
kfold: 1, epoch: 10. train_loss: 0.5079273471062395, train_acc: 82.95008412787436. val_loss: 0.46841017478730346, val_acc: 84.3684284312351
kfold: 1, epoch: 11. train_loss: 0.4908868282306281, train_acc: 83.06926528323051. val_loss: 0.45560079086112537, val_acc: 84.85910556568064
kfold: 1, epoch: 12. train_loss: 0.485533376346043, train_acc: 83.53196859226024. val_loss: 0.4516029872309266, val_acc: 84.99929903266508
kfold: 1, epoch: 13. train_loss: 0.4744669108625984, train_acc: 83.87549074593382. val_loss: 0.4477816106210726, val_acc: 85.32174400672929
kfold: 1, epoch: 14. train_loss: 0.4696107124110587, train_acc: 84.07178911946158. val_loss: 0.46215836633092855, val_acc: 84.69087340529931
kfold: 1, epoch: 15. train_loss: 0.46289396332394056, train_acc: 84.40830061693775. val_loss: 0.4534041621511376, val_acc: 85.1955698864433
kfold: 1, epoch: 16. train_loss: 0.4591344306334243, train_acc: 84.5695457094784. val_loss: 0.45247967211078566, val_acc: 85.0413570727604
kfold: 1, epoch: 17. train_loss: 0.4549603789827493, train_acc: 84.89203589455973. val_loss: 0.4578829493703563, val_acc: 84.77498948548998
kfold: 1, epoch: 18. train_loss: 0.4385949490457121, train_acc: 85.36174985978688. val_loss: 0.45645196472958666, val_acc: 84.95724099256975
kfold: 1, epoch: 19. train_loss: 0.4403768100316646, train_acc: 85.24256870443074. val_loss: 0.4382518823921572, val_acc: 85.47595682041216
kfold: 1, epoch: 20. train_loss: 0.44691282682709993, train_acc: 84.9481211441391. val_loss: 0.447959501972848, val_acc: 85.2937053133324
kfold: 1, epoch: 21. train_loss: 0.42579989706281524, train_acc: 85.59310151430174. val_loss: 0.4362504230217064, val_acc: 85.8404598345717
kfold: 1, epoch: 22. train_loss: 0.41873518129538034, train_acc: 85.69125070106561. val_loss: 0.4352804553233538, val_acc: 85.61615028739661
kfold: 1, epoch: 23. train_loss: 0.4218196697111084, train_acc: 85.51598429613011. val_loss: 0.4421822598147636, val_acc: 85.50399551380906
kfold: 1, epoch: 24. train_loss: 0.41760083506708057, train_acc: 86.25911385305665. val_loss: 0.4409723561220581, val_acc: 85.75634375438105
kfold: 1, epoch: 25. train_loss: 0.4116671229553353, train_acc: 86.32922041503085. val_loss: 0.44065297285884186, val_acc: 85.6441889807935
kfold: 2, epoch: 1. train_loss: 1.035448172635027, train_acc: 64.79495268138801. val_loss: 0.8302736564501786, val_acc: 73.27537857543466
kfold: 2, epoch: 2. train_loss: 0.7700917914660121, train_acc: 73.76095338240448. val_loss: 0.6460777522803957, val_acc: 79.16432978126753
kfold: 2, epoch: 3. train_loss: 0.6754038180036662, train_acc: 77.04872064493516. val_loss: 0.5770871675251712, val_acc: 80.32809871003926
kfold: 2, epoch: 4. train_loss: 0.6200172234485302, train_acc: 78.57693655800911. val_loss: 0.5270096400101155, val_acc: 81.92652832305103
kfold: 2, epoch: 5. train_loss: 0.6056295921858985, train_acc: 79.18682089029092. val_loss: 0.5057424466280191, val_acc: 82.75378575434661
kfold: 2, epoch: 6. train_loss: 0.5768559222974117, train_acc: 80.18226428321066. val_loss: 0.4983053751072675, val_acc: 83.14638250140213
kfold: 2, epoch: 7. train_loss: 0.5523555850309441, train_acc: 81.36698212407991. val_loss: 0.4800875251757758, val_acc: 83.6231071228267
kfold: 2, epoch: 8. train_loss: 0.5343985219314829, train_acc: 81.58429723098493. val_loss: 0.4648082496221449, val_acc: 84.01570386988222
kfold: 2, epoch: 9. train_loss: 0.5265121671784619, train_acc: 82.19418156326674. val_loss: 0.4584677464113625, val_acc: 84.35221536735838
kfold: 2, epoch: 10. train_loss: 0.5231457838471227, train_acc: 82.5727304591658. val_loss: 0.4532940837287348, val_acc: 84.22602355580483
kfold: 2, epoch: 11. train_loss: 0.5106332359351051, train_acc: 83.25972660357519. val_loss: 0.45577951655368165, val_acc: 84.1839596186203
kfold: 2, epoch: 12. train_loss: 0.5072558244832295, train_acc: 83.07045215562566. val_loss: 0.4499478230227804, val_acc: 84.54851374088615
kfold: 2, epoch: 13. train_loss: 0.4882782417007058, train_acc: 83.55415352260778. val_loss: 0.4477089637276537, val_acc: 84.6045989904655
kfold: 2, epoch: 14. train_loss: 0.48158300635530177, train_acc: 84.00981423063442. val_loss: 0.43472235975787044, val_acc: 84.92708917554683
kfold: 2, epoch: 15. train_loss: 0.48161903742884576, train_acc: 83.75043813529618. val_loss: 0.44108530801132056, val_acc: 84.6747055524397
kfold: 2, epoch: 16. train_loss: 0.46621362662210125, train_acc: 84.07991587802313. val_loss: 0.4312061631504964, val_acc: 85.38979248457656
kfold: 2, epoch: 17. train_loss: 0.4660831076331069, train_acc: 84.38836312653348. val_loss: 0.42790018984809886, val_acc: 85.58609085810431
kfold: 2, epoch: 18. train_loss: 0.45183685262094464, train_acc: 84.58464773922188. val_loss: 0.42787552506228566, val_acc: 85.16545148625912
kfold: 2, epoch: 19. train_loss: 0.4475861370559331, train_acc: 84.9421661409043. val_loss: 0.4180859703175941, val_acc: 85.88053841839596
kfold: 2, epoch: 20. train_loss: 0.44484531045619885, train_acc: 84.86505432877672. val_loss: 0.4118366142935349, val_acc: 86.02075154234436
kfold: 2, epoch: 21. train_loss: 0.44658951053704915, train_acc: 85.33473536628111. val_loss: 0.41852832967498976, val_acc: 85.71228266965788
kfold: 2, epoch: 22. train_loss: 0.43890813680369856, train_acc: 85.17350157728707. val_loss: 0.42650650977157056, val_acc: 85.64217610768368
kfold: 2, epoch: 23. train_loss: 0.4374064053116458, train_acc: 85.40483701366982. val_loss: 0.4219516720137279, val_acc: 85.6842400448682
kfold: 2, epoch: 24. train_loss: 0.42950475184693765, train_acc: 85.5099894847529. val_loss: 0.42576875718051543, val_acc: 85.50196298373528
kfold: 2, epoch: 25. train_loss: 0.4197433158982913, train_acc: 85.79740623904662. val_loss: 0.4261367996813178, val_acc: 85.27762198541784
kfold: 3, epoch: 1. train_loss: 1.028985695362158, train_acc: 64.86505432877672. val_loss: 0.8028340966611967, val_acc: 74.08861469433539
kfold: 3, epoch: 2. train_loss: 0.7564015010948139, train_acc: 73.84507535927094. val_loss: 0.6234036397873821, val_acc: 79.54290521592822
kfold: 3, epoch: 3. train_loss: 0.656665469858077, train_acc: 77.3080967402734. val_loss: 0.5449214686969538, val_acc: 81.6320807627594
kfold: 3, epoch: 4. train_loss: 0.6160056489924879, train_acc: 78.96950578338591. val_loss: 0.5210275713337644, val_acc: 82.1228266965788
kfold: 3, epoch: 5. train_loss: 0.5873226858967824, train_acc: 79.76866456361725. val_loss: 0.48819664785964206, val_acc: 83.35670218732473
kfold: 3, epoch: 6. train_loss: 0.5651045183530036, train_acc: 80.92534174553101. val_loss: 0.4744840588988611, val_acc: 83.94559730790802
kfold: 3, epoch: 7. train_loss: 0.5451480958886411, train_acc: 81.1496670171749. val_loss: 0.4613124144518322, val_acc: 84.3942793045429
kfold: 3, epoch: 8. train_loss: 0.5393695380129421, train_acc: 81.97686645636172. val_loss: 0.44349060383011407, val_acc: 84.7728547392036
kfold: 3, epoch: 9. train_loss: 0.5232570033370112, train_acc: 82.3764458464774. val_loss: 0.44835175043222547, val_acc: 84.56253505328098
kfold: 3, epoch: 10. train_loss: 0.5179237705768157, train_acc: 82.39747634069401. val_loss: 0.4469243015951974, val_acc: 84.82893998878295
kfold: 3, epoch: 11. train_loss: 0.5102222082977739, train_acc: 82.52365930599369. val_loss: 0.43371573442409456, val_acc: 84.96915311273135
kfold: 3, epoch: 12. train_loss: 0.5017602997936409, train_acc: 83.37188923939712. val_loss: 0.4310155882361249, val_acc: 85.23555804823332
kfold: 3, epoch: 13. train_loss: 0.47932900540789614, train_acc: 83.75043813529618. val_loss: 0.439178324927839, val_acc: 84.99719573752103
kfold: 3, epoch: 14. train_loss: 0.48064352601198607, train_acc: 83.89765159481247. val_loss: 0.4249332499943022, val_acc: 85.60011217049916
kfold: 3, epoch: 15. train_loss: 0.4742752667558233, train_acc: 84.19207851384508. val_loss: 0.42541086989885085, val_acc: 85.58609085810431
kfold: 3, epoch: 16. train_loss: 0.4618001515630449, train_acc: 84.33929197336137. val_loss: 0.42387615998208755, val_acc: 85.83847448121143
kfold: 3, epoch: 17. train_loss: 0.45371482100529853, train_acc: 84.73186119873817. val_loss: 0.43206769054350463, val_acc: 85.40381379697139
kfold: 3, epoch: 18. train_loss: 0.4524339328419768, train_acc: 85.07535927094287. val_loss: 0.43219510684491474, val_acc: 85.37577117218171
kfold: 3, epoch: 19. train_loss: 0.4454951910865848, train_acc: 85.08937960042061. val_loss: 0.4412093569207185, val_acc: 85.10936623667975
kfold: 3, epoch: 20. train_loss: 0.4465970085712459, train_acc: 85.18752190676481. val_loss: 0.42541992491854547, val_acc: 85.964666292765
kfold: 3, epoch: 21. train_loss: 0.4301335718534937, train_acc: 85.57308096740273. val_loss: 0.41846458486911964, val_acc: 86.27313516545149
kfold: 3, epoch: 22. train_loss: 0.4332583821086305, train_acc: 85.43287767262531. val_loss: 0.42507048606592746, val_acc: 85.72630398205273
kfold: 3, epoch: 23. train_loss: 0.422760043534421, train_acc: 85.83245706274097. val_loss: 0.4218088130084505, val_acc: 86.16096466629277
kfold: 3, epoch: 24. train_loss: 0.41827166386182535, train_acc: 85.62916228531371. val_loss: 0.42948767756823986, val_acc: 85.90858104318565
kfold: 3, epoch: 25. train_loss: 0.4132192829642612, train_acc: 86.04977216964599. val_loss: 0.42484874867900974, val_acc: 86.18900729108245