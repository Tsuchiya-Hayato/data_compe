model: efficientnet-b3, lr: 1e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 8, kfold: 3, epoch: 20, RandomHorizontalFlip:(True,),CenterCrop: True 

kfold: 1, epoch: 1. train_loss: 1.0128614509032137, train_acc: 64.20358945597307. val_loss: 0.7946154722451094, val_acc: 74.37263423524463
kfold: 1, epoch: 2. train_loss: 0.740480194943244, train_acc: 73.54178351093663. val_loss: 0.6329329574455594, val_acc: 78.66255432496845
kfold: 1, epoch: 3. train_loss: 0.6266359044421742, train_acc: 77.60095344924285. val_loss: 0.5552580965883328, val_acc: 80.55516612925838
kfold: 1, epoch: 4. train_loss: 0.5793742894399253, train_acc: 79.3325855300056. val_loss: 0.5223899800038057, val_acc: 81.60661713164167
kfold: 1, epoch: 5. train_loss: 0.5416279201360813, train_acc: 80.81884464385867. val_loss: 0.5039010483504277, val_acc: 82.92443572129538
kfold: 1, epoch: 6. train_loss: 0.5069972650846336, train_acc: 82.15086932136848. val_loss: 0.4886502723142739, val_acc: 83.28893873545493
kfold: 1, epoch: 7. train_loss: 0.47739215327643036, train_acc: 83.4127874369041. val_loss: 0.4807370299590342, val_acc: 83.55530632272536
kfold: 1, epoch: 8. train_loss: 0.4650271297633581, train_acc: 83.53897924845765. val_loss: 0.47198004155908396, val_acc: 84.10206084396467
kfold: 1, epoch: 9. train_loss: 0.44517911821227696, train_acc: 84.21200224340998. val_loss: 0.4762963661652543, val_acc: 83.93382868358334
kfold: 1, epoch: 10. train_loss: 0.42379496574184566, train_acc: 85.11637689287717. val_loss: 0.4726158677638955, val_acc: 84.45254451142577
kfold: 1, epoch: 11. train_loss: 0.40153804145423266, train_acc: 85.93662366797533. val_loss: 0.4712998361745432, val_acc: 84.85910556568064
kfold: 1, epoch: 12. train_loss: 0.3858119774530409, train_acc: 86.71480650588894. val_loss: 0.4776792376881127, val_acc: 83.94784803028179
kfold: 1, epoch: 13. train_loss: 0.3591825018657253, train_acc: 87.23359506449803. val_loss: 0.47590692376252264, val_acc: 84.35440908453666
kfold: 1, epoch: 14. train_loss: 0.34666427404191963, train_acc: 87.73135165451487. val_loss: 0.49694197823819725, val_acc: 83.65344174961447
kfold: 1, epoch: 15. train_loss: 0.32880992593271924, train_acc: 88.55159842961301. val_loss: 0.5007387714774957, val_acc: 83.83569325669424
kfold: 1, epoch: 16. train_loss: 0.31547541887171887, train_acc: 88.69882220975883. val_loss: 0.499856377660893, val_acc: 83.63942240291603
kfold: 1, epoch: 17. train_loss: 0.30179436110791635, train_acc: 89.28771733034212. val_loss: 0.5033955826709097, val_acc: 83.55530632272536
kfold: 1, epoch: 18. train_loss: 0.29496477438952823, train_acc: 89.71536735838474. val_loss: 0.5253104961679772, val_acc: 82.86835833450161
kfold: 1, epoch: 19. train_loss: 0.2668494626637329, train_acc: 90.75294447560292. val_loss: 0.5132877686190953, val_acc: 83.68148044301135
kfold: 1, epoch: 20. train_loss: 0.2634101191188762, train_acc: 90.77397644419517. val_loss: 0.5318107848163202, val_acc: 83.5693256694238
kfold: 2, epoch: 1. train_loss: 1.0043083027907285, train_acc: 65.60112162635822. val_loss: 0.881696952147735, val_acc: 72.96690970274818
kfold: 2, epoch: 2. train_loss: 0.7503622529251426, train_acc: 72.78654048370137. val_loss: 0.6621799963555662, val_acc: 78.07066741447
kfold: 2, epoch: 3. train_loss: 0.6494622543462523, train_acc: 76.74728356116368. val_loss: 0.5864532698998269, val_acc: 79.75322490185081
kfold: 2, epoch: 4. train_loss: 0.5852272703725795, train_acc: 79.15177006659657. val_loss: 0.5311599114070324, val_acc: 81.60403813796971
kfold: 2, epoch: 5. train_loss: 0.5450472923856011, train_acc: 80.53277252015423. val_loss: 0.5153292886486837, val_acc: 81.61805945036456
kfold: 2, epoch: 6. train_loss: 0.5230869818562349, train_acc: 81.36698212407991. val_loss: 0.4967232347495286, val_acc: 82.43129556926529
kfold: 2, epoch: 7. train_loss: 0.5062839705684962, train_acc: 82.27129337539432. val_loss: 0.4892186659551121, val_acc: 82.90802019068985
kfold: 2, epoch: 8. train_loss: 0.4723168490433673, train_acc: 83.28776726253066. val_loss: 0.4780597979747878, val_acc: 83.25855300056085
kfold: 2, epoch: 9. train_loss: 0.45320365239757493, train_acc: 84.27620049071153. val_loss: 0.47485275321844717, val_acc: 83.09029725182278
kfold: 2, epoch: 10. train_loss: 0.43355602880046107, train_acc: 84.7739221871714. val_loss: 0.46875831391871176, val_acc: 83.60908581043185
kfold: 2, epoch: 11. train_loss: 0.4133723359346189, train_acc: 85.62916228531371. val_loss: 0.46712577334373373, val_acc: 83.66517106001122
kfold: 2, epoch: 12. train_loss: 0.4008820462604408, train_acc: 86.02874167542937. val_loss: 0.47071820693382904, val_acc: 83.95961862030286
kfold: 2, epoch: 13. train_loss: 0.3700402887911857, train_acc: 86.91202243252717. val_loss: 0.4758234643105902, val_acc: 83.9736399326977
kfold: 2, epoch: 14. train_loss: 0.3547488437222125, train_acc: 87.73221170697511. val_loss: 0.4806731491215995, val_acc: 83.2024677509815
kfold: 2, epoch: 15. train_loss: 0.34334941437121297, train_acc: 87.84437434279705. val_loss: 0.486962531708941, val_acc: 83.244531688166
kfold: 2, epoch: 16. train_loss: 0.331172334959505, train_acc: 88.66456361724501. val_loss: 0.49036059897150763, val_acc: 83.03421200224341
kfold: 2, epoch: 17. train_loss: 0.309249329042408, train_acc: 89.28145811426569. val_loss: 0.4963387234210592, val_acc: 83.44083006169377
kfold: 2, epoch: 18. train_loss: 0.29681636101666486, train_acc: 89.71608832807571. val_loss: 0.5026131071726637, val_acc: 83.5530005608525
kfold: 2, epoch: 19. train_loss: 0.2722069349812319, train_acc: 90.354013319313. val_loss: 0.5239218400092795, val_acc: 83.13236118900728
kfold: 2, epoch: 20. train_loss: 0.26425992264182646, train_acc: 90.54328776726253. val_loss: 0.5263001833525027, val_acc: 83.52495793606282
kfold: 3, epoch: 1. train_loss: 1.017545646682983, train_acc: 64.2832106554504. val_loss: 0.8048695378974414, val_acc: 73.73808188446439
kfold: 3, epoch: 2. train_loss: 0.735324082378248, train_acc: 73.75394321766562. val_loss: 0.6343852267621478, val_acc: 77.6219854178351
kfold: 3, epoch: 3. train_loss: 0.6338467578833814, train_acc: 77.79179810725552. val_loss: 0.5628772729114032, val_acc: 79.97756590016826
kfold: 3, epoch: 4. train_loss: 0.5722676796938874, train_acc: 79.83876621100596. val_loss: 0.5254822283557244, val_acc: 81.56197420078519
kfold: 3, epoch: 5. train_loss: 0.536641627061494, train_acc: 81.20574833508587. val_loss: 0.5078113865098945, val_acc: 81.99663488502524
kfold: 3, epoch: 6. train_loss: 0.5234882607346092, train_acc: 81.70347003154573. val_loss: 0.4849116927703985, val_acc: 82.41727425687044
kfold: 3, epoch: 7. train_loss: 0.48895532868994657, train_acc: 83.00035050823695. val_loss: 0.4761226303967326, val_acc: 83.2725743129557
kfold: 3, epoch: 8. train_loss: 0.46250666541385677, train_acc: 83.869610935857. val_loss: 0.45877630410991577, val_acc: 83.98766124509254
kfold: 3, epoch: 9. train_loss: 0.4387508681766488, train_acc: 84.78093235191027. val_loss: 0.46105828771739366, val_acc: 83.5530005608525
kfold: 3, epoch: 10. train_loss: 0.42787131246997906, train_acc: 85.15247108307045. val_loss: 0.46765244402713874, val_acc: 83.23051037577117
kfold: 3, epoch: 11. train_loss: 0.4078220701494542, train_acc: 85.62916228531371. val_loss: 0.4586204488139449, val_acc: 83.94559730790802
kfold: 3, epoch: 12. train_loss: 0.39037068798457325, train_acc: 86.35120925341745. val_loss: 0.462745556265383, val_acc: 83.73527762198542
kfold: 3, epoch: 13. train_loss: 0.37422981292360163, train_acc: 87.14335786890992. val_loss: 0.4534546955647323, val_acc: 84.52047111609647
kfold: 3, epoch: 14. train_loss: 0.354193583562043, train_acc: 87.83736417805818. val_loss: 0.47862062622498586, val_acc: 83.66517106001122
kfold: 3, epoch: 15. train_loss: 0.3357873741409954, train_acc: 88.23694356817386. val_loss: 0.47148770359428305, val_acc: 84.15591699383062
kfold: 3, epoch: 16. train_loss: 0.32517199046573614, train_acc: 88.78373641780581. val_loss: 0.4725719716779955, val_acc: 83.98766124509254
kfold: 3, epoch: 17. train_loss: 0.3154686072370405, train_acc: 89.35856992639327. val_loss: 0.4967723447195726, val_acc: 84.21200224340998
kfold: 3, epoch: 18. train_loss: 0.29272591063257875, train_acc: 89.94041359971959. val_loss: 0.499801396731352, val_acc: 84.01570386988222
kfold: 3, epoch: 19. train_loss: 0.2821213006174543, train_acc: 90.31195233087978. val_loss: 0.517668184301463, val_acc: 83.42680874929893
kfold: 3, epoch: 20. train_loss: 0.27322222666675017, train_acc: 90.54328776726253. val_loss: 0.5175906824699243, val_acc: 83.66517106001122