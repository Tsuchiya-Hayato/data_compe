filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b5, lr: 1e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 2, kfold: 3, epoch: 25, weght_decay: 5e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.212984960791574, train_acc: 62.52103196859226. val_loss: 1.3294627401786656, val_acc: 60.535539043880554
kfold: 1, epoch: 2. train_loss: 1.0991067305516475, train_acc: 67.24621424565339. val_loss: 1.1620983326672372, val_acc: 68.47048927519978
kfold: 1, epoch: 3. train_loss: 1.0520641651470475, train_acc: 70.75855300056085. val_loss: 1.1032489079920424, val_acc: 69.62007570447217
kfold: 1, epoch: 4. train_loss: 1.0022903200462503, train_acc: 73.15619742007851. val_loss: 1.01377747281613, val_acc: 74.20440207486331
kfold: 1, epoch: 5. train_loss: 0.959273385925535, train_acc: 75.58188446438587. val_loss: 0.9670394216059702, val_acc: 76.55965232020188
kfold: 1, epoch: 6. train_loss: 0.9208465363878383, train_acc: 77.23639932697701. val_loss: 0.9391132835617312, val_acc: 78.87284452544512
kfold: 1, epoch: 7. train_loss: 0.8907033167883912, train_acc: 78.42120022434099. val_loss: 0.9234931326260044, val_acc: 79.75606336744708
kfold: 1, epoch: 8. train_loss: 0.864596268311519, train_acc: 79.94952327537858. val_loss: 0.961035825840592, val_acc: 79.16725080611243
kfold: 1, epoch: 9. train_loss: 0.8438487794632599, train_acc: 80.64357823892317. val_loss: 0.9067069888031379, val_acc: 80.49908874246461
kfold: 1, epoch: 10. train_loss: 0.8366077384852454, train_acc: 81.50588895120583. val_loss: 0.9447868051049687, val_acc: 80.26075984859105
kfold: 1, epoch: 11. train_loss: 0.8327771675633502, train_acc: 81.62507010656198. val_loss: 0.8993941696962791, val_acc: 81.7468105986261
kfold: 1, epoch: 12. train_loss: 0.8201067625214328, train_acc: 82.15086932136848. val_loss: 0.90616289519749, val_acc: 82.39170054675452
kfold: 1, epoch: 13. train_loss: 0.8111883990646278, train_acc: 82.71172181716209. val_loss: 0.9005413984998388, val_acc: 81.98513949249966
kfold: 1, epoch: 14. train_loss: 0.8052832278529045, train_acc: 83.19545709478408. val_loss: 0.8963067090775341, val_acc: 82.1954296929763
kfold: 1, epoch: 15. train_loss: 0.7985484452100196, train_acc: 83.2024677509815. val_loss: 0.9087619241092063, val_acc: 81.97112014580121
kfold: 1, epoch: 16. train_loss: 0.7935978941916082, train_acc: 83.6932136848009. val_loss: 0.9181205977369564, val_acc: 81.522501051451
kfold: 1, epoch: 17. train_loss: 0.7948206705169202, train_acc: 83.50392596747055. val_loss: 0.9026452731461226, val_acc: 82.33562315996075
kfold: 1, epoch: 18. train_loss: 0.7887710637036363, train_acc: 84.07178911946158. val_loss: 0.9177559462872279, val_acc: 81.83092667881677
kfold: 1, epoch: 19. train_loss: 0.7854618900113405, train_acc: 84.07178911946158. val_loss: 0.878024903012485, val_acc: 83.41511285574093
kfold: 1, epoch: 20. train_loss: 0.7859747867887099, train_acc: 83.82641615255189. val_loss: 0.8866580420426705, val_acc: 82.91041637459695
kfold: 1, epoch: 21. train_loss: 0.779312243550364, train_acc: 84.3942793045429. val_loss: 0.8720722875576378, val_acc: 83.4711902425347
kfold: 1, epoch: 22. train_loss: 0.7772899947755469, train_acc: 84.59057767807067. val_loss: 0.8930012410115488, val_acc: 82.78424225431095
kfold: 1, epoch: 23. train_loss: 0.7748945885480486, train_acc: 84.62563095905777. val_loss: 0.8704651271825683, val_acc: 83.73755782980513
kfold: 1, epoch: 24. train_loss: 0.7750090599787148, train_acc: 84.54150308468873. val_loss: 0.8792244133359082, val_acc: 83.21884200196271
kfold: 1, epoch: 25. train_loss: 0.772124886337252, train_acc: 84.48541783510936. val_loss: 0.8711743748401907, val_acc: 83.70951913640825
kfold: 2, epoch: 1. train_loss: 1.224331559923309, train_acc: 62.06098843322818. val_loss: 1.2610965801869893, val_acc: 62.77341559169938