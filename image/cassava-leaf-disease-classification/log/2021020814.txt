filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b4, lr: 1e-05, weights: tensor([1.5000, 1.0000, 1.0000, 1.0000, 1.0000]). batchsize: 4, kfold: 3, epoch: 25, weght_decay: 5e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.2134257826621921, train_acc: 65.5005608524958. val_loss: 1.0088228335094558, val_acc: 77.27463900182252
kfold: 1, epoch: 2. train_loss: 1.0400224577424504, train_acc: 74.17975322490184. val_loss: 0.9122414912343559, val_acc: 80.86359175662415
kfold: 1, epoch: 3. train_loss: 0.9805179874481141, train_acc: 77.36960179472798. val_loss: 0.8564098564231343, val_acc: 83.4711902425347
kfold: 1, epoch: 4. train_loss: 0.9463874135402501, train_acc: 78.9119461581604. val_loss: 0.8471134580972484, val_acc: 83.94784803028179
kfold: 1, epoch: 5. train_loss: 0.9282075629699651, train_acc: 79.94952327537858. val_loss: 0.8307896656372622, val_acc: 84.9432216458713
kfold: 1, epoch: 6. train_loss: 0.8961660662896835, train_acc: 81.48485698261358. val_loss: 0.8251495126785184, val_acc: 85.20958923314174
kfold: 1, epoch: 7. train_loss: 0.8797701316239522, train_acc: 82.45232753785754. val_loss: 0.803981545093081, val_acc: 85.85447918127015
kfold: 1, epoch: 8. train_loss: 0.8693505460234485, train_acc: 82.67666853617499. val_loss: 0.8004625342752901, val_acc: 86.23300154212814
kfold: 1, epoch: 9. train_loss: 0.8531694872053032, train_acc: 83.54598990465507. val_loss: 0.7971244932156507, val_acc: 86.35917566241413
kfold: 1, epoch: 10. train_loss: 0.8469184633058172, train_acc: 83.77033090297252. val_loss: 0.7997836298873072, val_acc: 86.00869199495304
kfold: 1, epoch: 11. train_loss: 0.84095077984666, train_acc: 84.23303421200224. val_loss: 0.7922880758485452, val_acc: 86.35917566241413
kfold: 1, epoch: 12. train_loss: 0.8242865221358656, train_acc: 85.1233875490746. val_loss: 0.7908013839892742, val_acc: 86.79377541006589
kfold: 1, epoch: 13. train_loss: 0.8257034821618626, train_acc: 84.82192933258553. val_loss: 0.7945699942352525, val_acc: 86.4432917426048
kfold: 1, epoch: 14. train_loss: 0.810832164325008, train_acc: 85.76836791923724. val_loss: 0.7904073130255858, val_acc: 87.03210430393943
kfold: 1, epoch: 15. train_loss: 0.809482658270431, train_acc: 85.72630398205273. val_loss: 0.7913483700343311, val_acc: 86.9900462638441
kfold: 1, epoch: 16. train_loss: 0.80291530693841, train_acc: 85.99270891755468. val_loss: 0.7978510724322143, val_acc: 87.03210430393943
kfold: 1, epoch: 17. train_loss: 0.8002841740228189, train_acc: 86.07683679192372. val_loss: 0.8020624922663642, val_acc: 86.75171736997056
kfold: 1, epoch: 18. train_loss: 0.7938966855732698, train_acc: 86.28715647784632. val_loss: 0.7967707286233859, val_acc: 87.14425907752698
kfold: 1, epoch: 19. train_loss: 0.7909774829080382, train_acc: 86.44139091418957. val_loss: 0.7998186742778316, val_acc: 87.04612365063788
kfold: 1, epoch: 20. train_loss: 0.7874234485880284, train_acc: 86.69377453729669. val_loss: 0.7990368651769086, val_acc: 87.14425907752698
kfold: 1, epoch: 21. train_loss: 0.7845670946916034, train_acc: 86.79893438025799. val_loss: 0.7918357484944732, val_acc: 87.14425907752698
kfold: 1, epoch: 22. train_loss: 0.7739908127923796, train_acc: 87.28266965787998. val_loss: 0.8064099032381725, val_acc: 87.15827842422543
kfold: 1, epoch: 23. train_loss: 0.7743960757537699, train_acc: 87.33174425126192. val_loss: 0.7935895081860067, val_acc: 87.4667040515912
kfold: 1, epoch: 24. train_loss: 0.7730670679805657, train_acc: 87.12843522153673. val_loss: 0.7976126655134385, val_acc: 87.25641385111454
kfold: 1, epoch: 25. train_loss: 0.7695641914780595, train_acc: 87.51402131239485. val_loss: 0.8050273508167588, val_acc: 87.13023973082855
kfold: 2, epoch: 1. train_loss: 1.2068606964807267, train_acc: 66.39327024185069. val_loss: 1.0055932859925159, val_acc: 78.95401009534493
kfold: 2, epoch: 2. train_loss: 1.0339547061338656, train_acc: 75.0578338590957. val_loss: 0.9010398491540118, val_acc: 81.99663488502524
kfold: 2, epoch: 3. train_loss: 0.9914232535892954, train_acc: 76.9645986680687. val_loss: 0.8528660206198359, val_acc: 83.63712843522154
kfold: 2, epoch: 4. train_loss: 0.9542561595032855, train_acc: 78.59796705222573. val_loss: 0.8257235213738108, val_acc: 84.8429613011778
kfold: 2, epoch: 5. train_loss: 0.928753615862721, train_acc: 80.09113214160533. val_loss: 0.8297731583531627, val_acc: 84.2540661805945
kfold: 2, epoch: 6. train_loss: 0.9076703715832386, train_acc: 81.26182965299685. val_loss: 0.8065789683909478, val_acc: 85.8945597307908
kfold: 2, epoch: 7. train_loss: 0.8889775941911318, train_acc: 81.689449702068. val_loss: 0.8017387750505799, val_acc: 86.2450925406618
kfold: 2, epoch: 8. train_loss: 0.8742450383286333, train_acc: 82.51664914125482. val_loss: 0.8020367597972016, val_acc: 86.46943353897925
kfold: 2, epoch: 9. train_loss: 0.8649220539970761, train_acc: 82.77602523659306. val_loss: 0.7848171547966196, val_acc: 86.98822209758833
kfold: 2, epoch: 10. train_loss: 0.8457554805536113, train_acc: 83.82053978268489. val_loss: 0.7910319076317185, val_acc: 86.63768928771734
kfold: 2, epoch: 11. train_loss: 0.8417349873987406, train_acc: 84.19908867858395. val_loss: 0.7704419892153844, val_acc: 87.70330902972518
kfold: 2, epoch: 12. train_loss: 0.835729021534119, train_acc: 84.5285664213109. val_loss: 0.7703487378322068, val_acc: 87.73135165451487
kfold: 2, epoch: 13. train_loss: 0.8297870330593985, train_acc: 84.83701366982125. val_loss: 0.7738674824584152, val_acc: 87.6051598429613
kfold: 2, epoch: 14. train_loss: 0.8254848483366093, train_acc: 84.90711531720996. val_loss: 0.7709244788528758, val_acc: 88.10992708917554
kfold: 2, epoch: 15. train_loss: 0.8127036978458536, train_acc: 85.5800911321416. val_loss: 0.767848618098744, val_acc: 87.89960740325294
kfold: 2, epoch: 16. train_loss: 0.812297017610404, train_acc: 85.40483701366982. val_loss: 0.7658811154755996, val_acc: 88.26416152551879
kfold: 2, epoch: 17. train_loss: 0.8036262960470053, train_acc: 86.02874167542937. val_loss: 0.7715577255857171, val_acc: 87.78743690409422
kfold: 2, epoch: 18. train_loss: 0.8048706348282568, train_acc: 85.62916228531371. val_loss: 0.7640878823254126, val_acc: 88.32024677509816
kfold: 2, epoch: 19. train_loss: 0.8011028871403911, train_acc: 85.86049772169646. val_loss: 0.7715836243888868, val_acc: 87.98373527762199
kfold: 2, epoch: 20. train_loss: 0.7917603942771101, train_acc: 86.55450403084473. val_loss: 0.7668929081650443, val_acc: 88.03982052720134
kfold: 2, epoch: 21. train_loss: 0.7911826901854271, train_acc: 86.44234139502278. val_loss: 0.778374747620228, val_acc: 87.73135165451487
kfold: 2, epoch: 22. train_loss: 0.784720878892497, train_acc: 86.85594111461619. val_loss: 0.7720278333694963, val_acc: 87.87156477846327
kfold: 2, epoch: 23. train_loss: 0.7828519450271367, train_acc: 87.02418506834911. val_loss: 0.7681522435240711, val_acc: 88.41839596186203
kfold: 2, epoch: 24. train_loss: 0.7771962105241984, train_acc: 87.01717490361024. val_loss: 0.7743531163328495, val_acc: 87.7453729669097
kfold: 2, epoch: 25. train_loss: 0.7800407705435339, train_acc: 87.04521556256572. val_loss: 0.7724095970743236, val_acc: 88.19405496354459
kfold: 3, epoch: 1. train_loss: 1.2209197242854188, train_acc: 65.22257273045916. val_loss: 1.0443880426970613, val_acc: 75.30846887268649
kfold: 3, epoch: 2. train_loss: 1.0424750272152234, train_acc: 74.24465474938661. val_loss: 0.9016055182934609, val_acc: 81.26752664049356
kfold: 3, epoch: 3. train_loss: 0.9834230649461257, train_acc: 77.27304591657904. val_loss: 0.8425587398646189, val_acc: 84.1839596186203
kfold: 3, epoch: 4. train_loss: 0.9547076312841272, train_acc: 78.71713985278654. val_loss: 0.8311579715182656, val_acc: 85.13740886146944
kfold: 3, epoch: 5. train_loss: 0.9226433982493532, train_acc: 80.3434980722047. val_loss: 0.8261260264252788, val_acc: 85.79641054402693
kfold: 3, epoch: 6. train_loss: 0.8964930529650567, train_acc: 81.59831756046268. val_loss: 0.822433933841333, val_acc: 85.78238923163208
kfold: 3, epoch: 7. train_loss: 0.8785411150207498, train_acc: 82.50262881177707. val_loss: 0.8045788893055127, val_acc: 86.49747616376892
kfold: 3, epoch: 8. train_loss: 0.864936562990788, train_acc: 83.11952330879775. val_loss: 0.8058944709904061, val_acc: 86.1749859786876
kfold: 3, epoch: 9. train_loss: 0.8565729914809062, train_acc: 83.59621451104101. val_loss: 0.7964856550389973, val_acc: 86.46943353897925
kfold: 3, epoch: 10. train_loss: 0.8496562750492572, train_acc: 83.70837714686296. val_loss: 0.7910392598964094, val_acc: 86.84800897363993
kfold: 3, epoch: 11. train_loss: 0.8389254998251742, train_acc: 84.33929197336137. val_loss: 0.8013793283543825, val_acc: 86.74985978687606
kfold: 3, epoch: 12. train_loss: 0.8321936029428055, train_acc: 84.51454609183315. val_loss: 0.7917711802967733, val_acc: 86.79192372406057
kfold: 3, epoch: 13. train_loss: 0.8223483104782008, train_acc: 85.01226778829303. val_loss: 0.7808695099558378, val_acc: 87.52103196859225
kfold: 3, epoch: 14. train_loss: 0.8166826509747613, train_acc: 85.1664914125482. val_loss: 0.7859664819110864, val_acc: 87.17049915872126
kfold: 3, epoch: 15. train_loss: 0.8128964040070179, train_acc: 85.8745180511742. val_loss: 0.7845541130139195, val_acc: 87.28266965787998
kfold: 3, epoch: 16. train_loss: 0.8073972431190347, train_acc: 85.76235541535226. val_loss: 0.7906823784731375, val_acc: 87.3948401570387
kfold: 3, epoch: 17. train_loss: 0.7959059328801631, train_acc: 86.21100595864003. val_loss: 0.8034399719099214, val_acc: 86.69377453729669
kfold: 3, epoch: 18. train_loss: 0.7916715711079494, train_acc: 86.57553452506134. val_loss: 0.7931832116571491, val_acc: 87.21256309590578
kfold: 3, epoch: 19. train_loss: 0.79309954872511, train_acc: 86.42832106554503. val_loss: 0.7904000578472203, val_acc: 87.73135165451487
kfold: 3, epoch: 20. train_loss: 0.7907438255973914, train_acc: 86.55450403084473. val_loss: 0.7878748858770627, val_acc: 87.66124509254067
kfold: 3, epoch: 21. train_loss: 0.7874105764698641, train_acc: 86.72274798457764. val_loss: 0.8026435301668913, val_acc: 87.21256309590578
kfold: 3, epoch: 22. train_loss: 0.7830672938515567, train_acc: 86.92604276200491. val_loss: 0.7951971199561957, val_acc: 87.6051598429613
kfold: 3, epoch: 23. train_loss: 0.7759551916397818, train_acc: 87.36067297581494. val_loss: 0.8034953064819567, val_acc: 87.03028603477286
kfold: 3, epoch: 24. train_loss: 0.7757554812728106, train_acc: 87.27655099894848. val_loss: 0.7940099388110257, val_acc: 87.28266965787998
kfold: 3, epoch: 25. train_loss: 0.7648880898300793, train_acc: 87.7602523659306. val_loss: 0.7897791425565355, val_acc: 87.36679753224902