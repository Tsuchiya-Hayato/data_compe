filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b3, lr: 1e-05, weights: tensor([1.5000, 1.0000, 1.0000, 1.0000, 1.0000]). batchsize: 8, kfold: 3, epoch: 25, weght_decay: 1e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.2328504689342843, train_acc: 64.50504767246214. val_loss: 1.0766498839374081, val_acc: 74.12028599467264
kfold: 1, epoch: 2. train_loss: 1.044489420804159, train_acc: 73.7100392596747. val_loss: 0.9581017582405843, val_acc: 79.46165708677975
kfold: 1, epoch: 3. train_loss: 0.9773530033419657, train_acc: 77.30650588895121. val_loss: 0.9051968383147577, val_acc: 81.6206364783401
kfold: 1, epoch: 4. train_loss: 0.9468478219467672, train_acc: 78.65956253505328. val_loss: 0.8776068462919226, val_acc: 82.96649376139072
kfold: 1, epoch: 5. train_loss: 0.9238375531309987, train_acc: 79.73219293325856. val_loss: 0.8585144013433713, val_acc: 83.90578999018646
kfold: 1, epoch: 6. train_loss: 0.9123955284084956, train_acc: 80.20891755468311. val_loss: 0.8461032003297934, val_acc: 84.08804149726623
kfold: 1, epoch: 7. train_loss: 0.8966435907399193, train_acc: 80.93802579921481. val_loss: 0.8353717665902167, val_acc: 84.53666059161642
kfold: 1, epoch: 8. train_loss: 0.8863859425016286, train_acc: 81.80033651149748. val_loss: 0.8234914870005552, val_acc: 85.26566661993552
kfold: 1, epoch: 9. train_loss: 0.8753900629913813, train_acc: 82.17190128996074. val_loss: 0.8209443209951769, val_acc: 85.30772466003084
kfold: 1, epoch: 10. train_loss: 0.8686963381288564, train_acc: 82.73275378575434. val_loss: 0.8274864947982967, val_acc: 85.02733772606197
kfold: 1, epoch: 11. train_loss: 0.8560507668582362, train_acc: 82.99214806505888. val_loss: 0.8183729859077342, val_acc: 85.22360857984017
kfold: 1, epoch: 12. train_loss: 0.8493796076523208, train_acc: 83.70723499719574. val_loss: 0.8127119283237799, val_acc: 85.34978270012617
kfold: 1, epoch: 13. train_loss: 0.8402683860254101, train_acc: 83.74228827818284. val_loss: 0.8101875306244923, val_acc: 85.54605355390439
kfold: 1, epoch: 14. train_loss: 0.8361175292272348, train_acc: 84.06477846326416. val_loss: 0.8139405506475089, val_acc: 85.2937053133324
kfold: 1, epoch: 15. train_loss: 0.8267178433836008, train_acc: 84.7027481772294. val_loss: 0.8086744510138516, val_acc: 85.56007290060283
kfold: 1, epoch: 16. train_loss: 0.825055917560954, train_acc: 84.6747055524397. val_loss: 0.8084517311087638, val_acc: 85.47595682041216
kfold: 1, epoch: 17. train_loss: 0.8210667637513718, train_acc: 85.10235558048234. val_loss: 0.8142484533412574, val_acc: 85.0413570727604
kfold: 1, epoch: 18. train_loss: 0.8094689979422179, train_acc: 85.5440269209198. val_loss: 0.8110852643112431, val_acc: 85.2937053133324
kfold: 1, epoch: 19. train_loss: 0.8085853798765181, train_acc: 85.55103757711721. val_loss: 0.8003988106956397, val_acc: 85.78438244777793
kfold: 1, epoch: 20. train_loss: 0.8143605596218226, train_acc: 85.04627033090297. val_loss: 0.8001679147973724, val_acc: 85.7423244076826
kfold: 1, epoch: 21. train_loss: 0.8015435652925402, train_acc: 85.9296130117779. val_loss: 0.7971249013604604, val_acc: 86.0928080751437
kfold: 1, epoch: 22. train_loss: 0.7992830162494957, train_acc: 85.99270891755468. val_loss: 0.7983394999541509, val_acc: 85.8684985279686
kfold: 1, epoch: 23. train_loss: 0.7985603302232482, train_acc: 85.81043185642176. val_loss: 0.797298944317172, val_acc: 86.07878872844526
kfold: 1, epoch: 24. train_loss: 0.7916965917864344, train_acc: 86.58861469433539. val_loss: 0.7956420906188777, val_acc: 85.9666339548577
kfold: 1, epoch: 25. train_loss: 0.7895091001197186, train_acc: 86.59562535053281. val_loss: 0.796359184878824, val_acc: 86.12084676854059
kfold: 2, epoch: 1. train_loss: 1.2314662570843782, train_acc: 64.64072905713284. val_loss: 1.0891947572541343, val_acc: 73.79416713404375
kfold: 2, epoch: 2. train_loss: 1.048995402562244, train_acc: 73.78899404135997. val_loss: 0.9605780194425797, val_acc: 79.43073471676949
kfold: 2, epoch: 3. train_loss: 0.9864255468874769, train_acc: 76.90150718541885. val_loss: 0.9093203262630599, val_acc: 81.33763320246776
kfold: 2, epoch: 4. train_loss: 0.9490823624446788, train_acc: 78.5559060637925. val_loss: 0.8731783920473047, val_acc: 82.80987100392596
kfold: 2, epoch: 5. train_loss: 0.9384538169131685, train_acc: 79.03259726603575. val_loss: 0.8574819568160403, val_acc: 83.88951205832866
kfold: 2, epoch: 6. train_loss: 0.918275442692731, train_acc: 80.22432527164388. val_loss: 0.8502728375084198, val_acc: 83.88951205832866
kfold: 2, epoch: 7. train_loss: 0.8999162346726041, train_acc: 81.2968804766912. val_loss: 0.8358506875722398, val_acc: 84.49242849130678
kfold: 2, epoch: 8. train_loss: 0.889417460280149, train_acc: 81.38100245355766. val_loss: 0.8259136132862536, val_acc: 85.01121704991587
kfold: 2, epoch: 9. train_loss: 0.8795181289315224, train_acc: 81.97686645636172. val_loss: 0.8206459448209258, val_acc: 85.16545148625912
kfold: 2, epoch: 10. train_loss: 0.8751031843937032, train_acc: 82.36943568173852. val_loss: 0.8165174224852446, val_acc: 85.06730229949524
kfold: 2, epoch: 11. train_loss: 0.8670317759161038, train_acc: 83.01437083771468. val_loss: 0.8177178330351954, val_acc: 85.19349411104879
kfold: 2, epoch: 12. train_loss: 0.8593030165997856, train_acc: 82.95127935506484. val_loss: 0.8106965987938937, val_acc: 85.50196298373528
kfold: 2, epoch: 13. train_loss: 0.8441949628727853, train_acc: 83.93971258324571. val_loss: 0.8063352990043537, val_acc: 85.62815479528884
kfold: 2, epoch: 14. train_loss: 0.8404747297143722, train_acc: 83.93971258324571. val_loss: 0.8017172164580213, val_acc: 85.93662366797533