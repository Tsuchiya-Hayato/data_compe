filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b3, lr: 1e-05, weights: tensor([1.5000, 1.0000, 1.0000, 1.0000, 1.0000]). batchsize: 8, kfold: 3, epoch: 25, weght_decay: 1e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.2328504689342843, train_acc: 64.50504767246214. val_loss: 1.0766498839374081, val_acc: 74.12028599467264
kfold: 1, epoch: 2. train_loss: 1.044489420804159, train_acc: 73.7100392596747. val_loss: 0.9581017582405843, val_acc: 79.46165708677975
kfold: 1, epoch: 3. train_loss: 0.9773530033419657, train_acc: 77.30650588895121. val_loss: 0.9051968383147577, val_acc: 81.6206364783401
kfold: 1, epoch: 4. train_loss: 0.9468478219467672, train_acc: 78.65956253505328. val_loss: 0.8776068462919226, val_acc: 82.96649376139072
kfold: 1, epoch: 5. train_loss: 0.9238375531309987, train_acc: 79.73219293325856. val_loss: 0.8585144013433713, val_acc: 83.90578999018646
kfold: 1, epoch: 6. train_loss: 0.9123955284084956, train_acc: 80.20891755468311. val_loss: 0.8461032003297934, val_acc: 84.08804149726623
kfold: 1, epoch: 7. train_loss: 0.8966435907399193, train_acc: 80.93802579921481. val_loss: 0.8353717665902167, val_acc: 84.53666059161642
kfold: 1, epoch: 8. train_loss: 0.8863859425016286, train_acc: 81.80033651149748. val_loss: 0.8234914870005552, val_acc: 85.26566661993552
kfold: 1, epoch: 9. train_loss: 0.8753900629913813, train_acc: 82.17190128996074. val_loss: 0.8209443209951769, val_acc: 85.30772466003084
kfold: 1, epoch: 10. train_loss: 0.8686963381288564, train_acc: 82.73275378575434. val_loss: 0.8274864947982967, val_acc: 85.02733772606197
kfold: 1, epoch: 11. train_loss: 0.8560507668582362, train_acc: 82.99214806505888. val_loss: 0.8183729859077342, val_acc: 85.22360857984017
kfold: 1, epoch: 12. train_loss: 0.8493796076523208, train_acc: 83.70723499719574. val_loss: 0.8127119283237799, val_acc: 85.34978270012617
kfold: 1, epoch: 13. train_loss: 0.8402683860254101, train_acc: 83.74228827818284. val_loss: 0.8101875306244923, val_acc: 85.54605355390439
kfold: 1, epoch: 14. train_loss: 0.8361175292272348, train_acc: 84.06477846326416. val_loss: 0.8139405506475089, val_acc: 85.2937053133324
kfold: 1, epoch: 15. train_loss: 0.8267178433836008, train_acc: 84.7027481772294. val_loss: 0.8086744510138516, val_acc: 85.56007290060283
kfold: 1, epoch: 16. train_loss: 0.825055917560954, train_acc: 84.6747055524397. val_loss: 0.8084517311087638, val_acc: 85.47595682041216
kfold: 1, epoch: 17. train_loss: 0.8210667637513718, train_acc: 85.10235558048234. val_loss: 0.8142484533412574, val_acc: 85.0413570727604
kfold: 1, epoch: 18. train_loss: 0.8094689979422179, train_acc: 85.5440269209198. val_loss: 0.8110852643112431, val_acc: 85.2937053133324
kfold: 1, epoch: 19. train_loss: 0.8085853798765181, train_acc: 85.55103757711721. val_loss: 0.8003988106956397, val_acc: 85.78438244777793
kfold: 1, epoch: 20. train_loss: 0.8143605596218226, train_acc: 85.04627033090297. val_loss: 0.8001679147973724, val_acc: 85.7423244076826
kfold: 1, epoch: 21. train_loss: 0.8015435652925402, train_acc: 85.9296130117779. val_loss: 0.7971249013604604, val_acc: 86.0928080751437
kfold: 1, epoch: 22. train_loss: 0.7992830162494957, train_acc: 85.99270891755468. val_loss: 0.7983394999541509, val_acc: 85.8684985279686
kfold: 1, epoch: 23. train_loss: 0.7985603302232482, train_acc: 85.81043185642176. val_loss: 0.797298944317172, val_acc: 86.07878872844526
kfold: 1, epoch: 24. train_loss: 0.7916965917864344, train_acc: 86.58861469433539. val_loss: 0.7956420906188777, val_acc: 85.9666339548577
kfold: 1, epoch: 25. train_loss: 0.7895091001197186, train_acc: 86.59562535053281. val_loss: 0.796359184878824, val_acc: 86.12084676854059
kfold: 2, epoch: 1. train_loss: 1.2314662570843782, train_acc: 64.64072905713284. val_loss: 1.0891947572541343, val_acc: 73.79416713404375
kfold: 2, epoch: 2. train_loss: 1.048995402562244, train_acc: 73.78899404135997. val_loss: 0.9605780194425797, val_acc: 79.43073471676949
kfold: 2, epoch: 3. train_loss: 0.9864255468874769, train_acc: 76.90150718541885. val_loss: 0.9093203262630599, val_acc: 81.33763320246776
kfold: 2, epoch: 4. train_loss: 0.9490823624446788, train_acc: 78.5559060637925. val_loss: 0.8731783920473047, val_acc: 82.80987100392596
kfold: 2, epoch: 5. train_loss: 0.9384538169131685, train_acc: 79.03259726603575. val_loss: 0.8574819568160403, val_acc: 83.88951205832866
kfold: 2, epoch: 6. train_loss: 0.918275442692731, train_acc: 80.22432527164388. val_loss: 0.8502728375084198, val_acc: 83.88951205832866
kfold: 2, epoch: 7. train_loss: 0.8999162346726041, train_acc: 81.2968804766912. val_loss: 0.8358506875722398, val_acc: 84.49242849130678
kfold: 2, epoch: 8. train_loss: 0.889417460280149, train_acc: 81.38100245355766. val_loss: 0.8259136132862536, val_acc: 85.01121704991587
kfold: 2, epoch: 9. train_loss: 0.8795181289315224, train_acc: 81.97686645636172. val_loss: 0.8206459448209258, val_acc: 85.16545148625912
kfold: 2, epoch: 10. train_loss: 0.8751031843937032, train_acc: 82.36943568173852. val_loss: 0.8165174224852446, val_acc: 85.06730229949524
kfold: 2, epoch: 11. train_loss: 0.8670317759161038, train_acc: 83.01437083771468. val_loss: 0.8177178330351954, val_acc: 85.19349411104879
kfold: 2, epoch: 12. train_loss: 0.8593030165997856, train_acc: 82.95127935506484. val_loss: 0.8106965987938937, val_acc: 85.50196298373528
kfold: 2, epoch: 13. train_loss: 0.8441949628727853, train_acc: 83.93971258324571. val_loss: 0.8063352990043537, val_acc: 85.62815479528884
kfold: 2, epoch: 14. train_loss: 0.8404747297143722, train_acc: 83.93971258324571. val_loss: 0.8017172164580213, val_acc: 85.93662366797533
kfold: 2, epoch: 15. train_loss: 0.8372209627732567, train_acc: 84.12898703119524. val_loss: 0.8058354203075572, val_acc: 85.79641054402693
kfold: 2, epoch: 16. train_loss: 0.8273625308689515, train_acc: 84.35331230283911. val_loss: 0.7986145788644996, val_acc: 86.00673022994953
kfold: 2, epoch: 17. train_loss: 0.8243310987080694, train_acc: 84.76691202243252. val_loss: 0.797955807749466, val_acc: 86.00673022994953
kfold: 2, epoch: 18. train_loss: 0.8188558847313504, train_acc: 84.94917630564318. val_loss: 0.7982420633993876, val_acc: 86.00673022994953
kfold: 2, epoch: 19. train_loss: 0.8145547808218965, train_acc: 85.32071503680336. val_loss: 0.7890542037283893, val_acc: 86.81996634885026
kfold: 2, epoch: 20. train_loss: 0.812638939195417, train_acc: 85.27164388363127. val_loss: 0.7880258831475347, val_acc: 86.48345485137409
kfold: 2, epoch: 21. train_loss: 0.8136096826249174, train_acc: 85.49596915527515. val_loss: 0.7907317842736907, val_acc: 86.58160403813797
kfold: 2, epoch: 22. train_loss: 0.8086468168772389, train_acc: 85.6081317910971. val_loss: 0.7936378466842421, val_acc: 86.56758272574314
kfold: 2, epoch: 23. train_loss: 0.8054418243768504, train_acc: 85.81843673326323. val_loss: 0.7907442431145185, val_acc: 86.49747616376892
kfold: 2, epoch: 24. train_loss: 0.7994539069153803, train_acc: 85.97967052225728. val_loss: 0.7939883150461009, val_acc: 86.28715647784632
kfold: 2, epoch: 25. train_loss: 0.7942999297995204, train_acc: 86.24605678233438. val_loss: 0.7942416504225923, val_acc: 86.14694335389792
kfold: 3, epoch: 1. train_loss: 1.226684530086047, train_acc: 64.6267087276551. val_loss: 1.0685370772943368, val_acc: 74.48121144139091
kfold: 3, epoch: 2. train_loss: 1.0399228770436193, train_acc: 73.79600420609884. val_loss: 0.9472404686993013, val_acc: 79.94952327537858
kfold: 3, epoch: 3. train_loss: 0.9736872611091276, train_acc: 77.19593410445145. val_loss: 0.8898451929669744, val_acc: 82.10880538418397
kfold: 3, epoch: 4. train_loss: 0.9454355328072347, train_acc: 78.79425166491413. val_loss: 0.8689237255018388, val_acc: 83.1744251261918
kfold: 3, epoch: 5. train_loss: 0.9241846112592873, train_acc: 79.61444093936207. val_loss: 0.8485731115656583, val_acc: 84.14189568143578
kfold: 3, epoch: 6. train_loss: 0.9092141360779514, train_acc: 80.75008762705923. val_loss: 0.8370292801493486, val_acc: 84.7448121144139
kfold: 3, epoch: 7. train_loss: 0.8955373327026452, train_acc: 80.84822993340343. val_loss: 0.8290349096059799, val_acc: 84.95513180033652
kfold: 3, epoch: 8. train_loss: 0.8886432077050743, train_acc: 81.5913073957238. val_loss: 0.8156865021973982, val_acc: 85.01121704991587
kfold: 3, epoch: 9. train_loss: 0.8767740316187854, train_acc: 82.38345601121627. val_loss: 0.818021032174072, val_acc: 85.08132361189007
kfold: 3, epoch: 10. train_loss: 0.8714234333134553, train_acc: 82.4956186470382. val_loss: 0.8174361158245882, val_acc: 85.33370723499719
kfold: 3, epoch: 11. train_loss: 0.8670029742434421, train_acc: 82.60077111812127. val_loss: 0.8102754843609216, val_acc: 85.31968592260236
kfold: 3, epoch: 12. train_loss: 0.8581745864430885, train_acc: 83.16158429723099. val_loss: 0.8045155774183872, val_acc: 85.67021873247336
kfold: 3, epoch: 13. train_loss: 0.8415870252211533, train_acc: 83.7434279705573. val_loss: 0.809333303650933, val_acc: 85.22153673583847
kfold: 3, epoch: 14. train_loss: 0.842276046762552, train_acc: 83.6733263231686. val_loss: 0.7993247373355343, val_acc: 85.78238923163208
kfold: 3, epoch: 15. train_loss: 0.835604657907657, train_acc: 83.94672274798458. val_loss: 0.7982231587706126, val_acc: 86.11890072910825
kfold: 3, epoch: 16. train_loss: 0.8264731968598515, train_acc: 84.69681037504381. val_loss: 0.7955575722349064, val_acc: 86.28715647784632
kfold: 3, epoch: 17. train_loss: 0.8188104992022429, train_acc: 84.9702067998598. val_loss: 0.8006102925859759, val_acc: 85.964666292765
kfold: 3, epoch: 18. train_loss: 0.8166219497876317, train_acc: 85.29968454258675. val_loss: 0.798872759590769, val_acc: 86.35726303982052
kfold: 3, epoch: 19. train_loss: 0.8121529388588106, train_acc: 85.32772520154224. val_loss: 0.8063602857124645, val_acc: 85.8244531688166
kfold: 3, epoch: 20. train_loss: 0.8094966959191545, train_acc: 85.56607080266386. val_loss: 0.7963815900108739, val_acc: 86.46943353897925
kfold: 3, epoch: 21. train_loss: 0.8016031444273187, train_acc: 85.8044164037855. val_loss: 0.7904535336211124, val_acc: 86.74985978687606
kfold: 3, epoch: 22. train_loss: 0.8034974272809756, train_acc: 85.81843673326323. val_loss: 0.7941462384211109, val_acc: 86.55356141334829
kfold: 3, epoch: 23. train_loss: 0.795700242367026, train_acc: 86.1689449702068. val_loss: 0.7936383055464569, val_acc: 86.32922041503085
kfold: 3, epoch: 24. train_loss: 0.7927683193921509, train_acc: 86.0708026638626. val_loss: 0.796644609538429, val_acc: 86.11890072910825
kfold: 3, epoch: 25. train_loss: 0.7910346185011714, train_acc: 86.47739221871714. val_loss: 0.7938931037759567, val_acc: 86.74985978687606