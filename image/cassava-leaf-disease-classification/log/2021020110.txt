filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b3, lr: 1e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 8, kfold: 3, epoch: 25, weght_decay: 1e-05, smoothing: 0.2

kfold: 1, epoch: 1. train_loss: 1.275882589369093, train_acc: 64.34380257992149. val_loss: 1.1667685940393953, val_acc: 74.07822795457732
kfold: 1, epoch: 2. train_loss: 1.1474181884670953, train_acc: 73.47167694896243. val_loss: 1.0878256251993734, val_acc: 79.6999859806533
kfold: 1, epoch: 3. train_loss: 1.1036670334674774, train_acc: 77.01205832865956. val_loss: 1.052783625275565, val_acc: 81.76082994532455
kfold: 1, epoch: 4. train_loss: 1.083830539389935, train_acc: 78.37212563095906. val_loss: 1.0335215334801395, val_acc: 83.13472592177204
kfold: 1, epoch: 5. train_loss: 1.0670632144004792, train_acc: 79.67610768367919. val_loss: 1.0194942621773133, val_acc: 84.15813823075845
kfold: 1, epoch: 6. train_loss: 1.0590211580592597, train_acc: 80.04066180594504. val_loss: 1.0097099221207102, val_acc: 84.32637039113978
kfold: 1, epoch: 7. train_loss: 1.0472125167333204, train_acc: 81.07823892316321. val_loss: 1.0016910921565085, val_acc: 84.81704752558531
kfold: 1, epoch: 8. train_loss: 1.0397415330285646, train_acc: 81.67414469994391. val_loss: 0.9934360934880817, val_acc: 85.50399551380906
kfold: 1, epoch: 9. train_loss: 1.0308981808262867, train_acc: 82.17190128996074. val_loss: 0.9911630484421692, val_acc: 85.60213094069816
kfold: 1, epoch: 10. train_loss: 1.0249316587383936, train_acc: 82.83791362871565. val_loss: 0.9958059764362771, val_acc: 85.22360857984017
kfold: 1, epoch: 11. train_loss: 1.0166792442339962, train_acc: 83.09029725182278. val_loss: 0.9887401301230015, val_acc: 85.60213094069816
kfold: 1, epoch: 12. train_loss: 1.0109317456813456, train_acc: 83.64413909141895. val_loss: 0.9844108759822332, val_acc: 85.60213094069816
kfold: 1, epoch: 13. train_loss: 1.0044997848958963, train_acc: 83.99467190128996. val_loss: 0.9842421639660549, val_acc: 85.7703631010795
kfold: 1, epoch: 14. train_loss: 1.0023382087136277, train_acc: 84.26808749298934. val_loss: 0.9854798349698028, val_acc: 85.53203420720594
kfold: 1, epoch: 15. train_loss: 0.9963802115608318, train_acc: 84.89904655075715. val_loss: 0.9816925098008639, val_acc: 85.67222767419038
kfold: 1, epoch: 16. train_loss: 0.9957857833641404, train_acc: 84.62563095905777. val_loss: 0.9829383201796912, val_acc: 85.75634375438105
kfold: 1, epoch: 17. train_loss: 0.993635852385022, train_acc: 85.15143017386427. val_loss: 0.9851271681855077, val_acc: 85.48997616711061
kfold: 1, epoch: 18. train_loss: 0.9857383862146152, train_acc: 85.53000560852496. val_loss: 0.9834398298520144, val_acc: 85.6441889807935
kfold: 1, epoch: 19. train_loss: 0.9851513225512095, train_acc: 85.69125070106561. val_loss: 0.9774405904147657, val_acc: 86.19094350203281
kfold: 1, epoch: 20. train_loss: 0.9893945209844957, train_acc: 85.16545148625912. val_loss: 0.9760114733012802, val_acc: 86.16290480863591
kfold: 1, epoch: 21. train_loss: 0.9806680616139697, train_acc: 85.84548513740886. val_loss: 0.974599277625704, val_acc: 86.13486611523903
kfold: 1, epoch: 22. train_loss: 0.9788715427201314, train_acc: 85.99270891755468. val_loss: 0.9757079568946309, val_acc: 85.9666339548577
kfold: 1, epoch: 23. train_loss: 0.9785437722655407, train_acc: 85.97868760515985. val_loss: 0.9743113305269335, val_acc: 86.23300154212814
kfold: 1, epoch: 24. train_loss: 0.9732523368639152, train_acc: 86.56057206954571. val_loss: 0.9732659484506188, val_acc: 86.14888546193747
kfold: 1, epoch: 25. train_loss: 0.9722074188680644, train_acc: 86.63768928771734. val_loss: 0.9745045359091908, val_acc: 86.19094350203281
kfold: 2, epoch: 1. train_loss: 1.2746586405375613, train_acc: 64.51454609183315. val_loss: 1.1743391921301058, val_acc: 73.92035894559731
kfold: 2, epoch: 2. train_loss: 1.149612946995438, train_acc: 73.31931300385558. val_loss: 1.0904879491826345, val_acc: 79.15030846887268
kfold: 2, epoch: 3. train_loss: 1.1107110771363091, train_acc: 76.54398878373642. val_loss: 1.057250614858529, val_acc: 81.73022994952328
kfold: 2, epoch: 4. train_loss: 1.0851710555665697, train_acc: 78.42972309849281. val_loss: 1.031118007852892, val_acc: 82.71172181716209
kfold: 2, epoch: 5. train_loss: 1.076954169390982, train_acc: 79.00455660708026. val_loss: 1.0188795852687862, val_acc: 83.86146943353899
kfold: 2, epoch: 6. train_loss: 1.0625510637402, train_acc: 80.08412197686646. val_loss: 1.0123769292115097, val_acc: 84.09983174425126
kfold: 2, epoch: 7. train_loss: 1.0489128976392104, train_acc: 81.28987031195233. val_loss: 1.0028780622599904, val_acc: 84.68872686483455
kfold: 2, epoch: 8. train_loss: 1.0417359124852403, train_acc: 81.34595162986331. val_loss: 0.9957567589031742, val_acc: 85.15143017386427
kfold: 2, epoch: 9. train_loss: 1.0330786605453277, train_acc: 81.94181563266737. val_loss: 0.9914673820739369, val_acc: 85.38979248457656
kfold: 2, epoch: 10. train_loss: 1.0286084726920577, train_acc: 82.29232386961094. val_loss: 0.987911422290075, val_acc: 85.37577117218171
kfold: 2, epoch: 11. train_loss: 1.022724791592814, train_acc: 83.21766561514195. val_loss: 0.9890200103478581, val_acc: 85.51598429613011
kfold: 2, epoch: 12. train_loss: 1.0173597957588096, train_acc: 83.21766561514195. val_loss: 0.9829530415246305, val_acc: 85.79641054402693
kfold: 2, epoch: 13. train_loss: 1.0080307730110236, train_acc: 84.19908867858395. val_loss: 0.9818172218954616, val_acc: 85.97868760515985
kfold: 2, epoch: 14. train_loss: 1.0057984050613882, train_acc: 84.05888538380653. val_loss: 0.9787761254294571, val_acc: 86.1048794167134
kfold: 2, epoch: 15. train_loss: 1.0037054064696145, train_acc: 84.15702769015071. val_loss: 0.9816203247004026, val_acc: 85.92260235558048
kfold: 2, epoch: 16. train_loss: 0.9979860024535068, train_acc: 84.47248510339993. val_loss: 0.9763109252992767, val_acc: 86.27313516545149
kfold: 2, epoch: 17. train_loss: 0.9957594904931671, train_acc: 84.79495268138801. val_loss: 0.9764008244056873, val_acc: 86.28715647784632
kfold: 2, epoch: 18. train_loss: 0.9927581208236015, train_acc: 84.95618647038205. val_loss: 0.976103803301606, val_acc: 86.32922041503085
kfold: 2, epoch: 19. train_loss: 0.9896538315733452, train_acc: 85.285664213109. val_loss: 0.9696256665370924, val_acc: 86.86203028603477
kfold: 2, epoch: 20. train_loss: 0.988087343294257, train_acc: 85.27865404837014. val_loss: 0.9694333489432998, val_acc: 86.60964666292764
kfold: 2, epoch: 21. train_loss: 0.988423408748323, train_acc: 85.5099894847529. val_loss: 0.9712582491839413, val_acc: 87.12843522153673
kfold: 2, epoch: 22. train_loss: 0.9847496538819753, train_acc: 85.67122327374693. val_loss: 0.9727404524526254, val_acc: 86.81996634885026
kfold: 2, epoch: 23. train_loss: 0.9817952637982476, train_acc: 85.62916228531371. val_loss: 0.9705434874568819, val_acc: 86.77790241166574
kfold: 2, epoch: 24. train_loss: 0.9783142172635404, train_acc: 86.06379249912374. val_loss: 0.9723998546065771, val_acc: 86.81996634885026
kfold: 2, epoch: 25. train_loss: 0.975223360942351, train_acc: 86.22502628811777. val_loss: 0.9737912741209894, val_acc: 86.51149747616377
kfold: 3, epoch: 1. train_loss: 1.2714486883894744, train_acc: 64.71784086926043. val_loss: 1.1601169037177423, val_acc: 74.32697700504767
kfold: 3, epoch: 2. train_loss: 1.144164684575235, train_acc: 73.31230283911673. val_loss: 1.0819001155717491, val_acc: 79.71116096466629
kfold: 3, epoch: 3. train_loss: 1.1018465425936097, train_acc: 76.95758850332983. val_loss: 1.0428080901570385, val_acc: 82.13684800897364
kfold: 3, epoch: 4. train_loss: 1.0820610435687907, train_acc: 78.71012968804767. val_loss: 1.027141626707107, val_acc: 83.59506449803702
kfold: 3, epoch: 5. train_loss: 1.0676392371277639, train_acc: 79.57237995092885. val_loss: 1.012841331183643, val_acc: 84.52047111609647
kfold: 3, epoch: 6. train_loss: 1.056668233577446, train_acc: 80.61689449702068. val_loss: 1.00386724744677, val_acc: 84.96915311273135
kfold: 3, epoch: 7. train_loss: 1.0468971550531452, train_acc: 80.89730108657554. val_loss: 0.997271001004852, val_acc: 84.913067863152
kfold: 3, epoch: 8. train_loss: 1.0409129324114377, train_acc: 81.64738871363477. val_loss: 0.9877727654482752, val_acc: 85.45989904655076
kfold: 3, epoch: 9. train_loss: 1.030756725324109, train_acc: 82.57974062390466. val_loss: 0.9885016178603664, val_acc: 85.45989904655076
kfold: 3, epoch: 10. train_loss: 1.0268270308193606, train_acc: 82.46056782334385. val_loss: 0.9878735970622221, val_acc: 85.60011217049916
kfold: 3, epoch: 11. train_loss: 1.0237535940558387, train_acc: 82.81808622502629. val_loss: 0.983405345558051, val_acc: 85.74032529444756
kfold: 3, epoch: 12. train_loss: 1.0164160007786323, train_acc: 83.43498072204697. val_loss: 0.9795510504277832, val_acc: 85.99270891755468
kfold: 3, epoch: 13. train_loss: 1.005319867834382, train_acc: 84.19207851384508. val_loss: 0.984255774673325, val_acc: 85.65619742007851
kfold: 3, epoch: 14. train_loss: 1.007088976657444, train_acc: 83.9887837364178. val_loss: 0.9763287213618446, val_acc: 86.11890072910825
kfold: 3, epoch: 15. train_loss: 1.0017657000989122, train_acc: 84.36032246757799. val_loss: 0.9764305349155392, val_acc: 86.25911385305665
kfold: 3, epoch: 16. train_loss: 0.9971365288167257, train_acc: 84.7248510339993. val_loss: 0.9732585221261721, val_acc: 86.42736960179472
kfold: 3, epoch: 17. train_loss: 0.9914732856066237, train_acc: 85.14546091833158. val_loss: 0.9774155574662803, val_acc: 86.34324172742569
kfold: 3, epoch: 18. train_loss: 0.9908804573085276, train_acc: 85.2646337188924. val_loss: 0.9755225797004229, val_acc: 86.56758272574314
kfold: 3, epoch: 19. train_loss: 0.9879986297990709, train_acc: 85.41184717840869. val_loss: 0.9812129999222777, val_acc: 85.95064498037016
kfold: 3, epoch: 20. train_loss: 0.9853004181732511, train_acc: 85.68524360322468. val_loss: 0.9748675992269688, val_acc: 86.62366797532249
kfold: 3, epoch: 21. train_loss: 0.9805640129898696, train_acc: 86.09183315807921. val_loss: 0.9714725080359677, val_acc: 86.80594503645541
kfold: 3, epoch: 22. train_loss: 0.9818770291425722, train_acc: 85.90255871012968. val_loss: 0.9741898188409249, val_acc: 86.66573191250701
kfold: 3, epoch: 23. train_loss: 0.976947955152379, train_acc: 86.19698562916228. val_loss: 0.9730720997792188, val_acc: 86.41334828939989
kfold: 3, epoch: 24. train_loss: 0.9745882622262823, train_acc: 86.23904661759552. val_loss: 0.975212585832506, val_acc: 86.315199102636
kfold: 3, epoch: 25. train_loss: 0.9733646433516469, train_acc: 86.68769716088327. val_loss: 0.9727713213105907, val_acc: 86.48345485137409