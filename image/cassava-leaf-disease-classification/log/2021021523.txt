filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b5, lr: 1e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 2, kfold: 3, epoch: 25, weght_decay: 5e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.2129919557877624, train_acc: 62.52103196859226. val_loss: 1.3294346783553515, val_acc: 60.549558390579
kfold: 1, epoch: 2. train_loss: 1.1144375990046187, train_acc: 66.11048794167134. val_loss: 1.2193377118067878, val_acc: 67.06855460535539
kfold: 1, epoch: 3. train_loss: 1.091064975852386, train_acc: 68.04542905215928. val_loss: 1.234239719814368, val_acc: 64.3207626524604
kfold: 1, epoch: 4. train_loss: 1.0711895890253953, train_acc: 69.3073471676949. val_loss: 1.18811365165796, val_acc: 67.4891350063087
kfold: 1, epoch: 5. train_loss: 1.067992628849228, train_acc: 69.55973079080202. val_loss: 1.203698993581398, val_acc: 65.49838777512969
kfold: 1, epoch: 6. train_loss: 1.0621663521195956, train_acc: 69.41951766685362. val_loss: 1.169408316434449, val_acc: 68.68077947567643
kfold: 1, epoch: 7. train_loss: 1.0689909848866674, train_acc: 69.4125070106562. val_loss: 1.1739060178603784, val_acc: 67.79756063367446
kfold: 1, epoch: 8. train_loss: 1.0647542177377225, train_acc: 70.05047672462142. val_loss: 1.171145350534708, val_acc: 68.00785083415113
kfold: 1, epoch: 9. train_loss: 1.059110302354804, train_acc: 70.01542344363432. val_loss: 1.1936294821453657, val_acc: 66.4657226973223
kfold: 1, epoch: 10. train_loss: 1.0637305350248156, train_acc: 69.81912507010657. val_loss: 1.192089591853118, val_acc: 66.42366465722698
kfold: 1, epoch: 11. train_loss: 1.061387358140357, train_acc: 69.81912507010657. val_loss: 1.1796160788555456, val_acc: 67.43305761951493
kfold: 1, epoch: 12. train_loss: 1.0639970730645432, train_acc: 69.89624228827819. val_loss: 1.1758266440419078, val_acc: 67.68540586008692
kfold: 1, epoch: 13. train_loss: 1.0580987024110018, train_acc: 70.09955131800336. val_loss: 1.188265743762263, val_acc: 66.73209028459274
kfold: 1, epoch: 14. train_loss: 1.0569104159640517, train_acc: 69.81912507010657. val_loss: 1.1930488413844684, val_acc: 66.25543249684564
kfold: 1, epoch: 15. train_loss: 1.0597730577911344, train_acc: 70.00140213123949. val_loss: 1.1757793626532622, val_acc: 67.53119304640404
kfold: 1, epoch: 16. train_loss: 1.0579487223322313, train_acc: 69.75602916432977. val_loss: 1.1959734605513002, val_acc: 65.80681340249545
kfold: 1, epoch: 17. train_loss: 1.06117969568332, train_acc: 70.02944475602916. val_loss: 1.1750749979561907, val_acc: 67.89569606056358
kfold: 1, epoch: 18. train_loss: 1.061859314303283, train_acc: 69.5877734155917. val_loss: 1.2031783003716165, val_acc: 65.59652320201879
kfold: 1, epoch: 19. train_loss: 1.0603252668863459, train_acc: 69.70695457094784. val_loss: 1.1674264911713639, val_acc: 68.27421842142157
kfold: 1, epoch: 20. train_loss: 1.0662454109444621, train_acc: 69.68592260235557. val_loss: 1.2006977422584297, val_acc: 65.63858124211411
kfold: 1, epoch: 21. train_loss: 1.0647053618362228, train_acc: 69.77706113292204. val_loss: 1.1843545896718908, val_acc: 67.4190382728165
kfold: 1, epoch: 22. train_loss: 1.0629496450713025, train_acc: 69.91026360067302. val_loss: 1.2041386916485695, val_acc: 65.94700686947988
kfold: 1, epoch: 23. train_loss: 1.0643649192268902, train_acc: 70.14161525518789. val_loss: 1.183980963345098, val_acc: 67.46109631291182