model: efficientnet-b3, lr: 1e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 8, kfold: 3, epoch: 20, RandomHorizontalFlip:(True,),CenterCrop: True 

kfold: 1, epoch: 1. train_loss: 1.0060524588980437, train_acc: 64.72938867077958. val_loss: 0.7897979813573607, val_acc: 73.83989906070377
kfold: 1, epoch: 2. train_loss: 0.7294493612702215, train_acc: 73.94840157038699. val_loss: 0.6130006320340217, val_acc: 79.74204402074864
kfold: 1, epoch: 3. train_loss: 0.6194623470791123, train_acc: 77.69910263600673. val_loss: 0.5515850066695981, val_acc: 80.8215337165288
kfold: 1, epoch: 4. train_loss: 0.5626307669619597, train_acc: 80.20891755468311. val_loss: 0.5106473376811587, val_acc: 82.33562315996075
kfold: 1, epoch: 5. train_loss: 0.5262828461002649, train_acc: 81.16236679753224. val_loss: 0.5164167079573388, val_acc: 82.41973924015142
kfold: 1, epoch: 6. train_loss: 0.49308903393739406, train_acc: 82.38923163208077. val_loss: 0.49149990768585305, val_acc: 83.03659049488294
kfold: 1, epoch: 7. train_loss: 0.46664841624161735, train_acc: 83.53196859226024. val_loss: 0.479411559613764, val_acc: 83.62540305621758
kfold: 1, epoch: 8. train_loss: 0.4311613143545503, train_acc: 84.7448121144139. val_loss: 0.48284136821179663, val_acc: 83.87775129678957
kfold: 1, epoch: 9. train_loss: 0.4109800753877846, train_acc: 85.90858104318565. val_loss: 0.48832663485045325, val_acc: 83.05060984158138
kfold: 1, epoch: 10. train_loss: 0.3947954043658242, train_acc: 86.2100392596747. val_loss: 0.48613281887715826, val_acc: 83.6674610963129
kfold: 1, epoch: 11. train_loss: 0.3690677034400667, train_acc: 87.00925406618059. val_loss: 0.496591182597892, val_acc: 83.28893873545493
kfold: 1, epoch: 12. train_loss: 0.34114810268421286, train_acc: 87.94868199663489. val_loss: 0.4867760913743848, val_acc: 83.8216739099958
kfold: 1, epoch: 13. train_loss: 0.3241978099625046, train_acc: 88.47448121144139. val_loss: 0.5033860581701479, val_acc: 83.37305481564559
kfold: 1, epoch: 14. train_loss: 0.30261472114886767, train_acc: 89.3508132361189. val_loss: 0.506464502124237, val_acc: 83.8216739099958
kfold: 1, epoch: 15. train_loss: 0.2860278688821434, train_acc: 90.02383623107123. val_loss: 0.5177199524818036, val_acc: 84.14411888406
kfold: 1, epoch: 16. train_loss: 0.26372913059016423, train_acc: 90.56365675827257. val_loss: 0.5257165940235564, val_acc: 83.38707416234404
kfold: 1, epoch: 17. train_loss: 0.24342878213710142, train_acc: 91.58020190689848. val_loss: 0.5509084621158526, val_acc: 83.34501612224871
kfold: 1, epoch: 18. train_loss: 0.23540474419741653, train_acc: 91.74845765563657. val_loss: 0.5625544958173677, val_acc: 83.0225711481845
kfold: 1, epoch: 19. train_loss: 0.21779328705434778, train_acc: 92.45653393157599. val_loss: 0.5571092301130038, val_acc: 83.65344174961447
kfold: 1, epoch: 20. train_loss: 0.20039477058912486, train_acc: 93.30482333146382. val_loss: 0.5562000325373911, val_acc: 83.45717089583626
kfold: 2, epoch: 1. train_loss: 1.0183427900978002, train_acc: 64.05187521906765. val_loss: 0.8064100271750726, val_acc: 72.279865395401
kfold: 2, epoch: 2. train_loss: 0.7340483591127556, train_acc: 73.39642481598318. val_loss: 0.6414469143066706, val_acc: 78.88390353337073
kfold: 2, epoch: 3. train_loss: 0.6354180732282555, train_acc: 77.17490361023484. val_loss: 0.551061646816542, val_acc: 81.14133482893999
kfold: 2, epoch: 4. train_loss: 0.5716857344095884, train_acc: 80.02103049421662. val_loss: 0.5104669371114484, val_acc: 82.17891194615817
kfold: 2, epoch: 5. train_loss: 0.5306817455000072, train_acc: 81.35296179460218. val_loss: 0.4914880756292943, val_acc: 82.90802019068985
kfold: 2, epoch: 6. train_loss: 0.4977752534889787, train_acc: 82.45355765860498. val_loss: 0.48471614869411683, val_acc: 82.97812675266405
kfold: 2, epoch: 7. train_loss: 0.464860577159248, train_acc: 83.92569225376796. val_loss: 0.4775426487392441, val_acc: 83.244531688166
kfold: 2, epoch: 8. train_loss: 0.4409120413704437, train_acc: 84.57062740974413. val_loss: 0.4687611042658147, val_acc: 83.84744812114414
kfold: 2, epoch: 9. train_loss: 0.4124260432329112, train_acc: 85.43287767262531. val_loss: 0.4734231609581748, val_acc: 83.4127874369041
kfold: 2, epoch: 10. train_loss: 0.384089058627387, train_acc: 86.39327024185069. val_loss: 0.4683658250353316, val_acc: 83.95961862030286
kfold: 2, epoch: 11. train_loss: 0.3728577946537204, train_acc: 86.98212407991588. val_loss: 0.47989858873919355, val_acc: 83.56702187324734
kfold: 2, epoch: 12. train_loss: 0.3494328929616698, train_acc: 88.01261829652996. val_loss: 0.477818043111101, val_acc: 83.2024677509815
kfold: 2, epoch: 13. train_loss: 0.32610953037132145, train_acc: 88.69961444093936. val_loss: 0.48446040994105566, val_acc: 83.73527762198542
kfold: 2, epoch: 14. train_loss: 0.3081045184120528, train_acc: 89.28846827900456. val_loss: 0.49492660056770416, val_acc: 83.35670218732473
kfold: 2, epoch: 15. train_loss: 0.2887379675492803, train_acc: 89.78618997546442. val_loss: 0.5019369382886169, val_acc: 83.52495793606282
kfold: 2, epoch: 16. train_loss: 0.2696656370598138, train_acc: 91.10410094637224. val_loss: 0.5161247338114031, val_acc: 83.1043185642176
kfold: 2, epoch: 17. train_loss: 0.2466993112466298, train_acc: 91.61584297230985. val_loss: 0.5319571859700719, val_acc: 83.53897924845765
kfold: 2, epoch: 18. train_loss: 0.231934138109872, train_acc: 92.27479845776375. val_loss: 0.544388807541831, val_acc: 83.06225462703308
kfold: 2, epoch: 19. train_loss: 0.21471443807240576, train_acc: 92.5832457062741. val_loss: 0.5557547433206795, val_acc: 83.25855300056085
kfold: 2, epoch: 20. train_loss: 0.20100577898397143, train_acc: 93.21416053277252. val_loss: 0.5585114800337558, val_acc: 83.04823331463825
kfold: 3, epoch: 1. train_loss: 1.0057481691876067, train_acc: 64.79495268138801. val_loss: 0.7894017795109161, val_acc: 73.6399326977005
kfold: 3, epoch: 2. train_loss: 0.717202256199791, train_acc: 74.47599018576936. val_loss: 0.6220704271988484, val_acc: 78.57543466068424
kfold: 3, epoch: 3. train_loss: 0.6129531873966413, train_acc: 78.18436733263232. val_loss: 0.5586572726394965, val_acc: 80.42624789680315
kfold: 3, epoch: 4. train_loss: 0.5593608363777933, train_acc: 80.3925692253768. val_loss: 0.5230173649633879, val_acc: 81.42176107683679
kfold: 3, epoch: 5. train_loss: 0.5236680365873359, train_acc: 81.57027690150719. val_loss: 0.4849461603976552, val_acc: 82.96410544026921
kfold: 3, epoch: 6. train_loss: 0.4909567184403806, train_acc: 82.69891342446547. val_loss: 0.48043712752457757, val_acc: 82.97812675266405
kfold: 3, epoch: 7. train_loss: 0.46648496209180207, train_acc: 83.58920434630214. val_loss: 0.46786752212458527, val_acc: 83.45485137408862
kfold: 3, epoch: 8. train_loss: 0.4373551345797832, train_acc: 84.95618647038205. val_loss: 0.4654713885883713, val_acc: 83.59506449803702
kfold: 3, epoch: 9. train_loss: 0.41344749968031197, train_acc: 85.61514195583597. val_loss: 0.4700868958805692, val_acc: 83.46887268648345
kfold: 3, epoch: 10. train_loss: 0.38818537511115253, train_acc: 86.68769716088327. val_loss: 0.47315210264777524, val_acc: 83.45485137408862
kfold: 3, epoch: 11. train_loss: 0.3703808421979036, train_acc: 86.99614440939362. val_loss: 0.47206253694545797, val_acc: 84.04374649467191
kfold: 3, epoch: 12. train_loss: 0.3397630852127172, train_acc: 88.03364879074658. val_loss: 0.4827054751235073, val_acc: 83.32865956253505
kfold: 3, epoch: 13. train_loss: 0.32648849056515794, train_acc: 88.78373641780581. val_loss: 0.4822648615401965, val_acc: 83.74929893438026
kfold: 3, epoch: 14. train_loss: 0.3038926344414998, train_acc: 89.50578338590957. val_loss: 0.49938237469334307, val_acc: 83.52495793606282
kfold: 3, epoch: 15. train_loss: 0.275963241337786, train_acc: 90.22082018927445. val_loss: 0.5056350965098783, val_acc: 83.8334268087493
kfold: 3, epoch: 16. train_loss: 0.2619620983109333, train_acc: 91.01296880476691. val_loss: 0.5152413838605904, val_acc: 83.44083006169377
kfold: 3, epoch: 17. train_loss: 0.2486815319452414, train_acc: 91.49667017174903. val_loss: 0.5251041606714377, val_acc: 83.30061693774537
kfold: 3, epoch: 18. train_loss: 0.23493064516599838, train_acc: 92.2888187872415. val_loss: 0.556653751627304, val_acc: 83.04823331463825
kfold: 3, epoch: 19. train_loss: 0.21870072021863252, train_acc: 92.71643883631265. val_loss: 0.5620921961148792, val_acc: 82.68367919237241
kfold: 3, epoch: 20. train_loss: 0.19580766008323738, train_acc: 93.64178058184368. val_loss: 0.5668187624608603, val_acc: 83.39876612450925