model: efficientnet-b1, lr: 1e-05, weights: tensor([0.5000, 1.0000, 1.1000, 6.1000, 1.2000]). batchsize: 16, kfold: 3, epoch: 20, RandomHorizontalFlip:(True,),CenterCrop: True 

kfold: 1, epoch: 1. train_loss: 0.7325284532501024, train_acc: 60.52299495232754. val_loss: 0.4213736776279227, val_acc: 64.68526566661994
kfold: 1, epoch: 2. train_loss: 0.34028463028872497, train_acc: 65.07291082445317. val_loss: 0.3257555218722521, val_acc: 67.15267068554606
kfold: 1, epoch: 3. train_loss: 0.29765769835110467, train_acc: 66.88166012338755. val_loss: 0.2900483693108965, val_acc: 69.45184354409085
kfold: 1, epoch: 4. train_loss: 0.26975432570372193, train_acc: 69.26528323051038. val_loss: 0.2668671036147483, val_acc: 72.83050609841581
kfold: 1, epoch: 5. train_loss: 0.2473781545199621, train_acc: 71.52271452607964. val_loss: 0.24768425411473743, val_acc: 74.98948548997616
kfold: 1, epoch: 6. train_loss: 0.22778019097721364, train_acc: 73.93438025799215. val_loss: 0.23736011593147377, val_acc: 76.96621337445676
kfold: 1, epoch: 7. train_loss: 0.21156718946508896, train_acc: 75.82024677509816. val_loss: 0.22921109111820903, val_acc: 78.03168372353848
kfold: 1, epoch: 8. train_loss: 0.2038956626815379, train_acc: 77.05412226584409. val_loss: 0.22130001737681873, val_acc: 78.71863171176223
kfold: 1, epoch: 9. train_loss: 0.1890115736912719, train_acc: 78.28799775659002. val_loss: 0.21832304336798833, val_acc: 79.54577316697042
kfold: 1, epoch: 10. train_loss: 0.1822046614690546, train_acc: 79.2274256870443. val_loss: 0.21759677820759638, val_acc: 80.19066311509884
kfold: 1, epoch: 11. train_loss: 0.1744540953975288, train_acc: 79.89343802579921. val_loss: 0.22501253930125134, val_acc: 80.63928220944904
kfold: 1, epoch: 12. train_loss: 0.16659186550336702, train_acc: 80.7627593942793. val_loss: 0.22437073375545274, val_acc: 81.08790130379924
kfold: 1, epoch: 13. train_loss: 0.15308081145678132, train_acc: 81.67414469994391. val_loss: 0.22750596988595387, val_acc: 81.15799803729146
kfold: 1, epoch: 14. train_loss: 0.14934002153466835, train_acc: 82.24901850813237. val_loss: 0.2288617530186147, val_acc: 81.38230758446656
kfold: 1, epoch: 15. train_loss: 0.14114664420861367, train_acc: 83.32865956253505. val_loss: 0.22700419187579188, val_acc: 81.49446235805411
kfold: 1, epoch: 16. train_loss: 0.13633285764596453, train_acc: 83.56001121704992. val_loss: 0.24228808829026305, val_acc: 81.92906210570587
kfold: 1, epoch: 17. train_loss: 0.13520561992253424, train_acc: 83.84744812114414. val_loss: 0.24596343413538263, val_acc: 81.88700406561054
kfold: 1, epoch: 18. train_loss: 0.12493281058691476, train_acc: 84.66068424004487. val_loss: 0.23876008392215578, val_acc: 81.81690733211832
kfold: 1, epoch: 19. train_loss: 0.11796169650987325, train_acc: 85.29865395401009. val_loss: 0.25519114185433683, val_acc: 82.2234683863732
kfold: 1, epoch: 20. train_loss: 0.11294457661155026, train_acc: 85.97868760515985. val_loss: 0.25973321061013394, val_acc: 82.18141034627786
kfold: 2, epoch: 1. train_loss: 0.7237644521143671, train_acc: 60.4416403785489. val_loss: 0.4290091683044027, val_acc: 65.2551878855861
kfold: 2, epoch: 2. train_loss: 0.3438052282305309, train_acc: 64.89309498773221. val_loss: 0.33041021257906217, val_acc: 67.75098149186763
kfold: 2, epoch: 3. train_loss: 0.29835243561543157, train_acc: 66.70872765509989. val_loss: 0.29138585637770426, val_acc: 70.00841278743691
kfold: 2, epoch: 4. train_loss: 0.2742584444866453, train_acc: 68.69260427620048. val_loss: 0.2719822151778525, val_acc: 72.71452607964106
kfold: 2, epoch: 5. train_loss: 0.25083412610061234, train_acc: 71.30038555906064. val_loss: 0.25144376338463725, val_acc: 74.63544587773416
kfold: 2, epoch: 6. train_loss: 0.23256663737125327, train_acc: 73.74693305292675. val_loss: 0.23725700043058315, val_acc: 76.68255748738082
kfold: 2, epoch: 7. train_loss: 0.21363621759708687, train_acc: 75.16298633017875. val_loss: 0.23010579154162664, val_acc: 77.77621985417835
kfold: 2, epoch: 8. train_loss: 0.20635416719126995, train_acc: 76.76130389064143. val_loss: 0.22760005478617723, val_acc: 78.54739203589456
kfold: 2, epoch: 9. train_loss: 0.19426304363382504, train_acc: 77.74272695408342. val_loss: 0.22586092556254614, val_acc: 79.71116096466629
kfold: 2, epoch: 10. train_loss: 0.1821855008560379, train_acc: 79.0466175955135. val_loss: 0.22373120889752568, val_acc: 80.03365114974761
kfold: 2, epoch: 11. train_loss: 0.17420323410660296, train_acc: 79.84577637574483. val_loss: 0.22394428906686636, val_acc: 80.01962983735278
kfold: 2, epoch: 12. train_loss: 0.16817391464160963, train_acc: 80.60287416754294. val_loss: 0.22319331101555326, val_acc: 80.79080201906899
kfold: 2, epoch: 13. train_loss: 0.16207768890438726, train_acc: 81.23378899404136. val_loss: 0.22892907786396052, val_acc: 80.74873808188447
kfold: 2, epoch: 14. train_loss: 0.15088812574836105, train_acc: 82.51664914125482. val_loss: 0.23250086877010595, val_acc: 81.05720695457094
kfold: 2, epoch: 15. train_loss: 0.14484674677737225, train_acc: 82.93024886084822. val_loss: 0.23325194898291152, val_acc: 81.15535614133483
kfold: 2, epoch: 16. train_loss: 0.1369859444148705, train_acc: 83.72940764107956. val_loss: 0.23822516790536888, val_acc: 81.32361189007291
kfold: 2, epoch: 17. train_loss: 0.13356264007816535, train_acc: 84.31826147914477. val_loss: 0.23977565102596587, val_acc: 81.43578238923163
kfold: 2, epoch: 18. train_loss: 0.12715947013995674, train_acc: 84.50052576235541. val_loss: 0.24440515013996328, val_acc: 81.39371845204711
kfold: 2, epoch: 19. train_loss: 0.12240317201496607, train_acc: 85.33473536628111. val_loss: 0.2586696200624041, val_acc: 81.33763320246776
kfold: 2, epoch: 20. train_loss: 0.1211922462056537, train_acc: 85.53803014370838. val_loss: 0.25598330017505005, val_acc: 81.94054963544588
kfold: 3, epoch: 1. train_loss: 0.7127890795335642, train_acc: 61.03750438135296. val_loss: 0.40360702961816913, val_acc: 65.26920919798093