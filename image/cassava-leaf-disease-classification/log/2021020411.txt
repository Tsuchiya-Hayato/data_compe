filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b4, lr: 1e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 4, kfold: 3, epoch: 25, weght_decay: 5e-05, smoothing: 0.1

kfold: 1, epoch: 1. train_loss: 1.1393599639898997, train_acc: 65.11497476163768. val_loss: 0.9375215444062323, val_acc: 76.29328473293144
kfold: 1, epoch: 2. train_loss: 0.9697285317431924, train_acc: 74.36904094223219. val_loss: 0.8553089256745016, val_acc: 80.54114678255993
kfold: 1, epoch: 3. train_loss: 0.9139982317012812, train_acc: 77.04711160964666. val_loss: 0.7989561949844051, val_acc: 83.16276461516894
kfold: 1, epoch: 4. train_loss: 0.8799550759528235, train_acc: 78.90493550196298. val_loss: 0.7804316127747966, val_acc: 84.42450581802888
kfold: 1, epoch: 5. train_loss: 0.8577544773086295, train_acc: 80.3771733034212. val_loss: 0.7680616251322453, val_acc: 85.27968596663395
kfold: 1, epoch: 6. train_loss: 0.829135725388551, train_acc: 81.60403813796971. val_loss: 0.7643203792984977, val_acc: 85.54605355390439
kfold: 1, epoch: 7. train_loss: 0.8162056516878938, train_acc: 82.41026360067302. val_loss: 0.7410749914333424, val_acc: 86.20496284873126
kfold: 1, epoch: 8. train_loss: 0.8025269371635514, train_acc: 83.18844643858665. val_loss: 0.741082098251501, val_acc: 86.58348520958923
kfold: 1, epoch: 9. train_loss: 0.7910846116348257, train_acc: 83.58104318564217. val_loss: 0.7391221429400915, val_acc: 86.28907892892191
kfold: 1, epoch: 10. train_loss: 0.7857394906004292, train_acc: 83.98766124509254. val_loss: 0.7363118892493804, val_acc: 86.12084676854059
kfold: 1, epoch: 11. train_loss: 0.7795993803561034, train_acc: 84.28210880538418. val_loss: 0.7321366084063, val_acc: 86.10682742184214
kfold: 1, epoch: 12. train_loss: 0.7690218411682699, train_acc: 84.57655636567583. val_loss: 0.7276124275485764, val_acc: 87.01808495724099
kfold: 1, epoch: 13. train_loss: 0.7613077134194831, train_acc: 84.96915311273135. val_loss: 0.73633163490838, val_acc: 86.5414271694939
kfold: 1, epoch: 14. train_loss: 0.751007984561059, train_acc: 85.65619742007851. val_loss: 0.7309207345271325, val_acc: 86.79377541006589
kfold: 1, epoch: 15. train_loss: 0.747102777959922, train_acc: 86.16096466629277. val_loss: 0.7331528447468184, val_acc: 86.62554324968457
kfold: 1, epoch: 16. train_loss: 0.7411596386437996, train_acc: 86.11890072910825. val_loss: 0.7432427195990834, val_acc: 86.63956259638302
kfold: 1, epoch: 17. train_loss: 0.7402338830694615, train_acc: 86.46242288278182. val_loss: 0.7468620246201085, val_acc: 86.75171736997056
kfold: 1, epoch: 18. train_loss: 0.7304368857095834, train_acc: 86.49747616376892. val_loss: 0.7322839887754264, val_acc: 87.13023973082855
kfold: 1, epoch: 19. train_loss: 0.7317142076476932, train_acc: 86.67274256870444. val_loss: 0.7400097458084602, val_acc: 86.84985279685966
kfold: 1, epoch: 20. train_loss: 0.7231141980267347, train_acc: 86.96017947279866. val_loss: 0.7316810104645154, val_acc: 87.08818169073321
kfold: 1, epoch: 21. train_loss: 0.7224019301185031, train_acc: 86.92512619181156. val_loss: 0.7365783971688405, val_acc: 87.2143558110192
kfold: 1, epoch: 22. train_loss: 0.7211230474279225, train_acc: 87.04430734716769. val_loss: 0.7527652741347193, val_acc: 87.08818169073321
kfold: 1, epoch: 23. train_loss: 0.7170009871362905, train_acc: 87.2546270330903. val_loss: 0.7318822720292705, val_acc: 87.42464601149587
kfold: 1, epoch: 24. train_loss: 0.7148454810586192, train_acc: 87.41587212563095. val_loss: 0.7346094603996908, val_acc: 87.42464601149587
kfold: 1, epoch: 25. train_loss: 0.7098004069979513, train_acc: 87.5701065619742. val_loss: 0.7312324373845027, val_acc: 87.49474274498809
kfold: 2, epoch: 1. train_loss: 1.1353174239639345, train_acc: 66.12688398177357. val_loss: 0.9558266899222012, val_acc: 76.23387549074593
kfold: 2, epoch: 2. train_loss: 0.9667970532123735, train_acc: 74.39887837364178. val_loss: 0.8329765409214471, val_acc: 81.92652832305103
kfold: 2, epoch: 3. train_loss: 0.9231306742746221, train_acc: 76.90150718541885. val_loss: 0.7841897029523694, val_acc: 83.81940549635446
kfold: 2, epoch: 4. train_loss: 0.8888814587919927, train_acc: 78.86435331230284. val_loss: 0.7709183620056007, val_acc: 84.8429613011778
kfold: 2, epoch: 5. train_loss: 0.8633622282404241, train_acc: 80.16824395373291. val_loss: 0.7609168758100829, val_acc: 85.57206954570948
kfold: 2, epoch: 6. train_loss: 0.8414613934652058, train_acc: 81.27584998247458. val_loss: 0.7453534674657842, val_acc: 86.35726303982052
kfold: 2, epoch: 7. train_loss: 0.8226782771546466, train_acc: 82.4465474938661. val_loss: 0.7387543661301549, val_acc: 86.41334828939989
kfold: 2, epoch: 8. train_loss: 0.8114736465586311, train_acc: 82.74097441289871. val_loss: 0.7361814965709701, val_acc: 86.89007291082446
kfold: 2, epoch: 9. train_loss: 0.7991231749179418, train_acc: 83.15457413249212. val_loss: 0.7278453741291568, val_acc: 87.70330902972518
kfold: 2, epoch: 10. train_loss: 0.7867697841869805, train_acc: 83.91167192429022. val_loss: 0.7233033691205406, val_acc: 87.73135165451487
kfold: 2, epoch: 11. train_loss: 0.7792703110044799, train_acc: 84.44444444444444. val_loss: 0.7098511791235934, val_acc: 88.09590577678071
kfold: 2, epoch: 12. train_loss: 0.7733311458465463, train_acc: 84.56361724500526. val_loss: 0.7129787857019025, val_acc: 87.78743690409422
kfold: 2, epoch: 13. train_loss: 0.7669659492128664, train_acc: 84.90010515247108. val_loss: 0.7140841353862257, val_acc: 87.85754346606842
kfold: 2, epoch: 14. train_loss: 0.7667168327028892, train_acc: 84.8229933403435. val_loss: 0.7159971960026832, val_acc: 87.92765002804262
kfold: 2, epoch: 15. train_loss: 0.7581767354036266, train_acc: 85.18752190676481. val_loss: 0.7098156028561423, val_acc: 87.85754346606842
kfold: 2, epoch: 16. train_loss: 0.7537815695488055, train_acc: 85.55205047318611. val_loss: 0.7134613435855423, val_acc: 88.33426808749299
kfold: 2, epoch: 17. train_loss: 0.7442715968325722, train_acc: 86.2180161233789. val_loss: 0.7137121313486083, val_acc: 88.12394840157039
kfold: 2, epoch: 18. train_loss: 0.7401052292050987, train_acc: 86.06379249912374. val_loss: 0.7065079378834348, val_acc: 88.34828939988783
kfold: 2, epoch: 19. train_loss: 0.738895533806408, train_acc: 86.13389414651245. val_loss: 0.7124293125117019, val_acc: 88.06786315199102
kfold: 2, epoch: 20. train_loss: 0.7339578090861695, train_acc: 86.35821941815632. val_loss: 0.7151568406462603, val_acc: 88.13796971396523
kfold: 2, epoch: 21. train_loss: 0.730409243676988, train_acc: 86.51945320715036. val_loss: 0.7193909073671597, val_acc: 88.20807627593943
kfold: 2, epoch: 22. train_loss: 0.7288694953113034, train_acc: 86.4633718892394. val_loss: 0.7107707668206562, val_acc: 88.44643858665171
kfold: 2, epoch: 23. train_loss: 0.7248627025438752, train_acc: 86.70171749036102. val_loss: 0.7214815595714282, val_acc: 88.05384183959619
kfold: 2, epoch: 24. train_loss: 0.7172571528282091, train_acc: 87.20644935155975. val_loss: 0.7166394010161123, val_acc: 88.37633202467751
kfold: 2, epoch: 25. train_loss: 0.7235076176725852, train_acc: 86.7788293024886. val_loss: 0.7146692674312441, val_acc: 88.29220415030846
kfold: 3, epoch: 1. train_loss: 1.1439109954440965, train_acc: 65.14546091833158. val_loss: 0.9658981075262796, val_acc: 74.83174425126192
kfold: 3, epoch: 2. train_loss: 0.9735378402770651, train_acc: 74.20259376095338. val_loss: 0.8292324704463336, val_acc: 81.57599551318003
kfold: 3, epoch: 3. train_loss: 0.9195127518513907, train_acc: 77.04171048019629. val_loss: 0.786575994529018, val_acc: 83.67919237240606
kfold: 3, epoch: 4. train_loss: 0.8900884238317429, train_acc: 78.61198738170347. val_loss: 0.7676218442380662, val_acc: 85.27762198541784
kfold: 3, epoch: 5. train_loss: 0.8555910254864924, train_acc: 80.61689449702068. val_loss: 0.760332121935308, val_acc: 85.83847448121143
kfold: 3, epoch: 6. train_loss: 0.8363918288936459, train_acc: 81.21976866456362. val_loss: 0.7614570163436907, val_acc: 85.47392035894559
kfold: 3, epoch: 7. train_loss: 0.811228481600991, train_acc: 82.97230984928146. val_loss: 0.7458370381102292, val_acc: 86.45541222658441
kfold: 3, epoch: 8. train_loss: 0.8062705152386338, train_acc: 82.55169996494918. val_loss: 0.7585002435136229, val_acc: 85.58609085810431
kfold: 3, epoch: 9. train_loss: 0.7939162069437115, train_acc: 83.70837714686296. val_loss: 0.739033091339046, val_acc: 86.76388109927089
kfold: 3, epoch: 10. train_loss: 0.7875929285923841, train_acc: 83.65930599369085. val_loss: 0.7325491992964613, val_acc: 86.66573191250701
kfold: 3, epoch: 11. train_loss: 0.780383561442538, train_acc: 84.34630213810024. val_loss: 0.7383659596498, val_acc: 86.46943353897925
kfold: 3, epoch: 12. train_loss: 0.7714614497619348, train_acc: 84.80897301086576. val_loss: 0.7370136637434956, val_acc: 86.62366797532249
kfold: 3, epoch: 13. train_loss: 0.7602699468842333, train_acc: 85.32071503680336. val_loss: 0.7230756128863945, val_acc: 87.3247335950645
kfold: 3, epoch: 14. train_loss: 0.7565246520672053, train_acc: 85.25762355415353. val_loss: 0.7324561096949318, val_acc: 87.3948401570387
kfold: 3, epoch: 15. train_loss: 0.7490749626825395, train_acc: 86.10585348755696. val_loss: 0.728386124181266, val_acc: 87.35277621985418
kfold: 3, epoch: 16. train_loss: 0.7453870986702398, train_acc: 86.26007711181212. val_loss: 0.7358526488702349, val_acc: 87.22658440830061
kfold: 3, epoch: 17. train_loss: 0.7372364436490615, train_acc: 86.2180161233789. val_loss: 0.7523362855528822, val_acc: 86.56758272574314
kfold: 3, epoch: 18. train_loss: 0.7404307914792839, train_acc: 86.29512793550649. val_loss: 0.7363518816964786, val_acc: 87.26864834548513
kfold: 3, epoch: 19. train_loss: 0.7348871044261067, train_acc: 86.39327024185069. val_loss: 0.7354602489121095, val_acc: 87.70330902972518
kfold: 3, epoch: 20. train_loss: 0.72941587955169, train_acc: 86.66666666666667. val_loss: 0.7387188117923993, val_acc: 87.24060572069546
kfold: 3, epoch: 21. train_loss: 0.7246510227805331, train_acc: 87.08727655099895. val_loss: 0.7497008806089304, val_acc: 87.35277621985418
kfold: 3, epoch: 22. train_loss: 0.7222425334671482, train_acc: 87.50788643533123. val_loss: 0.73511831377974, val_acc: 87.8855860908581
kfold: 3, epoch: 23. train_loss: 0.7188933402558886, train_acc: 87.37469330529268. val_loss: 0.7425311947229934, val_acc: 87.4649467190129
kfold: 3, epoch: 24. train_loss: 0.7138710912449674, train_acc: 87.45180511742026. val_loss: 0.7402358199864107, val_acc: 87.47896803140775
kfold: 3, epoch: 25. train_loss: 0.7069795105030866, train_acc: 87.98457763757449. val_loss: 0.7317385400571785, val_acc: 87.77341559169939