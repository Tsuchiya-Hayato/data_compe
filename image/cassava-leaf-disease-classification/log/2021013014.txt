model: efficientnet-b3, lr: 1e-05, weights: tensor([1.5000, 1.0000, 1.0000, 1.0000, 1.0000]). batchsize: 8, kfold: 3, epoch: 25, weght_decay: 1e-05,

kfold: 1, epoch: 1. train_loss: 1.232850461947537, train_acc: 64.50504767246214. val_loss: 1.0766499529638633, val_acc: 74.12028599467264
kfold: 1, epoch: 2. train_loss: 1.0444894166589118, train_acc: 73.7100392596747. val_loss: 0.9581018415668086, val_acc: 79.46165708677975
kfold: 1, epoch: 3. train_loss: 0.9773530078549366, train_acc: 77.30650588895121. val_loss: 0.9051969179658077, val_acc: 81.6206364783401
kfold: 1, epoch: 4. train_loss: 0.946847822247632, train_acc: 78.65956253505328. val_loss: 0.8776071330223383, val_acc: 82.96649376139072
kfold: 1, epoch: 5. train_loss: 0.923837550490075, train_acc: 79.73219293325856. val_loss: 0.858514351160537, val_acc: 83.90578999018646
kfold: 1, epoch: 6. train_loss: 0.9123955218229011, train_acc: 80.20891755468311. val_loss: 0.8461031883019503, val_acc: 84.08804149726623
kfold: 1, epoch: 7. train_loss: 0.896643584655766, train_acc: 80.93802579921481. val_loss: 0.8353718632807111, val_acc: 84.53666059161642
kfold: 1, epoch: 8. train_loss: 0.8863859393592638, train_acc: 81.80033651149748. val_loss: 0.8234916776418686, val_acc: 85.26566661993552
kfold: 1, epoch: 9. train_loss: 0.8753900582444046, train_acc: 82.17190128996074. val_loss: 0.8209442144819439, val_acc: 85.30772466003084
kfold: 1, epoch: 10. train_loss: 0.8686963330810149, train_acc: 82.73275378575434. val_loss: 0.8274867804595708, val_acc: 85.02733772606197
kfold: 1, epoch: 11. train_loss: 0.8560507626127006, train_acc: 82.99214806505888. val_loss: 0.818372968333719, val_acc: 85.22360857984017
kfold: 1, epoch: 12. train_loss: 0.849379604108803, train_acc: 83.70723499719574. val_loss: 0.8127119870597471, val_acc: 85.34978270012617
kfold: 1, epoch: 13. train_loss: 0.8402683947504871, train_acc: 83.74228827818284. val_loss: 0.810187615955357, val_acc: 85.54605355390439
kfold: 1, epoch: 14. train_loss: 0.836117527455476, train_acc: 84.06477846326416. val_loss: 0.8139404387217466, val_acc: 85.2937053133324
kfold: 1, epoch: 15. train_loss: 0.8267178405086713, train_acc: 84.7027481772294. val_loss: 0.8086744441312524, val_acc: 85.56007290060283
kfold: 1, epoch: 16. train_loss: 0.8250559134491361, train_acc: 84.6747055524397. val_loss: 0.8084519419969465, val_acc: 85.47595682041216
kfold: 1, epoch: 17. train_loss: 0.8210667595058362, train_acc: 85.10235558048234. val_loss: 0.8142485698776929, val_acc: 85.0413570727604
kfold: 1, epoch: 18. train_loss: 0.8094689962707472, train_acc: 85.5440269209198. val_loss: 0.8110853310657724, val_acc: 85.2937053133324
kfold: 1, epoch: 19. train_loss: 0.8085853845900655, train_acc: 85.55103757711721. val_loss: 0.8003988684292866, val_acc: 85.78438244777793
kfold: 1, epoch: 20. train_loss: 0.8143605599895463, train_acc: 85.04627033090297. val_loss: 0.8001679706600214, val_acc: 85.7423244076826
kfold: 1, epoch: 21. train_loss: 0.8015435688026287, train_acc: 85.9296130117779. val_loss: 0.7971247946467634, val_acc: 86.0928080751437
kfold: 1, epoch: 22. train_loss: 0.7992830129065543, train_acc: 85.99270891755468. val_loss: 0.798339434803334, val_acc: 85.8684985279686
kfold: 1, epoch: 23. train_loss: 0.7985603288192129, train_acc: 85.81043185642176. val_loss: 0.7972989497965227, val_acc: 86.07878872844526
kfold: 1, epoch: 24. train_loss: 0.7916965911512754, train_acc: 86.58861469433539. val_loss: 0.7956423531599643, val_acc: 85.9666339548577
kfold: 1, epoch: 25. train_loss: 0.7895090949381595, train_acc: 86.59562535053281. val_loss: 0.7963593890848716, val_acc: 86.12084676854059
kfold: 2, epoch: 1. train_loss: 1.2314662564829861, train_acc: 64.64072905713284. val_loss: 1.0891949823084432, val_acc: 73.79416713404375
kfold: 2, epoch: 2. train_loss: 1.048995397016072, train_acc: 73.78899404135997. val_loss: 0.9605779448699524, val_acc: 79.43073471676949
kfold: 2, epoch: 3. train_loss: 0.9864255467538342, train_acc: 76.90150718541885. val_loss: 0.909320414868171, val_acc: 81.33763320246776
kfold: 2, epoch: 4. train_loss: 0.9490823574998988, train_acc: 78.5559060637925. val_loss: 0.8731786883331735, val_acc: 82.80987100392596
kfold: 2, epoch: 5. train_loss: 0.9384538221920552, train_acc: 79.03259726603575. val_loss: 0.8574816191009342, val_acc: 83.88951205832866
kfold: 2, epoch: 6. train_loss: 0.918275446702012, train_acc: 80.22432527164388. val_loss: 0.8502724597005031, val_acc: 83.88951205832866
kfold: 2, epoch: 7. train_loss: 0.8999162329018383, train_acc: 81.2968804766912. val_loss: 0.8358506697309391, val_acc: 84.49242849130678
kfold: 2, epoch: 8. train_loss: 0.8894174612156479, train_acc: 81.38100245355766. val_loss: 0.825913693405053, val_acc: 85.01121704991587
kfold: 2, epoch: 9. train_loss: 0.8795181243876705, train_acc: 81.97686645636172. val_loss: 0.8206458693796209, val_acc: 85.16545148625912
kfold: 2, epoch: 10. train_loss: 0.875103187500896, train_acc: 82.36943568173852. val_loss: 0.8165173302049594, val_acc: 85.06730229949524
kfold: 2, epoch: 11. train_loss: 0.8670317729759643, train_acc: 83.01437083771468. val_loss: 0.8177179812449511, val_acc: 85.19349411104879
kfold: 2, epoch: 12. train_loss: 0.8593030161988575, train_acc: 82.95127935506484. val_loss: 0.8106967110537627, val_acc: 85.50196298373528
kfold: 2, epoch: 13. train_loss: 0.8441949633071241, train_acc: 83.93971258324571. val_loss: 0.8063353218572556, val_acc: 85.62815479528884
kfold: 2, epoch: 14. train_loss: 0.840474734157992, train_acc: 83.93971258324571. val_loss: 0.8017171433554636, val_acc: 85.93662366797533
kfold: 2, epoch: 15. train_loss: 0.837220966348199, train_acc: 84.12898703119524. val_loss: 0.8058355891651102, val_acc: 85.79641054402693
kfold: 2, epoch: 16. train_loss: 0.8273625351455179, train_acc: 84.35331230283911. val_loss: 0.7986143827438354, val_acc: 86.00673022994953
kfold: 2, epoch: 17. train_loss: 0.824331103485796, train_acc: 84.76691202243252. val_loss: 0.7979555640520002, val_acc: 86.00673022994953
kfold: 2, epoch: 18. train_loss: 0.8188558858004921, train_acc: 84.94917630564318. val_loss: 0.7982418327989065, val_acc: 86.00673022994953
kfold: 2, epoch: 19. train_loss: 0.8145547838956786, train_acc: 85.32071503680336. val_loss: 0.7890542090740974, val_acc: 86.81996634885026
kfold: 2, epoch: 20. train_loss: 0.8126389234255782, train_acc: 85.27164388363127. val_loss: 0.7880257009925329, val_acc: 86.48345485137409
kfold: 2, epoch: 21. train_loss: 0.8136096842620405, train_acc: 85.49596915527515. val_loss: 0.7907317244685819, val_acc: 86.58160403813797
kfold: 2, epoch: 22. train_loss: 0.8086468204187706, train_acc: 85.6081317910971. val_loss: 0.7936379497227647, val_acc: 86.56758272574314
kfold: 2, epoch: 23. train_loss: 0.8054418247443678, train_acc: 85.81843673326323. val_loss: 0.7907443161502548, val_acc: 86.49747616376892
kfold: 2, epoch: 24. train_loss: 0.7994539012689762, train_acc: 85.97967052225728. val_loss: 0.7939882844419223, val_acc: 86.28715647784632
kfold: 2, epoch: 25. train_loss: 0.7942999350115857, train_acc: 86.24605678233438. val_loss: 0.7942413204587628, val_acc: 86.14694335389792
kfold: 3, epoch: 1. train_loss: 1.2266845306540284, train_acc: 64.6267087276551. val_loss: 1.068537146120328, val_acc: 74.48121144139091
kfold: 3, epoch: 2. train_loss: 1.039922881821346, train_acc: 73.79600420609884. val_loss: 0.9472411766046901, val_acc: 79.94952327537858
kfold: 3, epoch: 3. train_loss: 0.9736872607750209, train_acc: 77.19593410445145. val_loss: 0.8898451673743971, val_acc: 82.10880538418397
kfold: 3, epoch: 4. train_loss: 0.9454355384870495, train_acc: 78.79425166491413. val_loss: 0.8689236288113444, val_acc: 83.1744251261918
kfold: 3, epoch: 5. train_loss: 0.9241846102235564, train_acc: 79.61444093936207. val_loss: 0.8485731830645035, val_acc: 84.14189568143578
kfold: 3, epoch: 6. train_loss: 0.9092141401874645, train_acc: 80.75008762705923. val_loss: 0.8370294423247666, val_acc: 84.7448121144139
kfold: 3, epoch: 7. train_loss: 0.8955373324687705, train_acc: 80.84822993340343. val_loss: 0.8290349522380016, val_acc: 84.95513180033652
kfold: 3, epoch: 8. train_loss: 0.8886432175946343, train_acc: 81.5913073957238. val_loss: 0.8156864829528492, val_acc: 85.01121704991587
kfold: 3, epoch: 9. train_loss: 0.8767740308503399, train_acc: 82.38345601121627. val_loss: 0.818021222949028, val_acc: 85.08132361189007
kfold: 3, epoch: 10. train_loss: 0.8714234363204161, train_acc: 82.4956186470382. val_loss: 0.8174359420222552, val_acc: 85.33370723499719
kfold: 3, epoch: 11. train_loss: 0.86700297414321, train_acc: 82.60077111812127. val_loss: 0.8102754050439783, val_acc: 85.31968592260236
kfold: 3, epoch: 12. train_loss: 0.8581745847725547, train_acc: 83.16158429723099. val_loss: 0.8045155866397335, val_acc: 85.67021873247336
kfold: 3, epoch: 13. train_loss: 0.8415870196081597, train_acc: 83.7434279705573. val_loss: 0.8093338090208079, val_acc: 85.22153673583847
kfold: 3, epoch: 14. train_loss: 0.8422760396794888, train_acc: 83.6733263231686. val_loss: 0.7993247023879679, val_acc: 85.78238923163208
kfold: 3, epoch: 15. train_loss: 0.8356046546668215, train_acc: 83.94672274798458. val_loss: 0.7982233186741047, val_acc: 86.11890072910825
kfold: 3, epoch: 16. train_loss: 0.8264731951559071, train_acc: 84.69681037504381. val_loss: 0.7955578224140433, val_acc: 86.28715647784632
kfold: 3, epoch: 17. train_loss: 0.8188104960950501, train_acc: 84.9702067998598. val_loss: 0.8006100969330612, val_acc: 85.964666292765
kfold: 3, epoch: 18. train_loss: 0.8166219395305544, train_acc: 85.29968454258675. val_loss: 0.7988728173912374, val_acc: 86.35726303982052
kfold: 3, epoch: 19. train_loss: 0.8121529463428019, train_acc: 85.32772520154224. val_loss: 0.8063601612911097, val_acc: 85.8244531688166
kfold: 3, epoch: 20. train_loss: 0.8094966977901523, train_acc: 85.56607080266386. val_loss: 0.796381833173769, val_acc: 86.46943353897925
kfold: 3, epoch: 21. train_loss: 0.801603138647272, train_acc: 85.8044164037855. val_loss: 0.7904534651292279, val_acc: 86.74985978687606
kfold: 3, epoch: 22. train_loss: 0.8034974297867762, train_acc: 85.81843673326323. val_loss: 0.7941463319041804, val_acc: 86.55356141334829
kfold: 3, epoch: 23. train_loss: 0.7957002412978844, train_acc: 86.1689449702068. val_loss: 0.7936381777172131, val_acc: 86.32922041503085
kfold: 3, epoch: 24. train_loss: 0.7927683186905267, train_acc: 86.0708026638626. val_loss: 0.7966446972748624, val_acc: 86.11890072910825
kfold: 3, epoch: 25. train_loss: 0.7910346190357422, train_acc: 86.47739221871714. val_loss: 0.7938930059494994, val_acc: 86.74985978687606