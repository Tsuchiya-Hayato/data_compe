filename: 003_albumentations_smoothing.ipynb, model: efficientnet-b3, lr: 1e-05, weights: tensor([1., 1., 1., 1., 1.]). batchsize: 8, kfold: 3, epoch: 25, weght_decay: 1e-05, smoothing: 0.05

kfold: 1, epoch: 1. train_loss: 1.0923049668883316, train_acc: 64.44896242288279. val_loss: 0.90489296825611, val_acc: 73.44735735314734
kfold: 1, epoch: 2. train_loss: 0.865654422286783, train_acc: 73.41559169938306. val_loss: 0.7685895810079147, val_acc: 79.19528949950933
kfold: 1, epoch: 3. train_loss: 0.7888102066095666, train_acc: 77.15227145260796. val_loss: 0.7117017719710889, val_acc: 81.59259778494322
kfold: 1, epoch: 4. train_loss: 0.7567788130001479, train_acc: 78.69461581604038. val_loss: 0.6809936389661156, val_acc: 82.67208748072339
kfold: 1, epoch: 5. train_loss: 0.7310921260632629, train_acc: 79.82333146382501. val_loss: 0.6591951413071744, val_acc: 84.01794476377401
kfold: 1, epoch: 6. train_loss: 0.7172562666843263, train_acc: 80.36315199102636. val_loss: 0.6468486761498878, val_acc: 84.13009953736156
kfold: 1, epoch: 7. train_loss: 0.7001763344045041, train_acc: 81.14834548513741. val_loss: 0.6342679221734338, val_acc: 84.4946025515211
kfold: 1, epoch: 8. train_loss: 0.6909479946817365, train_acc: 81.7372406057207. val_loss: 0.6201811742221294, val_acc: 85.13949249964952
kfold: 1, epoch: 9. train_loss: 0.6776412233033343, train_acc: 82.15086932136848. val_loss: 0.6187223350052876, val_acc: 85.50399551380906
kfold: 1, epoch: 10. train_loss: 0.6708783050868462, train_acc: 82.79584969153113. val_loss: 0.625870641571524, val_acc: 85.02733772606197
kfold: 1, epoch: 11. train_loss: 0.6587907184193259, train_acc: 82.99214806505888. val_loss: 0.6162897081452635, val_acc: 85.32174400672929
kfold: 1, epoch: 12. train_loss: 0.6526774121547642, train_acc: 83.45485137408862. val_loss: 0.6100062954786647, val_acc: 85.54605355390439
kfold: 1, epoch: 13. train_loss: 0.6419549322469276, train_acc: 83.85445877734156. val_loss: 0.6070568573915905, val_acc: 85.78438244777793
kfold: 1, epoch: 14. train_loss: 0.6387176440127165, train_acc: 83.89652271452609. val_loss: 0.613775263218869, val_acc: 85.37782139352306
kfold: 1, epoch: 15. train_loss: 0.6283282698771958, train_acc: 84.65367358384745. val_loss: 0.6069390669531887, val_acc: 85.57409224730128
kfold: 1, epoch: 16. train_loss: 0.6251697777130599, train_acc: 84.61160964666293. val_loss: 0.6075839109952674, val_acc: 85.6441889807935
kfold: 1, epoch: 17. train_loss: 0.6204280539703583, train_acc: 85.03925967470555. val_loss: 0.6126533549930483, val_acc: 85.1675311930464
kfold: 1, epoch: 18. train_loss: 0.6060240608684414, train_acc: 85.60011217049916. val_loss: 0.6092513349959668, val_acc: 85.44791812701528
kfold: 1, epoch: 19. train_loss: 0.6048601798241017, train_acc: 85.60712282669658. val_loss: 0.5958550686325728, val_acc: 85.98065330155615
kfold: 1, epoch: 20. train_loss: 0.6098310315267998, train_acc: 85.07431295569265. val_loss: 0.5980316955145164, val_acc: 85.91055656806392
kfold: 1, epoch: 21. train_loss: 0.5966282657071305, train_acc: 85.7192933258553. val_loss: 0.5930750409450232, val_acc: 85.98065330155615
kfold: 1, epoch: 22. train_loss: 0.5917354140533067, train_acc: 86.01374088614695. val_loss: 0.5954471920103236, val_acc: 85.91055656806392
kfold: 1, epoch: 23. train_loss: 0.5912819369515875, train_acc: 86.09786876051598. val_loss: 0.5930011848096356, val_acc: 86.05075003504837
kfold: 1, epoch: 24. train_loss: 0.583901656456229, train_acc: 86.52551878855861. val_loss: 0.592143090316533, val_acc: 86.02271134165147
kfold: 1, epoch: 25. train_loss: 0.5818599535719572, train_acc: 86.65171060011217. val_loss: 0.5924260272172535, val_acc: 86.14888546193747
kfold: 2, epoch: 1. train_loss: 1.089101706435194, train_acc: 64.83701366982125. val_loss: 0.9166079244739271, val_acc: 73.48569826135726
kfold: 2, epoch: 2. train_loss: 0.8711573790942607, train_acc: 73.45250613389415. val_loss: 0.7710069630111279, val_acc: 78.86988222097588
kfold: 2, epoch: 3. train_loss: 0.8006612680217611, train_acc: 76.8664563617245. val_loss: 0.7188239240592905, val_acc: 80.70667414469995
kfold: 2, epoch: 4. train_loss: 0.7588910785557977, train_acc: 78.45075359270943. val_loss: 0.6777894020147388, val_acc: 82.48738081884464
kfold: 2, epoch: 5. train_loss: 0.7477376596509341, train_acc: 79.15177006659657. val_loss: 0.6591730024582068, val_acc: 83.4828939988783
kfold: 2, epoch: 6. train_loss: 0.7252323449894185, train_acc: 80.21030494216615. val_loss: 0.651619727468544, val_acc: 83.70723499719574
kfold: 2, epoch: 7. train_loss: 0.7056350324620313, train_acc: 81.45110410094637. val_loss: 0.6369720999769566, val_acc: 84.28210880538418
kfold: 2, epoch: 8. train_loss: 0.6938620519744976, train_acc: 81.40203294777427. val_loss: 0.6250079704172943, val_acc: 84.6045989904655
kfold: 2, epoch: 9. train_loss: 0.6850248546143284, train_acc: 81.92779530318963. val_loss: 0.6194631634071269, val_acc: 85.15143017386427
kfold: 2, epoch: 10. train_loss: 0.6798797179965695, train_acc: 82.19418156326674. val_loss: 0.6162118955177042, val_acc: 84.99719573752103
kfold: 2, epoch: 11. train_loss: 0.6722859770159818, train_acc: 83.02839116719242. val_loss: 0.6195506197588326, val_acc: 84.99719573752103
kfold: 2, epoch: 12. train_loss: 0.6667124446264296, train_acc: 82.85313704872064. val_loss: 0.610532312382497, val_acc: 85.33370723499719
kfold: 2, epoch: 13. train_loss: 0.6509284325144483, train_acc: 83.68033648790747. val_loss: 0.6071510541131678, val_acc: 85.53000560852496
kfold: 2, epoch: 14. train_loss: 0.6441838760346575, train_acc: 83.85559060637925. val_loss: 0.6001744536273682, val_acc: 85.81043185642176
kfold: 2, epoch: 15. train_loss: 0.6404468284527283, train_acc: 84.04486505432878. val_loss: 0.6061120380401077, val_acc: 85.45989904655076
kfold: 2, epoch: 16. train_loss: 0.6269692779923768, train_acc: 84.33929197336137. val_loss: 0.596537707899718, val_acc: 85.90858104318565
kfold: 2, epoch: 17. train_loss: 0.6237951675137596, train_acc: 84.73887136347705. val_loss: 0.5959258668893122, val_acc: 86.11890072910825
kfold: 2, epoch: 18. train_loss: 0.6166328548750268, train_acc: 84.99824745881529. val_loss: 0.5972871715578798, val_acc: 85.7543466068424
kfold: 2, epoch: 19. train_loss: 0.6101005506021024, train_acc: 85.37679635471433. val_loss: 0.5844930098329424, val_acc: 86.62366797532249
kfold: 2, epoch: 20. train_loss: 0.6082342492057337, train_acc: 85.15948124780932. val_loss: 0.5831443481314342, val_acc: 86.35726303982052
kfold: 2, epoch: 21. train_loss: 0.6087304424711675, train_acc: 85.60112162635822. val_loss: 0.5870874211058489, val_acc: 86.45541222658441
kfold: 2, epoch: 22. train_loss: 0.6033535095875573, train_acc: 85.67122327374693. val_loss: 0.5917002729436742, val_acc: 86.35726303982052
kfold: 2, epoch: 23. train_loss: 0.5991130466719112, train_acc: 85.81142656852435. val_loss: 0.5892686626702681, val_acc: 86.34324172742569
kfold: 2, epoch: 24. train_loss: 0.592641416202078, train_acc: 86.00070101647388. val_loss: 0.5909748289550366, val_acc: 86.315199102636
kfold: 2, epoch: 25. train_loss: 0.5875870634054122, train_acc: 86.1689449702068. val_loss: 0.59088892850507, val_acc: 86.20302860347728
kfold: 3, epoch: 1. train_loss: 1.0842156425920302, train_acc: 64.71784086926043. val_loss: 0.8936582537443114, val_acc: 74.04655075715087
kfold: 3, epoch: 2. train_loss: 0.8597027712038012, train_acc: 73.51559761654399. val_loss: 0.7533245353621217, val_acc: 79.34660684240045
kfold: 3, epoch: 3. train_loss: 0.7855882374695063, train_acc: 77.3080967402734. val_loss: 0.6925299301275758, val_acc: 81.82837913628715
kfold: 3, epoch: 4. train_loss: 0.7549503794599809, train_acc: 78.9204346302138. val_loss: 0.6705480025154058, val_acc: 83.06225462703308
kfold: 3, epoch: 5. train_loss: 0.7316978003813013, train_acc: 79.64248159831756. val_loss: 0.6468902686318474, val_acc: 83.98766124509254
kfold: 3, epoch: 6. train_loss: 0.7157545641164876, train_acc: 80.6589554854539. val_loss: 0.6350406475465394, val_acc: 84.66068424004487
kfold: 3, epoch: 7. train_loss: 0.7002611759999943, train_acc: 81.08657553452507. val_loss: 0.6249760670311783, val_acc: 84.82893998878295
kfold: 3, epoch: 8. train_loss: 0.6935947595890862, train_acc: 81.75955134945671. val_loss: 0.6100059335742296, val_acc: 85.27762198541784
kfold: 3, epoch: 9. train_loss: 0.6805707976021574, train_acc: 82.56572029442692. val_loss: 0.6132657059171809, val_acc: 85.23555804823332
kfold: 3, epoch: 10. train_loss: 0.6756919848444484, train_acc: 82.39046617595514. val_loss: 0.6122561404189186, val_acc: 85.60011217049916
kfold: 3, epoch: 11. train_loss: 0.6716545851976348, train_acc: 82.70592358920435. val_loss: 0.6040950812766904, val_acc: 85.58609085810431
kfold: 3, epoch: 12. train_loss: 0.6629815923526148, train_acc: 83.09849281458115. val_loss: 0.5998125970697724, val_acc: 85.6842400448682
kfold: 3, epoch: 13. train_loss: 0.6450509694091675, train_acc: 83.82053978268489. val_loss: 0.6072313815622586, val_acc: 85.22153673583847
kfold: 3, epoch: 14. train_loss: 0.6472781373714118, train_acc: 83.49807220469681. val_loss: 0.5943915457736216, val_acc: 86.0347728547392
kfold: 3, epoch: 15. train_loss: 0.6403701300544856, train_acc: 83.9887837364178. val_loss: 0.5932040321452735, val_acc: 86.13292204150308
kfold: 3, epoch: 16. train_loss: 0.6312088555919483, train_acc: 84.39537329127235. val_loss: 0.5915583805118441, val_acc: 86.20302860347728
kfold: 3, epoch: 17. train_loss: 0.6211877696282928, train_acc: 84.81598317560463. val_loss: 0.5981439264165447, val_acc: 85.964666292765
kfold: 3, epoch: 18. train_loss: 0.6199093671022776, train_acc: 85.02628811777076. val_loss: 0.5946601897879031, val_acc: 86.16096466629277
kfold: 3, epoch: 19. train_loss: 0.6131397017315364, train_acc: 85.22257273045916. val_loss: 0.6048391909075425, val_acc: 85.72630398205273
kfold: 3, epoch: 20. train_loss: 0.6091072310948319, train_acc: 85.36978618997547. val_loss: 0.5926600223231743, val_acc: 86.34324172742569
kfold: 3, epoch: 21. train_loss: 0.5989216889668206, train_acc: 85.75534525061339. val_loss: 0.5842182259054461, val_acc: 86.60964666292764
kfold: 3, epoch: 22. train_loss: 0.6002675879897024, train_acc: 85.79740623904662. val_loss: 0.5892588848356709, val_acc: 86.23107122826697
kfold: 3, epoch: 23. train_loss: 0.5915693560857409, train_acc: 86.11286365229583. val_loss: 0.5885296729581239, val_acc: 86.34324172742569
kfold: 3, epoch: 24. train_loss: 0.5875554912694366, train_acc: 86.04276200490712. val_loss: 0.5933763808132287, val_acc: 86.3853056646102
kfold: 3, epoch: 25. train_loss: 0.5848177312935949, train_acc: 86.49141254819489. val_loss: 0.5888060695520966, val_acc: 86.35726303982052