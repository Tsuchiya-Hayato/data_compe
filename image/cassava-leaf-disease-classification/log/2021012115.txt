model: efficientnet-b3, lr: 1e-05, weights: tensor([1.5000, 1.0000, 1.0000, 1.0000, 1.0000]). batchsize: 8, kfold: 3, epoch: 20, weght_decay: 1e-06,

kfold: 1, epoch: 1. train_loss: 1.0384300365684678, train_acc: 64.78547392035894. val_loss: 0.813506838151425, val_acc: 73.25108649936912
kfold: 1, epoch: 2. train_loss: 0.7624586757337252, train_acc: 73.57683679192372. val_loss: 0.6465020867006126, val_acc: 79.01303799242956
kfold: 1, epoch: 3. train_loss: 0.6618698785479524, train_acc: 77.22237801458216. val_loss: 0.5727789123279498, val_acc: 81.28417215757746
kfold: 1, epoch: 4. train_loss: 0.6164873914184091, train_acc: 78.54038137969714. val_loss: 0.5330978624142639, val_acc: 82.16739099957942
kfold: 1, epoch: 5. train_loss: 0.5867790843637486, train_acc: 79.93550196298374. val_loss: 0.5054532374743991, val_acc: 83.20482265526427
kfold: 1, epoch: 6. train_loss: 0.564738844503062, train_acc: 80.33510936623668. val_loss: 0.49052398978532064, val_acc: 83.6674610963129
kfold: 1, epoch: 7. train_loss: 0.5433771170527412, train_acc: 81.08524957936064. val_loss: 0.47501413416819055, val_acc: 83.87775129678957
kfold: 1, epoch: 8. train_loss: 0.5322834443733455, train_acc: 82.10179472798654. val_loss: 0.4619105333554237, val_acc: 84.81704752558531
kfold: 1, epoch: 9. train_loss: 0.5136673805072477, train_acc: 82.48037016264722. val_loss: 0.45986876652822434, val_acc: 84.92920229917286
kfold: 1, epoch: 10. train_loss: 0.5079273411119278, train_acc: 82.95008412787436. val_loss: 0.4684108821722165, val_acc: 84.3684284312351
kfold: 1, epoch: 11. train_loss: 0.4908868356895661, train_acc: 83.06926528323051. val_loss: 0.4556007758994073, val_acc: 84.85910556568064
kfold: 1, epoch: 12. train_loss: 0.4855333798206127, train_acc: 83.53196859226024. val_loss: 0.4516027263718586, val_acc: 84.99929903266508
kfold: 1, epoch: 13. train_loss: 0.47446692362009846, train_acc: 83.87549074593382. val_loss: 0.4477817494841919, val_acc: 85.32174400672929
kfold: 1, epoch: 14. train_loss: 0.4696107017052889, train_acc: 84.07178911946158. val_loss: 0.4621584802728163, val_acc: 84.67685405860087
kfold: 1, epoch: 15. train_loss: 0.46289396638064256, train_acc: 84.40830061693775. val_loss: 0.4534038186940937, val_acc: 85.1955698864433
kfold: 1, epoch: 16. train_loss: 0.4591344167445475, train_acc: 84.5695457094784. val_loss: 0.45248039566698767, val_acc: 85.0413570727604
kfold: 1, epoch: 17. train_loss: 0.4549603804421522, train_acc: 84.89203589455973. val_loss: 0.45788333732154507, val_acc: 84.77498948548998
kfold: 1, epoch: 18. train_loss: 0.43859495623094674, train_acc: 85.36174985978688. val_loss: 0.45645193784652205, val_acc: 84.95724099256975
kfold: 1, epoch: 19. train_loss: 0.44037682457763827, train_acc: 85.24256870443074. val_loss: 0.43825172467602025, val_acc: 85.47595682041216
kfold: 1, epoch: 20. train_loss: 0.44691283217580613, train_acc: 84.9481211441391. val_loss: 0.4479598153534976, val_acc: 85.2937053133324
kfold: 2, epoch: 1. train_loss: 1.036467372469036, train_acc: 64.36733263231686. val_loss: 0.823321896584312, val_acc: 72.2378014582165
kfold: 2, epoch: 2. train_loss: 0.7640117224088698, train_acc: 73.59971959341044. val_loss: 0.6190249727111761, val_acc: 79.92148065058889
kfold: 2, epoch: 3. train_loss: 0.6670671408127309, train_acc: 77.32211706975114. val_loss: 0.5555932510669256, val_acc: 81.64610207515423
kfold: 2, epoch: 4. train_loss: 0.6182873804172325, train_acc: 78.54889589905363. val_loss: 0.5168002662854478, val_acc: 82.76780706674144
kfold: 2, epoch: 5. train_loss: 0.5879021180572297, train_acc: 79.76165439887838. val_loss: 0.4887439779051884, val_acc: 83.37072349971957
kfold: 2, epoch: 6. train_loss: 0.5739763355333642, train_acc: 80.18927444794953. val_loss: 0.48009474930716806, val_acc: 83.60908581043185
kfold: 2, epoch: 7. train_loss: 0.555137482083365, train_acc: 80.96039256922538. val_loss: 0.4623846391449795, val_acc: 84.35221536735838
kfold: 2, epoch: 8. train_loss: 0.5415540093330524, train_acc: 81.60532772520155. val_loss: 0.45348647416615234, val_acc: 84.42232192933258
kfold: 2, epoch: 9. train_loss: 0.5214235459124427, train_acc: 82.22222222222223. val_loss: 0.4516962613156608, val_acc: 84.71676948962423
kfold: 2, epoch: 10. train_loss: 0.5218117575958839, train_acc: 82.45355765860498. val_loss: 0.4450257396776513, val_acc: 84.88502523836232
kfold: 2, epoch: 11. train_loss: 0.5090708196551577, train_acc: 82.50963897651594. val_loss: 0.4519524848623193, val_acc: 84.78687605159843
kfold: 2, epoch: 12. train_loss: 0.4944737284912022, train_acc: 83.5751840168244. val_loss: 0.43703036769105313, val_acc: 85.31968592260236
kfold: 2, epoch: 13. train_loss: 0.4839520159536647, train_acc: 83.59621451104101. val_loss: 0.42961774760389476, val_acc: 85.78238923163208
kfold: 2, epoch: 14. train_loss: 0.48353629560531386, train_acc: 83.68734665264634. val_loss: 0.42781157807902237, val_acc: 85.58609085810431
kfold: 2, epoch: 15. train_loss: 0.4802479113320582, train_acc: 83.98177357167893. val_loss: 0.42939587735107393, val_acc: 85.65619742007851
kfold: 2, epoch: 16. train_loss: 0.46972343134129996, train_acc: 84.25516999649491. val_loss: 0.4313887486896256, val_acc: 85.50196298373528
kfold: 2, epoch: 17. train_loss: 0.4680598715368257, train_acc: 84.31826147914477. val_loss: 0.42162018955367797, val_acc: 86.13292204150308
kfold: 2, epoch: 18. train_loss: 0.45274657523468337, train_acc: 84.99824745881529. val_loss: 0.42634319915486324, val_acc: 85.72630398205273
kfold: 2, epoch: 19. train_loss: 0.43637757487762135, train_acc: 85.25762355415353. val_loss: 0.41796247358225086, val_acc: 86.06281547952888
kfold: 2, epoch: 20. train_loss: 0.44843331089602456, train_acc: 84.92814581142657. val_loss: 0.4183038798340433, val_acc: 85.69826135726304
kfold: 3, epoch: 1. train_loss: 1.0312089172563612, train_acc: 64.98422712933754. val_loss: 0.8119735418914946, val_acc: 73.68199663488502
kfold: 3, epoch: 2. train_loss: 0.7763792361245562, train_acc: 73.56466876971609. val_loss: 0.6441476901517054, val_acc: 79.41671340437465
kfold: 3, epoch: 3. train_loss: 0.6687319587724024, train_acc: 77.111812127585. val_loss: 0.5584061361323089, val_acc: 81.42176107683679
kfold: 3, epoch: 4. train_loss: 0.6197808395085581, train_acc: 79.03960743077462. val_loss: 0.5206372162281231, val_acc: 82.57150869321369
kfold: 3, epoch: 5. train_loss: 0.5935663249836441, train_acc: 79.59341044514547. val_loss: 0.49578595448769797, val_acc: 83.00616937745373
kfold: 3, epoch: 6. train_loss: 0.5718203630640836, train_acc: 80.72204696810375. val_loss: 0.47216547571431694, val_acc: 84.15591699383062
kfold: 3, epoch: 7. train_loss: 0.5493632343058963, train_acc: 81.25481948825798. val_loss: 0.4636166070738281, val_acc: 84.09983174425126
kfold: 3, epoch: 8. train_loss: 0.5444302668861811, train_acc: 81.61934805467928. val_loss: 0.44588367703930376, val_acc: 85.01121704991587
kfold: 3, epoch: 9. train_loss: 0.5320641262239605, train_acc: 81.78058184367333. val_loss: 0.4426325749294757, val_acc: 85.33370723499719
kfold: 3, epoch: 10. train_loss: 0.5218771060536127, train_acc: 82.81808622502629. val_loss: 0.43910661002964557, val_acc: 85.13740886146944
kfold: 3, epoch: 11. train_loss: 0.499802496353156, train_acc: 82.89519803715388. val_loss: 0.44931356053101945, val_acc: 84.66068424004487
kfold: 3, epoch: 12. train_loss: 0.5050012830461087, train_acc: 82.90921836663162. val_loss: 0.439916518934472, val_acc: 85.23555804823332
kfold: 3, epoch: 13. train_loss: 0.4862571556221343, train_acc: 83.51209253417456. val_loss: 0.42733458637974053, val_acc: 85.72630398205273
kfold: 3, epoch: 14. train_loss: 0.4803473783631897, train_acc: 83.869610935857. val_loss: 0.42859132839742664, val_acc: 85.614133482894
kfold: 3, epoch: 15. train_loss: 0.4757553993018486, train_acc: 83.75744830003505. val_loss: 0.43717671672849095, val_acc: 85.17947279865395
kfold: 3, epoch: 16. train_loss: 0.46555515415047716, train_acc: 84.52155625657203. val_loss: 0.42119315488946796, val_acc: 85.74032529444756
kfold: 3, epoch: 17. train_loss: 0.4476182713922982, train_acc: 84.84402383456012. val_loss: 0.421126777805271, val_acc: 86.02075154234436
kfold: 3, epoch: 18. train_loss: 0.44890094491039223, train_acc: 85.18752190676481. val_loss: 0.42047824001883577, val_acc: 86.13292204150308
kfold: 3, epoch: 19. train_loss: 0.4440253369338944, train_acc: 85.1384507535927. val_loss: 0.4245313779798633, val_acc: 85.88053841839596
kfold: 3, epoch: 20. train_loss: 0.44414405804023044, train_acc: 85.25061338941465. val_loss: 0.4236063171134251, val_acc: 85.62815479528884